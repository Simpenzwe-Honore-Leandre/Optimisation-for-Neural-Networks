{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "af8e0a2f-362c-4eca-98a5-8538a5c9a57e",
      "metadata": {
        "id": "af8e0a2f-362c-4eca-98a5-8538a5c9a57e"
      },
      "source": [
        "# 1 . PERCEPTRON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d4c691e-6c40-4b7d-9d02-27e3669b8270",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d4c691e-6c40-4b7d-9d02-27e3669b8270",
        "outputId": "c51822ad-d249-4e08-c74a-578d8e0790e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5caa0ecc-7fd2-4b69-baba-1c8c8f6fc841",
      "metadata": {
        "id": "5caa0ecc-7fd2-4b69-baba-1c8c8f6fc841"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import json\n",
        "import threading\n",
        "from collections import defaultdict\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78f6daff-55ea-4cf2-ba0c-a9a8e975bd6d",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "78f6daff-55ea-4cf2-ba0c-a9a8e975bd6d"
      },
      "source": [
        "# 1.1 perceptron test withOUT regularisation learns mean function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48c8475a-c8df-470c-a908-e55ef99f5b51",
      "metadata": {
        "id": "48c8475a-c8df-470c-a908-e55ef99f5b51"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "class perceptron_model:\n",
        "    \"\"\"\n",
        "    we need\n",
        "    input, weights and learning rate\n",
        "    \"\"\"\n",
        "    def __init__(self, learning_rate=0.8 , epochs=200 ):\n",
        "        self.learning_rate= learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.cache= defaultdict(list)\n",
        "\n",
        "    def sigmoid(self , X):\n",
        "        return 1 / ( 1 + np.exp(-X))\n",
        "\n",
        "    def loss(self , y_true , y_pred ):\n",
        "        # print(y_true.shape[0])\n",
        "        n = y_true.shape[0]\n",
        "        e = y_true - y_pred\n",
        "        loss = 1/(2 * n ) * np.sum( np.square( e ))\n",
        "        return loss\n",
        "\n",
        "    def weight_update(self, y_true , y_pred):\n",
        "        n = y_true.shape[0]\n",
        "        delta_W =   self.learning_rate / n *  np.dot( ( y_true - y_pred )  , self.X )\n",
        "        delta_B =  self.learning_rate  * np.mean(( y_true - y_pred ))\n",
        "        self.bias += delta_B\n",
        "        self.weights += delta_W\n",
        "\n",
        "    def train(self , X , Y ):\n",
        "        self.cache.clear()\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        self.input_size = self.X.shape\n",
        "        # Xavier initialisation\n",
        "        self.weights = np.random.normal(0, np.sqrt( 1 / self.input_size[1] ) , size=self.input_size[1] )\n",
        "        self.bias= 0\n",
        "        output = None\n",
        "        for epoch in range(self.epochs):\n",
        "            state = np.dot( self.weights , self.X.T ) + self.bias\n",
        "            activation = self.sigmoid( state )\n",
        "            self.cache[\"states\"].append(output)\n",
        "            self.cache[\"activations\"].append(activation)\n",
        "            self.cache[\"Losses\"].append( self.loss( self.Y , activation ) )\n",
        "            self.weight_update( self.Y , activation )\n",
        "            print( f\"the loss for epoch {1+epoch} is  { self.cache['Losses'][-1] }\" )\n",
        "        plt.plot( range(self.epochs) , self.cache[\"Losses\"] )\n",
        "        plt.xlabel('X-axis ,  epochs')\n",
        "        plt.ylabel('Y-axis ,  Loss')\n",
        "\n",
        "    def test(self, y_test ):\n",
        "        self.y_pred = np.dot( self.weights , y_test.T )  + self.bias\n",
        "        return self.y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e17bfe33-d113-4264-b2d0-5812fd337304",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "e17bfe33-d113-4264-b2d0-5812fd337304",
        "outputId": "ddf87a09-1041-46b2-dcf2-04f146c971e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              0             1             2             3             4  \\\n",
              "0  4.131046e+13  1.608853e+01  3.686298e+16  4.716351e+33  2.150463e-01   \n",
              "1  5.910223e+34  8.069013e+18  5.414948e-06  3.251156e+14  7.111508e-06   \n",
              "2  4.338903e+08  3.288009e-34  1.578145e-30  8.312346e-08  1.302078e-16   \n",
              "3  1.455148e-14  2.030690e-24  3.566097e+32  3.135070e-01  1.691886e+05   \n",
              "4  1.860552e-07  1.192445e+06  2.597127e-19  1.782425e+11  1.479848e-08   \n",
              "\n",
              "              5  \n",
              "0  2.152052e-01  \n",
              "1  6.408797e-06  \n",
              "2  1.122187e+10  \n",
              "3  1.159946e-24  \n",
              "4  1.614381e-02  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13ca8c21-99bf-44c9-ab09-651135ec42d6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.131046e+13</td>\n",
              "      <td>1.608853e+01</td>\n",
              "      <td>3.686298e+16</td>\n",
              "      <td>4.716351e+33</td>\n",
              "      <td>2.150463e-01</td>\n",
              "      <td>2.152052e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.910223e+34</td>\n",
              "      <td>8.069013e+18</td>\n",
              "      <td>5.414948e-06</td>\n",
              "      <td>3.251156e+14</td>\n",
              "      <td>7.111508e-06</td>\n",
              "      <td>6.408797e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.338903e+08</td>\n",
              "      <td>3.288009e-34</td>\n",
              "      <td>1.578145e-30</td>\n",
              "      <td>8.312346e-08</td>\n",
              "      <td>1.302078e-16</td>\n",
              "      <td>1.122187e+10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.455148e-14</td>\n",
              "      <td>2.030690e-24</td>\n",
              "      <td>3.566097e+32</td>\n",
              "      <td>3.135070e-01</td>\n",
              "      <td>1.691886e+05</td>\n",
              "      <td>1.159946e-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.860552e-07</td>\n",
              "      <td>1.192445e+06</td>\n",
              "      <td>2.597127e-19</td>\n",
              "      <td>1.782425e+11</td>\n",
              "      <td>1.479848e-08</td>\n",
              "      <td>1.614381e-02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13ca8c21-99bf-44c9-ab09-651135ec42d6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-13ca8c21-99bf-44c9-ab09-651135ec42d6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-13ca8c21-99bf-44c9-ab09-651135ec42d6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d669fc92-5dc0-4f9e-a051-8f2cfc23ef59\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d669fc92-5dc0-4f9e-a051-8f2cfc23ef59')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d669fc92-5dc0-4f9e-a051-8f2cfc23ef59 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 80,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.700839374069463e+45,\n        \"min\": 2.6818288827888172e-30,\n        \"max\": 5.064309076630638e+46,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          1.3684369300554334e+16,\n          41310461359606.6,\n          1.4053402766149817e-17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4341985670182218e+39,\n        \"min\": 1.1616914594617484e-35,\n        \"max\": 1.2828890221013167e+40,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          1.4355042341726838e-13,\n          16.08852761181757,\n          14594405387709.857\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1699910253219573e+45,\n        \"min\": 5.1323045055907595e-48,\n        \"max\": 9.746238379029789e+45,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          9.54835855958911e-18,\n          3.686298089210936e+16,\n          8.711864692878117e-15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.2335931143411263e+39,\n        \"min\": 8.348830695991992e-42,\n        \"max\": 3.7594927634097145e+40,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          21763572154241.59,\n          4.716351293221101e+33,\n          1.582736109134116e+34\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3441504859206468e+63,\n        \"min\": 3.662241078428268e-60,\n        \"max\": 1.2022447434031763e+64,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          0.34790516884469186,\n          0.2150463134729476,\n          3.99331998275853e-12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7865144887678282e+78,\n        \"min\": 1.1361159100414841e-36,\n        \"max\": 1.5979071358692623e+79,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          7.286881328944776e+17,\n          0.215205248357592,\n          0.004116433156693826\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 177
        }
      ],
      "source": [
        "\n",
        "X = np.random.lognormal( 9 , 45 , size=[80 , 6] )\n",
        "Y = np.mean( X,axis=1)\n",
        "data = pd.DataFrame(X)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.insert( len(data.columns), len(data.columns) , Y)"
      ],
      "metadata": {
        "id": "-arVv1hP4Ial"
      },
      "id": "-arVv1hP4Ial",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bAdU1vx05h_W",
        "outputId": "ee7c4de9-13cb-4991-ae39-f43fb8301393"
      },
      "id": "bAdU1vx05h_W",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              0             1             2             3             4  \\\n",
              "0  4.131046e+13  1.608853e+01  3.686298e+16  4.716351e+33  2.150463e-01   \n",
              "1  5.910223e+34  8.069013e+18  5.414948e-06  3.251156e+14  7.111508e-06   \n",
              "2  4.338903e+08  3.288009e-34  1.578145e-30  8.312346e-08  1.302078e-16   \n",
              "3  1.455148e-14  2.030690e-24  3.566097e+32  3.135070e-01  1.691886e+05   \n",
              "4  1.860552e-07  1.192445e+06  2.597127e-19  1.782425e+11  1.479848e-08   \n",
              "\n",
              "              5             6  \n",
              "0  2.152052e-01  7.860585e+32  \n",
              "1  6.408797e-06  9.850371e+33  \n",
              "2  1.122187e+10  1.942626e+09  \n",
              "3  1.159946e-24  5.943494e+31  \n",
              "4  1.614381e-02  2.970728e+10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b3339dd-21cf-494e-9632-c815f1afbba1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.131046e+13</td>\n",
              "      <td>1.608853e+01</td>\n",
              "      <td>3.686298e+16</td>\n",
              "      <td>4.716351e+33</td>\n",
              "      <td>2.150463e-01</td>\n",
              "      <td>2.152052e-01</td>\n",
              "      <td>7.860585e+32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.910223e+34</td>\n",
              "      <td>8.069013e+18</td>\n",
              "      <td>5.414948e-06</td>\n",
              "      <td>3.251156e+14</td>\n",
              "      <td>7.111508e-06</td>\n",
              "      <td>6.408797e-06</td>\n",
              "      <td>9.850371e+33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.338903e+08</td>\n",
              "      <td>3.288009e-34</td>\n",
              "      <td>1.578145e-30</td>\n",
              "      <td>8.312346e-08</td>\n",
              "      <td>1.302078e-16</td>\n",
              "      <td>1.122187e+10</td>\n",
              "      <td>1.942626e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.455148e-14</td>\n",
              "      <td>2.030690e-24</td>\n",
              "      <td>3.566097e+32</td>\n",
              "      <td>3.135070e-01</td>\n",
              "      <td>1.691886e+05</td>\n",
              "      <td>1.159946e-24</td>\n",
              "      <td>5.943494e+31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.860552e-07</td>\n",
              "      <td>1.192445e+06</td>\n",
              "      <td>2.597127e-19</td>\n",
              "      <td>1.782425e+11</td>\n",
              "      <td>1.479848e-08</td>\n",
              "      <td>1.614381e-02</td>\n",
              "      <td>2.970728e+10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b3339dd-21cf-494e-9632-c815f1afbba1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8b3339dd-21cf-494e-9632-c815f1afbba1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8b3339dd-21cf-494e-9632-c815f1afbba1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bf4a64c6-7245-4400-b729-9fa76b429227\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bf4a64c6-7245-4400-b729-9fa76b429227')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bf4a64c6-7245-4400-b729-9fa76b429227 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 80,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.700839374069463e+45,\n        \"min\": 2.6818288827888172e-30,\n        \"max\": 5.064309076630638e+46,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          1.3684369300554334e+16,\n          41310461359606.6,\n          1.4053402766149817e-17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4341985670182218e+39,\n        \"min\": 1.1616914594617484e-35,\n        \"max\": 1.2828890221013167e+40,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          1.4355042341726838e-13,\n          16.08852761181757,\n          14594405387709.857\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1699910253219573e+45,\n        \"min\": 5.1323045055907595e-48,\n        \"max\": 9.746238379029789e+45,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          9.54835855958911e-18,\n          3.686298089210936e+16,\n          8.711864692878117e-15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.2335931143411263e+39,\n        \"min\": 8.348830695991992e-42,\n        \"max\": 3.7594927634097145e+40,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          21763572154241.59,\n          4.716351293221101e+33,\n          1.582736109134116e+34\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3441504859206468e+63,\n        \"min\": 3.662241078428268e-60,\n        \"max\": 1.2022447434031763e+64,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          0.34790516884469186,\n          0.2150463134729476,\n          3.99331998275853e-12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7865144887678282e+78,\n        \"min\": 1.1361159100414841e-36,\n        \"max\": 1.5979071358692623e+79,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          7.286881328944776e+17,\n          0.215205248357592,\n          0.004116433156693826\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 6,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.977524147946382e+77,\n        \"min\": 149219.2093071559,\n        \"max\": 2.663178559782104e+78,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          1.2373237762786437e+17,\n          7.860585488701836e+32,\n          2.637893515223527e+33\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "data = scaler.fit_transform(data)"
      ],
      "metadata": {
        "id": "EEUE145y4Bwv"
      },
      "id": "EEUE145y4Bwv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "184699bc-13f5-4fb1-8a90-50e4a97532a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "184699bc-13f5-4fb1-8a90-50e4a97532a9",
        "outputId": "d8b5f85e-6e8f-403f-eda9-e499397c6945"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ],
      "source": [
        "data[: ,:-1].shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X862EZsX6I58",
        "outputId": "592379d9-cf50-4203-9251-2a76f895e17e"
      },
      "id": "X862EZsX6I58",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert  0.39514757042074466 > 0.39514756978355536"
      ],
      "metadata": {
        "id": "aafnq0Ge6jaB"
      },
      "id": "aafnq0Ge6jaB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "801d26ee-ea0a-4b8e-ad89-6137481502bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "801d26ee-ea0a-4b8e-ad89-6137481502bf",
        "outputId": "74838fc7-4118-49bc-cb56-fff1bbb0880a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the loss for epoch 1 is  0.7058280953630676\n",
            "the loss for epoch 2 is  0.5232353661513355\n",
            "the loss for epoch 3 is  0.4713368616204496\n",
            "the loss for epoch 4 is  0.44531915128526256\n",
            "the loss for epoch 5 is  0.4302415779736521\n",
            "the loss for epoch 6 is  0.4209181425043802\n",
            "the loss for epoch 7 is  0.41480209188723793\n",
            "the loss for epoch 8 is  0.41058628929771573\n",
            "the loss for epoch 9 is  0.4075596821302182\n",
            "the loss for epoch 10 is  0.4053130939439119\n",
            "the loss for epoch 11 is  0.4035989446658008\n",
            "the loss for epoch 12 is  0.40226074272399925\n",
            "the loss for epoch 13 is  0.40119576219332614\n",
            "the loss for epoch 14 is  0.40033432552452947\n",
            "the loss for epoch 15 is  0.39962780460720615\n",
            "the loss for epoch 16 is  0.39904140409041505\n",
            "the loss for epoch 17 is  0.3985496732414385\n",
            "the loss for epoch 18 is  0.3981336304226715\n",
            "the loss for epoch 19 is  0.39777887120465194\n",
            "the loss for epoch 20 is  0.3974742936864651\n",
            "the loss for epoch 21 is  0.39721122109340523\n",
            "the loss for epoch 22 is  0.3969827860442311\n",
            "the loss for epoch 23 is  0.396783490804276\n",
            "the loss for epoch 24 is  0.3966088881677328\n",
            "the loss for epoch 25 is  0.3964553464720907\n",
            "the loss for epoch 26 is  0.3963198742304699\n",
            "the loss for epoch 27 is  0.3961999876325177\n",
            "the loss for epoch 28 is  0.39609360928835796\n",
            "the loss for epoch 29 is  0.3959989900282546\n",
            "the loss for epoch 30 is  0.3959146479137833\n",
            "the loss for epoch 31 is  0.3958393202363246\n",
            "the loss for epoch 32 is  0.39577192541387046\n",
            "the loss for epoch 33 is  0.3957115325025791\n",
            "the loss for epoch 34 is  0.3956573366177286\n",
            "the loss for epoch 35 is  0.39560863897835746\n",
            "the loss for epoch 36 is  0.39556483059759223\n",
            "the loss for epoch 37 is  0.3955253788684727\n",
            "the loss for epoch 38 is  0.3954898164652858\n",
            "the loss for epoch 39 is  0.3954577321086623\n",
            "the loss for epoch 40 is  0.3954287628401076\n",
            "the loss for epoch 41 is  0.3954025875261949\n",
            "the loss for epoch 42 is  0.395378921370128\n",
            "the loss for epoch 43 is  0.395357511252993\n",
            "the loss for epoch 44 is  0.3953381317618665\n",
            "the loss for epoch 45 is  0.395320581789337\n",
            "the loss for epoch 46 is  0.395304681610646\n",
            "the loss for epoch 47 is  0.39529027036187003\n",
            "the loss for epoch 48 is  0.3952772038563106\n",
            "the loss for epoch 49 is  0.39526535268730845\n",
            "the loss for epoch 50 is  0.3952546005746079\n",
            "the loss for epoch 51 is  0.3952448429186244\n",
            "the loss for epoch 52 is  0.395235985532849\n",
            "the loss for epoch 53 is  0.395227943529438\n",
            "the loss for epoch 54 is  0.3952206403369854\n",
            "the loss for epoch 55 is  0.3952140068327342\n",
            "the loss for epoch 56 is  0.3952079805741786\n",
            "the loss for epoch 57 is  0.39520250511725\n",
            "the loss for epoch 58 is  0.3951975294101494\n",
            "the loss for epoch 59 is  0.39519300725344925\n",
            "the loss for epoch 60 is  0.39518889681840574\n",
            "the loss for epoch 61 is  0.39518516021652644\n",
            "the loss for epoch 62 is  0.395181763114377\n",
            "the loss for epoch 63 is  0.3951786743884034\n",
            "the loss for epoch 64 is  0.39517586581522485\n",
            "the loss for epoch 65 is  0.395173311793429\n",
            "the loss for epoch 66 is  0.395170989093397\n",
            "the loss for epoch 67 is  0.39516887663211153\n",
            "the loss for epoch 68 is  0.39516695527026874\n",
            "the loss for epoch 69 is  0.3951652076293293\n",
            "the loss for epoch 70 is  0.39516361792642396\n",
            "the loss for epoch 71 is  0.39516217182526375\n",
            "the loss for epoch 72 is  0.3951608563014155\n",
            "the loss for epoch 73 is  0.39515965952048615\n",
            "the loss for epoch 74 is  0.39515857072791744\n",
            "the loss for epoch 75 is  0.3951575801492352\n",
            "the loss for epoch 76 is  0.395156678899719\n",
            "the loss for epoch 77 is  0.39515585890256766\n",
            "the loss for epoch 78 is  0.3951551128147339\n",
            "the loss for epoch 79 is  0.3951544339596842\n",
            "the loss for epoch 80 is  0.39515381626641854\n",
            "the loss for epoch 81 is  0.3951532542141496\n",
            "the loss for epoch 82 is  0.3951527427821051\n",
            "the loss for epoch 83 is  0.39515227740396264\n",
            "the loss for epoch 84 is  0.3951518539264863\n",
            "the loss for epoch 85 is  0.3951514685719644\n",
            "the loss for epoch 86 is  0.39515111790409657\n",
            "the loss for epoch 87 is  0.3951507987970043\n",
            "the loss for epoch 88 is  0.39515050840707844\n",
            "the loss for epoch 89 is  0.39515024414739713\n",
            "the loss for epoch 90 is  0.3951500036644777\n",
            "the loss for epoch 91 is  0.39514978481714724\n",
            "the loss for epoch 92 is  0.3951495856573359\n",
            "the loss for epoch 93 is  0.39514940441261664\n",
            "the loss for epoch 94 is  0.3951492394703316\n",
            "the loss for epoch 95 is  0.39514908936315796\n",
            "the loss for epoch 96 is  0.3951489527559845\n",
            "the loss for epoch 97 is  0.3951488284339759\n",
            "the loss for epoch 98 is  0.39514871529171947\n",
            "the loss for epoch 99 is  0.3951486123233534\n",
            "the loss for epoch 100 is  0.39514851861358813\n",
            "the loss for epoch 101 is  0.39514843332954025\n",
            "the loss for epoch 102 is  0.39514835571330315\n",
            "the loss for epoch 103 is  0.3951482850751906\n",
            "the loss for epoch 104 is  0.39514822078758893\n",
            "the loss for epoch 105 is  0.3951481622793649\n",
            "the loss for epoch 106 is  0.3951481090307783\n",
            "the loss for epoch 107 is  0.3951480605688532\n",
            "the loss for epoch 108 is  0.3951480164631669\n",
            "the loss for epoch 109 is  0.39514797632201876\n",
            "the loss for epoch 110 is  0.39514793978894386\n",
            "the loss for epoch 111 is  0.3951479065395416\n",
            "the loss for epoch 112 is  0.3951478762785894\n",
            "the loss for epoch 113 is  0.3951478487374166\n",
            "the loss for epoch 114 is  0.3951478236715158\n",
            "the loss for epoch 115 is  0.3951478008583679\n",
            "the loss for epoch 116 is  0.39514778009546414\n",
            "the loss for epoch 117 is  0.39514776119850553\n",
            "the loss for epoch 118 is  0.39514774399976493\n",
            "the loss for epoch 119 is  0.39514772834659606\n",
            "the loss for epoch 120 is  0.3951477141000774\n",
            "the loss for epoch 121 is  0.39514770113377723\n",
            "the loss for epoch 122 is  0.3951476893326307\n",
            "the loss for epoch 123 is  0.39514767859191746\n",
            "the loss for epoch 124 is  0.3951476688163311\n",
            "the loss for epoch 125 is  0.395147659919133\n",
            "the loss for epoch 126 is  0.39514765182138156\n",
            "the loss for epoch 127 is  0.39514764445123135\n",
            "the loss for epoch 128 is  0.395147637743295\n",
            "the loss for epoch 129 is  0.39514763163806244\n",
            "the loss for epoch 130 is  0.39514762608137244\n",
            "the loss for epoch 131 is  0.39514762102393197\n",
            "the loss for epoch 132 is  0.39514761642087837\n",
            "the loss for epoch 133 is  0.395147612231381\n",
            "the loss for epoch 134 is  0.395147608418279\n",
            "the loss for epoch 135 is  0.3951476049477511\n",
            "the loss for epoch 136 is  0.39514760178901565\n",
            "the loss for epoch 137 is  0.3951475989140573\n",
            "the loss for epoch 138 is  0.3951475962973785\n",
            "the loss for epoch 139 is  0.39514759391577275\n",
            "the loss for epoch 140 is  0.39514759174811914\n",
            "the loss for epoch 141 is  0.3951475897751949\n",
            "the loss for epoch 142 is  0.3951475879795042\n",
            "the loss for epoch 143 is  0.3951475863451239\n",
            "the loss for epoch 144 is  0.3951475848575611\n",
            "the loss for epoch 145 is  0.39514758350362567\n",
            "the loss for epoch 146 is  0.39514758227131236\n",
            "the loss for epoch 147 is  0.3951475811496947\n",
            "the loss for epoch 148 is  0.3951475801288282\n",
            "the loss for epoch 149 is  0.3951475791996615\n",
            "the loss for epoch 150 is  0.39514757835395675\n",
            "the loss for epoch 151 is  0.39514757758421615\n",
            "the loss for epoch 152 is  0.39514757688361557\n",
            "the loss for epoch 153 is  0.39514757624594404\n",
            "the loss for epoch 154 is  0.39514757566554853\n",
            "the loss for epoch 155 is  0.39514757513728405\n",
            "the loss for epoch 156 is  0.3951475746564675\n",
            "the loss for epoch 157 is  0.395147574218837\n",
            "the loss for epoch 158 is  0.39514757382051297\n",
            "the loss for epoch 159 is  0.3951475734579648\n",
            "the loss for epoch 160 is  0.395147573127979\n",
            "the loss for epoch 161 is  0.39514757282763063\n",
            "the loss for epoch 162 is  0.3951475725542577\n",
            "the loss for epoch 163 is  0.395147572305437\n",
            "the loss for epoch 164 is  0.39514757207896317\n",
            "the loss for epoch 165 is  0.39514757187282934\n",
            "the loss for epoch 166 is  0.39514757168520825\n",
            "the loss for epoch 167 is  0.39514757151443747\n",
            "the loss for epoch 168 is  0.39514757135900314\n",
            "the loss for epoch 169 is  0.3951475712175282\n",
            "the loss for epoch 170 is  0.39514757108875853\n",
            "the loss for epoch 171 is  0.39514757097155323\n",
            "the loss for epoch 172 is  0.3951475708648736\n",
            "the loss for epoch 173 is  0.3951475707677743\n",
            "the loss for epoch 174 is  0.3951475706793949\n",
            "the loss for epoch 175 is  0.3951475705989521\n",
            "the loss for epoch 176 is  0.3951475705257334\n",
            "the loss for epoch 177 is  0.3951475704590899\n",
            "the loss for epoch 178 is  0.395147570398431\n",
            "the loss for epoch 179 is  0.3951475703432192\n",
            "the loss for epoch 180 is  0.39514757029296554\n",
            "the loss for epoch 181 is  0.3951475702472245\n",
            "the loss for epoch 182 is  0.39514757020559094\n",
            "the loss for epoch 183 is  0.39514757016769597\n",
            "the loss for epoch 184 is  0.39514757013320384\n",
            "the loss for epoch 185 is  0.395147570101809\n",
            "the loss for epoch 186 is  0.3951475700732332\n",
            "the loss for epoch 187 is  0.39514757004722345\n",
            "the loss for epoch 188 is  0.3951475700235492\n",
            "the loss for epoch 189 is  0.39514757000200085\n",
            "the loss for epoch 190 is  0.3951475699823872\n",
            "the loss for epoch 191 is  0.3951475699645348\n",
            "the loss for epoch 192 is  0.3951475699482854\n",
            "the loss for epoch 193 is  0.3951475699334952\n",
            "the loss for epoch 194 is  0.3951475699200328\n",
            "the loss for epoch 195 is  0.39514756990777933\n",
            "the loss for epoch 196 is  0.395147569896626\n",
            "the loss for epoch 197 is  0.3951475698864741\n",
            "the loss for epoch 198 is  0.3951475698772338\n",
            "the loss for epoch 199 is  0.39514756986882327\n",
            "the loss for epoch 200 is  0.3951475698611677\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = perceptron_model(learning_rate=0.9)\n",
        "model.train( data[: , :-1] , data[: ,-1])\n",
        "# the loss for epoch 200 is  0.39514757042074466\n",
        "# the loss for epoch 200 is  0.39514756978355536\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65aec707-7527-4607-b48d-4442b9e58060",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "65aec707-7527-4607-b48d-4442b9e58060"
      },
      "source": [
        "# 2. BACKPROPAGATING GRADIENTS THROUGH TIME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5dfa85f-b12b-4a3f-93b5-6135c981c9b7",
      "metadata": {
        "id": "a5dfa85f-b12b-4a3f-93b5-6135c981c9b7"
      },
      "outputs": [],
      "source": [
        "class RNN:\n",
        "    \"\"\"\n",
        "    RNN implementation from staudemeyer et al\n",
        "    \"\"\"\n",
        "    def __init__(self, learning_rate=0.5 , epochs=1000, hidden_units=10 ):\n",
        "        self.learning_rate= learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.hidden_units = hidden_units\n",
        "        self.cache= defaultdict(list)\n",
        "\n",
        "    def sigmoid(self , X):\n",
        "        return 1 / ( 1 + np.exp(-X))\n",
        "\n",
        "    def loss(self , y_true , y_pred ):\n",
        "\n",
        "        n = self.input_size[0]\n",
        "\n",
        "        e = y_true - y_pred\n",
        "\n",
        "        loss = 1/(2 * n ) * np.sum( np.square( e ))\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def weight_update(self):\n",
        "\n",
        "        error_t  = 1/self.input_size[0] * self.cache[\"activations\"][-1] * (1 - self.cache[\"activations\"][-1] ) * ( self.Y[-1] - self.cache[\"activations\"][-1] )\n",
        "\n",
        "        delta_Wi = np.zeros( ( self.hidden_units , self.input_size[1] ) )\n",
        "\n",
        "        delta_Wc = np.zeros( (self.hidden_units , self.hidden_units) )\n",
        "\n",
        "        #Note to self, this can be replaced with np.outer\n",
        "\n",
        "        for i,u in enumerate(error_t):\n",
        "\n",
        "            #for each hidden unit sum up product of recurrent connections and respective unit error signal at that specific timestep. so we get an H size matrix containing sums of error signal into all previous inputs\n",
        "\n",
        "            delta_Wc[i] += ( u * self.cache[\"activations\"][-2] )\n",
        "\n",
        "            delta_Wi[i] += ( u * self.X[-2] )\n",
        "\n",
        "        for timestep in range( self.input_size[0]-2,0,-1  ):\n",
        "\n",
        "            error_t = 1/self.input_size[0] * self.cache[\"activations\"][timestep-1] * (1 - self.cache[\"activations\"][timestep-1] ) * np.dot( self.context_weights , error_t )\n",
        "\n",
        "            for i,u in enumerate(error_t):\n",
        "\n",
        "                delta_Wc[i] += ( u * self.cache[\"activations\"][timestep-1] )\n",
        "\n",
        "                delta_Wi[i] += ( u * self.X[timestep-1] )\n",
        "\n",
        "\n",
        "        self.input_weights += ( self.learning_rate * delta_Wi )\n",
        "\n",
        "        self.context_weights += ( self.learning_rate *  delta_Wc )\n",
        "\n",
        "\n",
        "\n",
        "    def train(self , X , Y ):\n",
        "        self.cache.clear()\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        self.input_size = self.X.shape\n",
        "\n",
        "        # Glorot initialisation\n",
        "        self.input_weights = np.random.randn(self.hidden_units, self.input_size[1]) * np.sqrt(1.0 / self.input_size[1])\n",
        "\n",
        "        self.context_weights = np.random.randn(self.hidden_units, self.hidden_units) * np.sqrt(1.0 / self.hidden_units)\n",
        "\n",
        "        self.epoch_loss=[]\n",
        "\n",
        "        training_counter = 1\n",
        "\n",
        "        step = self.epochs // 100\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            self.cache.clear()\n",
        "            activation = np.zeros( self.hidden_units, )\n",
        "            for timestep in range( self.input_size[0] ):\n",
        "                state = np.dot(self.context_weights , activation  ) + np.dot(   self.input_weights, self.X[timestep]   )\n",
        "                activation = self.sigmoid( state )\n",
        "                self.cache[\"states\"].append( state )\n",
        "                self.cache[\"activations\"].append(activation)\n",
        "                self.cache[\"Losses\"].append( self.loss( self.Y[timestep] , activation ) )\n",
        "            self.weight_update()\n",
        "            self.epoch_loss.append( np.sum( self.cache[\"Losses\"] ) / self.input_size[0] / self.hidden_units )\n",
        "            if epoch+1 == training_counter * step:\n",
        "                print( \"[\", \"=\" *training_counter, \"]\" , f\" the loss for epoch {1+epoch} is  {  self.epoch_loss[-1] }\" )\n",
        "                training_counter +=1\n",
        "        plt.plot( range(self.epochs) , self.epoch_loss )\n",
        "        plt.xlabel('X-axis ,  epochs')\n",
        "        plt.ylabel('Y-axis ,  Loss')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83783fc2-7a62-48e2-8649-e0997233252e",
      "metadata": {
        "id": "83783fc2-7a62-48e2-8649-e0997233252e"
      },
      "outputs": [],
      "source": [
        "rnn = RNN(learning_rate=8e-1,epochs=800)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de4c7cd9-96ed-454c-a724-42fbfb1ed78b",
      "metadata": {
        "id": "de4c7cd9-96ed-454c-a724-42fbfb1ed78b"
      },
      "outputs": [],
      "source": [
        "# np.random.seed(42)\n",
        "# X = np.random.lognormal( 9 , 45 , size=[400 , 6] )\n",
        "# Y = np.dot(X , np.random.lognormal( 1 , 4 , size=6 ))\n",
        "# data = pd.DataFrame(X)\n",
        "# data[: ,-1] = Y\n",
        "# scaler = StandardScaler()\n",
        "# data = scaler.fit_transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45f9416e-02a9-47d7-988c-c5684255781f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "45f9416e-02a9-47d7-988c-c5684255781f",
        "outputId": "aab9bca1-de59-4c4b-eb65-39148d6bd100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ = ]  the loss for epoch 8 is  0.008476875776808755\n",
            "[ == ]  the loss for epoch 16 is  0.00842978976296081\n",
            "[ === ]  the loss for epoch 24 is  0.008384281080065082\n",
            "[ ==== ]  the loss for epoch 32 is  0.008340303818997887\n",
            "[ ===== ]  the loss for epoch 40 is  0.008297809923251267\n",
            "[ ====== ]  the loss for epoch 48 is  0.008256750004170066\n",
            "[ ======= ]  the loss for epoch 56 is  0.008217074014043757\n",
            "[ ======== ]  the loss for epoch 64 is  0.008178731797152745\n",
            "[ ========= ]  the loss for epoch 72 is  0.008141673536435013\n",
            "[ ========== ]  the loss for epoch 80 is  0.0081058501111495\n",
            "[ =========== ]  the loss for epoch 88 is  0.008071213378857453\n",
            "[ ============ ]  the loss for epoch 96 is  0.00803771639324535\n",
            "[ ============= ]  the loss for epoch 104 is  0.008005313567760745\n",
            "[ ============== ]  the loss for epoch 112 is  0.00797396079369672\n",
            "[ =============== ]  the loss for epoch 120 is  0.007943615520209096\n",
            "[ ================ ]  the loss for epoch 128 is  0.007914236802751735\n",
            "[ ================= ]  the loss for epoch 136 is  0.007885785325543555\n",
            "[ ================== ]  the loss for epoch 144 is  0.00785822340291498\n",
            "[ =================== ]  the loss for epoch 152 is  0.00783151496370559\n",
            "[ ==================== ]  the loss for epoch 160 is  0.007805625522286727\n",
            "[ ===================== ]  the loss for epoch 168 is  0.007780522139252968\n",
            "[ ====================== ]  the loss for epoch 176 is  0.007756173374358202\n",
            "[ ======================= ]  the loss for epoch 184 is  0.007732549233859043\n",
            "[ ======================== ]  the loss for epoch 192 is  0.007709621114065708\n",
            "[ ========================= ]  the loss for epoch 200 is  0.007687361742583929\n",
            "[ ========================== ]  the loss for epoch 208 is  0.007665745118456494\n",
            "[ =========================== ]  the loss for epoch 216 is  0.007644746452175955\n",
            "[ ============================ ]  the loss for epoch 224 is  0.007624342106336876\n",
            "[ ============================= ]  the loss for epoch 232 is  0.007604509537523665\n",
            "[ ============================== ]  the loss for epoch 240 is  0.007585227239884279\n",
            "[ =============================== ]  the loss for epoch 248 is  0.007566474690718776\n",
            "[ ================================ ]  the loss for epoch 256 is  0.00754823229831094\n",
            "[ ================================= ]  the loss for epoch 264 is  0.007530481352148828\n",
            "[ ================================== ]  the loss for epoch 272 is  0.007513203975613318\n",
            "[ =================================== ]  the loss for epoch 280 is  0.007496383081160582\n",
            "[ ==================================== ]  the loss for epoch 288 is  0.007480002327982296\n",
            "[ ===================================== ]  the loss for epoch 296 is  0.007464046082095499\n",
            "[ ====================================== ]  the loss for epoch 304 is  0.0074484993787894\n",
            "[ ======================================= ]  the loss for epoch 312 is  0.007433347887339256\n",
            "[ ======================================== ]  the loss for epoch 320 is  0.007418577877885043\n",
            "[ ========================================= ]  the loss for epoch 328 is  0.007404176190365178\n",
            "[ ========================================== ]  the loss for epoch 336 is  0.0073901302053912725\n",
            "[ =========================================== ]  the loss for epoch 344 is  0.007376427816948786\n",
            "[ ============================================ ]  the loss for epoch 352 is  0.007363057406809062\n",
            "[ ============================================= ]  the loss for epoch 360 is  0.007350007820540999\n",
            "[ ============================================== ]  the loss for epoch 368 is  0.007337268345014211\n",
            "[ =============================================== ]  the loss for epoch 376 is  0.007324828687290235\n",
            "[ ================================================ ]  the loss for epoch 384 is  0.007312678954803549\n",
            "[ ================================================= ]  the loss for epoch 392 is  0.00730080963673971\n",
            "[ ================================================== ]  the loss for epoch 400 is  0.007289211586523714\n",
            "[ =================================================== ]  the loss for epoch 408 is  0.007277876005337444\n",
            "[ ==================================================== ]  the loss for epoch 416 is  0.007266794426590735\n",
            "[ ===================================================== ]  the loss for epoch 424 is  0.007255958701276197\n",
            "[ ====================================================== ]  the loss for epoch 432 is  0.007245360984143208\n",
            "[ ======================================================= ]  the loss for epoch 440 is  0.007234993720631524\n",
            "[ ======================================================== ]  the loss for epoch 448 is  0.007224849634509837\n",
            "[ ========================================================= ]  the loss for epoch 456 is  0.0072149217161689705\n",
            "[ ========================================================== ]  the loss for epoch 464 is  0.007205203211523554\n",
            "[ =========================================================== ]  the loss for epoch 472 is  0.007195687611480081\n",
            "[ ============================================================ ]  the loss for epoch 480 is  0.0071863686419325196\n",
            "[ ============================================================= ]  the loss for epoch 488 is  0.007177240254250148\n",
            "[ ============================================================== ]  the loss for epoch 496 is  0.0071682966162252195\n",
            "[ =============================================================== ]  the loss for epoch 504 is  0.00715953210345073\n",
            "[ ================================================================ ]  the loss for epoch 512 is  0.007150941291101209\n",
            "[ ================================================================= ]  the loss for epoch 520 is  0.0071425189460915615\n",
            "[ ================================================================== ]  the loss for epoch 528 is  0.007134260019591195\n",
            "[ =================================================================== ]  the loss for epoch 536 is  0.007126159639872407\n",
            "[ ==================================================================== ]  the loss for epoch 544 is  0.007118213105473878\n",
            "[ ===================================================================== ]  the loss for epoch 552 is  0.00711041587866139\n",
            "[ ====================================================================== ]  the loss for epoch 560 is  0.007102763579169566\n",
            "[ ======================================================================= ]  the loss for epoch 568 is  0.007095251978209466\n",
            "[ ======================================================================== ]  the loss for epoch 576 is  0.0070878769927280845\n",
            "[ ========================================================================= ]  the loss for epoch 584 is  0.007080634679906848\n",
            "[ ========================================================================== ]  the loss for epoch 592 is  0.007073521231887087\n",
            "[ =========================================================================== ]  the loss for epoch 600 is  0.007066532970711303\n",
            "[ ============================================================================ ]  the loss for epoch 608 is  0.007059666343469854\n",
            "[ ============================================================================= ]  the loss for epoch 616 is  0.007052917917643309\n",
            "[ ============================================================================== ]  the loss for epoch 624 is  0.007046284376631387\n",
            "[ =============================================================================== ]  the loss for epoch 632 is  0.007039762515459967\n",
            "[ ================================================================================ ]  the loss for epoch 640 is  0.007033349236658146\n",
            "[ ================================================================================= ]  the loss for epoch 648 is  0.00702704154629782\n",
            "[ ================================================================================== ]  the loss for epoch 656 is  0.007020836550188666\n",
            "[ =================================================================================== ]  the loss for epoch 664 is  0.007014731450221875\n",
            "[ ==================================================================================== ]  the loss for epoch 672 is  0.007008723540856203\n",
            "[ ===================================================================================== ]  the loss for epoch 680 is  0.0070028102057404186\n",
            "[ ====================================================================================== ]  the loss for epoch 688 is  0.0069969889144664175\n",
            "[ ======================================================================================= ]  the loss for epoch 696 is  0.00699125721944757\n",
            "[ ======================================================================================== ]  the loss for epoch 704 is  0.006985612752917194\n",
            "[ ========================================================================================= ]  the loss for epoch 712 is  0.006980053224042227\n",
            "[ ========================================================================================== ]  the loss for epoch 720 is  0.006974576416147451\n",
            "[ =========================================================================================== ]  the loss for epoch 728 is  0.006969180184045802\n",
            "[ ============================================================================================ ]  the loss for epoch 736 is  0.006963862451470506\n",
            "[ ============================================================================================= ]  the loss for epoch 744 is  0.006958621208605004\n",
            "[ ============================================================================================== ]  the loss for epoch 752 is  0.006953454509706751\n",
            "[ =============================================================================================== ]  the loss for epoch 760 is  0.006948360470821205\n",
            "[ ================================================================================================ ]  the loss for epoch 768 is  0.006943337267582411\n",
            "[ ================================================================================================= ]  the loss for epoch 776 is  0.006938383133096815\n",
            "[ ================================================================================================== ]  the loss for epoch 784 is  0.006933496355906994\n",
            "[ =================================================================================================== ]  the loss for epoch 792 is  0.006928675278032219\n",
            "[ ==================================================================================================== ]  the loss for epoch 800 is  0.0069239182930828065\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "rnn.train( data[: , :-1] , data[: ,-1] )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ts_data= pd.DataFrame(X)\n",
        "ts_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vog1TndmCm6-",
        "outputId": "777f9337-f3c4-4acd-c5d0-3b83c82e1c00"
      },
      "id": "vog1TndmCm6-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              0             1             2             3             4  \\\n",
              "0  4.131046e+13  1.608853e+01  3.686298e+16  4.716351e+33  2.150463e-01   \n",
              "1  5.910223e+34  8.069013e+18  5.414948e-06  3.251156e+14  7.111508e-06   \n",
              "2  4.338903e+08  3.288009e-34  1.578145e-30  8.312346e-08  1.302078e-16   \n",
              "3  1.455148e-14  2.030690e-24  3.566097e+32  3.135070e-01  1.691886e+05   \n",
              "4  1.860552e-07  1.192445e+06  2.597127e-19  1.782425e+11  1.479848e-08   \n",
              "\n",
              "              5  \n",
              "0  2.152052e-01  \n",
              "1  6.408797e-06  \n",
              "2  1.122187e+10  \n",
              "3  1.159946e-24  \n",
              "4  1.614381e-02  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20e8abac-44e0-45eb-b097-44336b1567ed\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.131046e+13</td>\n",
              "      <td>1.608853e+01</td>\n",
              "      <td>3.686298e+16</td>\n",
              "      <td>4.716351e+33</td>\n",
              "      <td>2.150463e-01</td>\n",
              "      <td>2.152052e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.910223e+34</td>\n",
              "      <td>8.069013e+18</td>\n",
              "      <td>5.414948e-06</td>\n",
              "      <td>3.251156e+14</td>\n",
              "      <td>7.111508e-06</td>\n",
              "      <td>6.408797e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.338903e+08</td>\n",
              "      <td>3.288009e-34</td>\n",
              "      <td>1.578145e-30</td>\n",
              "      <td>8.312346e-08</td>\n",
              "      <td>1.302078e-16</td>\n",
              "      <td>1.122187e+10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.455148e-14</td>\n",
              "      <td>2.030690e-24</td>\n",
              "      <td>3.566097e+32</td>\n",
              "      <td>3.135070e-01</td>\n",
              "      <td>1.691886e+05</td>\n",
              "      <td>1.159946e-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.860552e-07</td>\n",
              "      <td>1.192445e+06</td>\n",
              "      <td>2.597127e-19</td>\n",
              "      <td>1.782425e+11</td>\n",
              "      <td>1.479848e-08</td>\n",
              "      <td>1.614381e-02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20e8abac-44e0-45eb-b097-44336b1567ed')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-20e8abac-44e0-45eb-b097-44336b1567ed button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-20e8abac-44e0-45eb-b097-44336b1567ed');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f113f365-6e44-4264-b81f-d9e6d8ad682b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f113f365-6e44-4264-b81f-d9e6d8ad682b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f113f365-6e44-4264-b81f-d9e6d8ad682b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ts_data",
              "summary": "{\n  \"name\": \"ts_data\",\n  \"rows\": 80,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.700839374069463e+45,\n        \"min\": 2.6818288827888172e-30,\n        \"max\": 5.064309076630638e+46,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          1.3684369300554334e+16,\n          41310461359606.6,\n          1.4053402766149817e-17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4341985670182218e+39,\n        \"min\": 1.1616914594617484e-35,\n        \"max\": 1.2828890221013167e+40,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          1.4355042341726838e-13,\n          16.08852761181757,\n          14594405387709.857\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1699910253219573e+45,\n        \"min\": 5.1323045055907595e-48,\n        \"max\": 9.746238379029789e+45,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          9.54835855958911e-18,\n          3.686298089210936e+16,\n          8.711864692878117e-15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.2335931143411263e+39,\n        \"min\": 8.348830695991992e-42,\n        \"max\": 3.7594927634097145e+40,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          21763572154241.59,\n          4.716351293221101e+33,\n          1.582736109134116e+34\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3441504859206468e+63,\n        \"min\": 3.662241078428268e-60,\n        \"max\": 1.2022447434031763e+64,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          0.34790516884469186,\n          0.2150463134729476,\n          3.99331998275853e-12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7865144887678282e+78,\n        \"min\": 1.1361159100414841e-36,\n        \"max\": 1.5979071358692623e+79,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          7.286881328944776e+17,\n          0.215205248357592,\n          0.004116433156693826\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ts = ts_data.shift(1) + ts_data\n",
        "ts /= 2\n",
        "ts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Jsypbn9_MAeX",
        "outputId": "4f4dde9c-ad8c-49ba-a71a-ebffa13d34d6"
      },
      "id": "Jsypbn9_MAeX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               0             1             2             3             4  \\\n",
              "0            NaN           NaN           NaN           NaN           NaN   \n",
              "1   2.955111e+34  4.034506e+18  1.843149e+16  2.358176e+33  1.075267e-01   \n",
              "2   2.955111e+34  4.034506e+18  2.707474e-06  1.625578e+14  3.555754e-06   \n",
              "3   2.169451e+08  1.015345e-24  1.783048e+32  1.567536e-01  8.459429e+04   \n",
              "4   9.302759e-08  5.962226e+05  1.783048e+32  8.912125e+10  8.459429e+04   \n",
              "..           ...           ...           ...           ...           ...   \n",
              "75  2.413609e+02  1.880218e+22  5.917553e+10  2.872951e+13  5.429294e-07   \n",
              "76  2.741628e+02  1.880213e+22  6.130736e-08  2.872951e+13  1.010970e+42   \n",
              "77  3.280191e+01  6.158623e+07  2.584431e+01  1.946058e-01  1.010970e+42   \n",
              "78  1.738269e-07  6.158623e+07  2.586138e+01  1.946058e-01  4.077883e+15   \n",
              "79  5.696897e+35  5.503596e-02  7.506166e+14  4.902984e+09  6.011224e+63   \n",
              "\n",
              "               5  \n",
              "0            NaN  \n",
              "1   1.076058e-01  \n",
              "2   5.610933e+09  \n",
              "3   5.610933e+09  \n",
              "4   8.071904e-03  \n",
              "..           ...  \n",
              "75  1.295119e-12  \n",
              "76  1.980545e+04  \n",
              "77  2.580977e+18  \n",
              "78  2.093091e+30  \n",
              "79  2.093122e+30  \n",
              "\n",
              "[80 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51b5c918-2ecc-457c-8567-5fb8211556ea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.955111e+34</td>\n",
              "      <td>4.034506e+18</td>\n",
              "      <td>1.843149e+16</td>\n",
              "      <td>2.358176e+33</td>\n",
              "      <td>1.075267e-01</td>\n",
              "      <td>1.076058e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.955111e+34</td>\n",
              "      <td>4.034506e+18</td>\n",
              "      <td>2.707474e-06</td>\n",
              "      <td>1.625578e+14</td>\n",
              "      <td>3.555754e-06</td>\n",
              "      <td>5.610933e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.169451e+08</td>\n",
              "      <td>1.015345e-24</td>\n",
              "      <td>1.783048e+32</td>\n",
              "      <td>1.567536e-01</td>\n",
              "      <td>8.459429e+04</td>\n",
              "      <td>5.610933e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.302759e-08</td>\n",
              "      <td>5.962226e+05</td>\n",
              "      <td>1.783048e+32</td>\n",
              "      <td>8.912125e+10</td>\n",
              "      <td>8.459429e+04</td>\n",
              "      <td>8.071904e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>2.413609e+02</td>\n",
              "      <td>1.880218e+22</td>\n",
              "      <td>5.917553e+10</td>\n",
              "      <td>2.872951e+13</td>\n",
              "      <td>5.429294e-07</td>\n",
              "      <td>1.295119e-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>2.741628e+02</td>\n",
              "      <td>1.880213e+22</td>\n",
              "      <td>6.130736e-08</td>\n",
              "      <td>2.872951e+13</td>\n",
              "      <td>1.010970e+42</td>\n",
              "      <td>1.980545e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>3.280191e+01</td>\n",
              "      <td>6.158623e+07</td>\n",
              "      <td>2.584431e+01</td>\n",
              "      <td>1.946058e-01</td>\n",
              "      <td>1.010970e+42</td>\n",
              "      <td>2.580977e+18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>1.738269e-07</td>\n",
              "      <td>6.158623e+07</td>\n",
              "      <td>2.586138e+01</td>\n",
              "      <td>1.946058e-01</td>\n",
              "      <td>4.077883e+15</td>\n",
              "      <td>2.093091e+30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>5.696897e+35</td>\n",
              "      <td>5.503596e-02</td>\n",
              "      <td>7.506166e+14</td>\n",
              "      <td>4.902984e+09</td>\n",
              "      <td>6.011224e+63</td>\n",
              "      <td>2.093122e+30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51b5c918-2ecc-457c-8567-5fb8211556ea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-51b5c918-2ecc-457c-8567-5fb8211556ea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-51b5c918-2ecc-457c-8567-5fb8211556ea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-deec1507-3f2f-41b1-af4c-173e67f8de1a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-deec1507-3f2f-41b1-af4c-173e67f8de1a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-deec1507-3f2f-41b1-af4c-173e67f8de1a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_09d89c76-e26a-4052-a70d-df9ab0d47e33\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('ts')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_09d89c76-e26a-4052-a70d-df9ab0d47e33 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('ts');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ts",
              "summary": "{\n  \"name\": \"ts\",\n  \"rows\": 80,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.020683883659388e+45,\n        \"min\": 1.3003030576708091e-22,\n        \"max\": 2.532154538315328e+46,\n        \"num_unique_values\": 69,\n        \"samples\": [\n          804399194.1055608,\n          2.955111419243911e+34,\n          2334.9553347396713\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0137947027287717e+39,\n        \"min\": 1.0153450356922068e-24,\n        \"max\": 6.414445110506583e+39,\n        \"num_unique_values\": 67,\n        \"samples\": [\n          5.57812974948218e+18,\n          3.4699352313570186e-08,\n          0.005285365616166924\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.233068989766365e+44,\n        \"min\": 4.477614403798695e-23,\n        \"max\": 4.8731191895148944e+45,\n        \"num_unique_values\": 64,\n        \"samples\": [\n          23.39588284848099,\n          189045297478.7133,\n          1.843149044605468e+16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.184144345760139e+39,\n        \"min\": 5.859537771353713e-20,\n        \"max\": 2.131096998007693e+40,\n        \"num_unique_values\": 72,\n        \"samples\": [\n          89121250529.01974,\n          6.288919953150146e+27,\n          5.859537771353713e-20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.763155073774128e+62,\n        \"min\": 1.5047328861908964e-20,\n        \"max\": 6.0112237170158815e+63,\n        \"num_unique_values\": 69,\n        \"samples\": [\n          64279182229027.47,\n          0.10752671249070292,\n          4.619880853660417e+22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2630514855104069e+78,\n        \"min\": 4.324642299420083e-24,\n        \"max\": 7.989535679346312e+78,\n        \"num_unique_values\": 65,\n        \"samples\": [\n          2.765646283570351e-06,\n          1.2951191757838974e-12,\n          0.10760582857751867\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = np.mean(ts,axis=1)\n",
        "Y[0] = np.mean(X[0])\n",
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "DrbaXFX1ZNJi",
        "outputId": "a18f3460-df06-4a37-ad2a-33cfc4899c75"
      },
      "id": "DrbaXFX1ZNJi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     7.860585e+32\n",
              "1     5.318215e+33\n",
              "2     4.925186e+33\n",
              "3     2.971747e+31\n",
              "4     2.971747e+31\n",
              "          ...     \n",
              "75    3.133697e+21\n",
              "76    1.684949e+41\n",
              "77    1.684949e+41\n",
              "78    3.488486e+29\n",
              "79    1.001871e+63\n",
              "Length: 80, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.860585e+32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.318215e+33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.925186e+33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.971747e+31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.971747e+31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>3.133697e+21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>1.684949e+41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>1.684949e+41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>3.488486e+29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>1.001871e+63</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ts.iloc[0,:] = X[0,]\n",
        "ts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "N2LUGTTqVP35",
        "outputId": "50edbbc3-9833-4a4e-f51a-78c0d09dc570"
      },
      "id": "N2LUGTTqVP35",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               0             1             2             3             4  \\\n",
              "0   4.131046e+13  1.608853e+01  3.686298e+16  4.716351e+33  2.150463e-01   \n",
              "1   2.955111e+34  4.034506e+18  1.843149e+16  2.358176e+33  1.075267e-01   \n",
              "2   2.955111e+34  4.034506e+18  2.707474e-06  1.625578e+14  3.555754e-06   \n",
              "3   2.169451e+08  1.015345e-24  1.783048e+32  1.567536e-01  8.459429e+04   \n",
              "4   9.302759e-08  5.962226e+05  1.783048e+32  8.912125e+10  8.459429e+04   \n",
              "..           ...           ...           ...           ...           ...   \n",
              "75  2.413609e+02  1.880218e+22  5.917553e+10  2.872951e+13  5.429294e-07   \n",
              "76  2.741628e+02  1.880213e+22  6.130736e-08  2.872951e+13  1.010970e+42   \n",
              "77  3.280191e+01  6.158623e+07  2.584431e+01  1.946058e-01  1.010970e+42   \n",
              "78  1.738269e-07  6.158623e+07  2.586138e+01  1.946058e-01  4.077883e+15   \n",
              "79  5.696897e+35  5.503596e-02  7.506166e+14  4.902984e+09  6.011224e+63   \n",
              "\n",
              "               5  \n",
              "0   2.152052e-01  \n",
              "1   1.076058e-01  \n",
              "2   5.610933e+09  \n",
              "3   5.610933e+09  \n",
              "4   8.071904e-03  \n",
              "..           ...  \n",
              "75  1.295119e-12  \n",
              "76  1.980545e+04  \n",
              "77  2.580977e+18  \n",
              "78  2.093091e+30  \n",
              "79  2.093122e+30  \n",
              "\n",
              "[80 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86a96e4e-d1df-408d-b990-e1e1e88ba9b1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.131046e+13</td>\n",
              "      <td>1.608853e+01</td>\n",
              "      <td>3.686298e+16</td>\n",
              "      <td>4.716351e+33</td>\n",
              "      <td>2.150463e-01</td>\n",
              "      <td>2.152052e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.955111e+34</td>\n",
              "      <td>4.034506e+18</td>\n",
              "      <td>1.843149e+16</td>\n",
              "      <td>2.358176e+33</td>\n",
              "      <td>1.075267e-01</td>\n",
              "      <td>1.076058e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.955111e+34</td>\n",
              "      <td>4.034506e+18</td>\n",
              "      <td>2.707474e-06</td>\n",
              "      <td>1.625578e+14</td>\n",
              "      <td>3.555754e-06</td>\n",
              "      <td>5.610933e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.169451e+08</td>\n",
              "      <td>1.015345e-24</td>\n",
              "      <td>1.783048e+32</td>\n",
              "      <td>1.567536e-01</td>\n",
              "      <td>8.459429e+04</td>\n",
              "      <td>5.610933e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.302759e-08</td>\n",
              "      <td>5.962226e+05</td>\n",
              "      <td>1.783048e+32</td>\n",
              "      <td>8.912125e+10</td>\n",
              "      <td>8.459429e+04</td>\n",
              "      <td>8.071904e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>2.413609e+02</td>\n",
              "      <td>1.880218e+22</td>\n",
              "      <td>5.917553e+10</td>\n",
              "      <td>2.872951e+13</td>\n",
              "      <td>5.429294e-07</td>\n",
              "      <td>1.295119e-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>2.741628e+02</td>\n",
              "      <td>1.880213e+22</td>\n",
              "      <td>6.130736e-08</td>\n",
              "      <td>2.872951e+13</td>\n",
              "      <td>1.010970e+42</td>\n",
              "      <td>1.980545e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>3.280191e+01</td>\n",
              "      <td>6.158623e+07</td>\n",
              "      <td>2.584431e+01</td>\n",
              "      <td>1.946058e-01</td>\n",
              "      <td>1.010970e+42</td>\n",
              "      <td>2.580977e+18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>1.738269e-07</td>\n",
              "      <td>6.158623e+07</td>\n",
              "      <td>2.586138e+01</td>\n",
              "      <td>1.946058e-01</td>\n",
              "      <td>4.077883e+15</td>\n",
              "      <td>2.093091e+30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>5.696897e+35</td>\n",
              "      <td>5.503596e-02</td>\n",
              "      <td>7.506166e+14</td>\n",
              "      <td>4.902984e+09</td>\n",
              "      <td>6.011224e+63</td>\n",
              "      <td>2.093122e+30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86a96e4e-d1df-408d-b990-e1e1e88ba9b1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-86a96e4e-d1df-408d-b990-e1e1e88ba9b1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-86a96e4e-d1df-408d-b990-e1e1e88ba9b1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-27c95a67-f96c-40de-8793-f252da619d1e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-27c95a67-f96c-40de-8793-f252da619d1e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-27c95a67-f96c-40de-8793-f252da619d1e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_97acdaee-5ada-4541-897d-eb17c8220f18\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('ts')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_97acdaee-5ada-4541-897d-eb17c8220f18 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('ts');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ts",
              "summary": "{\n  \"name\": \"ts\",\n  \"rows\": 80,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.996046940445547e+45,\n        \"min\": 1.3003030576708091e-22,\n        \"max\": 2.532154538315328e+46,\n        \"num_unique_values\": 70,\n        \"samples\": [\n          3.2091651781420683e+19,\n          41310461359606.6,\n          248349731.7361867\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0075256457450246e+39,\n        \"min\": 1.0153450356922068e-24,\n        \"max\": 6.414445110506583e+39,\n        \"num_unique_values\": 68,\n        \"samples\": [\n          11.593161204173759,\n          3168370403.79134,\n          6.414445110506583e+39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.183086327397696e+44,\n        \"min\": 4.477614403798695e-23,\n        \"max\": 4.8731191895148944e+45,\n        \"num_unique_values\": 65,\n        \"samples\": [\n          23.39588284848099,\n          59175526745.752846,\n          3.686298089210936e+16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.164502287321019e+39,\n        \"min\": 5.859537771353713e-20,\n        \"max\": 2.131096998007693e+40,\n        \"num_unique_values\": 73,\n        \"samples\": [\n          89121250529.1765,\n          6.288919953150146e+27,\n          1228.7202065698707\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.720752429603234e+62,\n        \"min\": 1.5047328861908964e-20,\n        \"max\": 6.0112237170158815e+63,\n        \"num_unique_values\": 70,\n        \"samples\": [\n          64277018467227.586,\n          0.2150463134729476,\n          4.619880215468928e+22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2552357523514228e+78,\n        \"min\": 4.324642299420083e-24,\n        \"max\": 7.989535679346312e+78,\n        \"num_unique_values\": 66,\n        \"samples\": [\n          2.765646283570351e-06,\n          19805.454492569563,\n          0.215205248357592\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ts.insert(len(ts.columns),len(ts.columns),Y)\n",
        "ts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ALSlTzl_VpFZ",
        "outputId": "37e411a6-9889-433d-ecce-fe134a2dfc5e"
      },
      "id": "ALSlTzl_VpFZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               0             1             2             3             4  \\\n",
              "0   4.131046e+13  1.608853e+01  3.686298e+16  4.716351e+33  2.150463e-01   \n",
              "1   2.955111e+34  4.034506e+18  1.843149e+16  2.358176e+33  1.075267e-01   \n",
              "2   2.955111e+34  4.034506e+18  2.707474e-06  1.625578e+14  3.555754e-06   \n",
              "3   2.169451e+08  1.015345e-24  1.783048e+32  1.567536e-01  8.459429e+04   \n",
              "4   9.302759e-08  5.962226e+05  1.783048e+32  8.912125e+10  8.459429e+04   \n",
              "..           ...           ...           ...           ...           ...   \n",
              "75  2.413609e+02  1.880218e+22  5.917553e+10  2.872951e+13  5.429294e-07   \n",
              "76  2.741628e+02  1.880213e+22  6.130736e-08  2.872951e+13  1.010970e+42   \n",
              "77  3.280191e+01  6.158623e+07  2.584431e+01  1.946058e-01  1.010970e+42   \n",
              "78  1.738269e-07  6.158623e+07  2.586138e+01  1.946058e-01  4.077883e+15   \n",
              "79  5.696897e+35  5.503596e-02  7.506166e+14  4.902984e+09  6.011224e+63   \n",
              "\n",
              "               5             6  \n",
              "0   2.152052e-01  7.860585e+32  \n",
              "1   1.076058e-01  5.318215e+33  \n",
              "2   5.610933e+09  4.925186e+33  \n",
              "3   5.610933e+09  2.971747e+31  \n",
              "4   8.071904e-03  2.971747e+31  \n",
              "..           ...           ...  \n",
              "75  1.295119e-12  3.133697e+21  \n",
              "76  1.980545e+04  1.684949e+41  \n",
              "77  2.580977e+18  1.684949e+41  \n",
              "78  2.093091e+30  3.488486e+29  \n",
              "79  2.093122e+30  1.001871e+63  \n",
              "\n",
              "[80 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41f8fc28-dc72-41ad-b9f0-05a7b1c4f207\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.131046e+13</td>\n",
              "      <td>1.608853e+01</td>\n",
              "      <td>3.686298e+16</td>\n",
              "      <td>4.716351e+33</td>\n",
              "      <td>2.150463e-01</td>\n",
              "      <td>2.152052e-01</td>\n",
              "      <td>7.860585e+32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.955111e+34</td>\n",
              "      <td>4.034506e+18</td>\n",
              "      <td>1.843149e+16</td>\n",
              "      <td>2.358176e+33</td>\n",
              "      <td>1.075267e-01</td>\n",
              "      <td>1.076058e-01</td>\n",
              "      <td>5.318215e+33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.955111e+34</td>\n",
              "      <td>4.034506e+18</td>\n",
              "      <td>2.707474e-06</td>\n",
              "      <td>1.625578e+14</td>\n",
              "      <td>3.555754e-06</td>\n",
              "      <td>5.610933e+09</td>\n",
              "      <td>4.925186e+33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.169451e+08</td>\n",
              "      <td>1.015345e-24</td>\n",
              "      <td>1.783048e+32</td>\n",
              "      <td>1.567536e-01</td>\n",
              "      <td>8.459429e+04</td>\n",
              "      <td>5.610933e+09</td>\n",
              "      <td>2.971747e+31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.302759e-08</td>\n",
              "      <td>5.962226e+05</td>\n",
              "      <td>1.783048e+32</td>\n",
              "      <td>8.912125e+10</td>\n",
              "      <td>8.459429e+04</td>\n",
              "      <td>8.071904e-03</td>\n",
              "      <td>2.971747e+31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>2.413609e+02</td>\n",
              "      <td>1.880218e+22</td>\n",
              "      <td>5.917553e+10</td>\n",
              "      <td>2.872951e+13</td>\n",
              "      <td>5.429294e-07</td>\n",
              "      <td>1.295119e-12</td>\n",
              "      <td>3.133697e+21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>2.741628e+02</td>\n",
              "      <td>1.880213e+22</td>\n",
              "      <td>6.130736e-08</td>\n",
              "      <td>2.872951e+13</td>\n",
              "      <td>1.010970e+42</td>\n",
              "      <td>1.980545e+04</td>\n",
              "      <td>1.684949e+41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>3.280191e+01</td>\n",
              "      <td>6.158623e+07</td>\n",
              "      <td>2.584431e+01</td>\n",
              "      <td>1.946058e-01</td>\n",
              "      <td>1.010970e+42</td>\n",
              "      <td>2.580977e+18</td>\n",
              "      <td>1.684949e+41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>1.738269e-07</td>\n",
              "      <td>6.158623e+07</td>\n",
              "      <td>2.586138e+01</td>\n",
              "      <td>1.946058e-01</td>\n",
              "      <td>4.077883e+15</td>\n",
              "      <td>2.093091e+30</td>\n",
              "      <td>3.488486e+29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>5.696897e+35</td>\n",
              "      <td>5.503596e-02</td>\n",
              "      <td>7.506166e+14</td>\n",
              "      <td>4.902984e+09</td>\n",
              "      <td>6.011224e+63</td>\n",
              "      <td>2.093122e+30</td>\n",
              "      <td>1.001871e+63</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41f8fc28-dc72-41ad-b9f0-05a7b1c4f207')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-41f8fc28-dc72-41ad-b9f0-05a7b1c4f207 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-41f8fc28-dc72-41ad-b9f0-05a7b1c4f207');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e69dbb7e-bae6-4ef0-9a2e-b8f7fc15fdcb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e69dbb7e-bae6-4ef0-9a2e-b8f7fc15fdcb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e69dbb7e-bae6-4ef0-9a2e-b8f7fc15fdcb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_35fb5e32-7d0d-4d25-800e-4daf62474689\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('ts')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_35fb5e32-7d0d-4d25-800e-4daf62474689 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('ts');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ts",
              "summary": "{\n  \"name\": \"ts\",\n  \"rows\": 80,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.996046940445547e+45,\n        \"min\": 1.3003030576708091e-22,\n        \"max\": 2.532154538315328e+46,\n        \"num_unique_values\": 70,\n        \"samples\": [\n          3.2091651781420683e+19,\n          41310461359606.6,\n          248349731.7361867\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0075256457450246e+39,\n        \"min\": 1.0153450356922068e-24,\n        \"max\": 6.414445110506583e+39,\n        \"num_unique_values\": 68,\n        \"samples\": [\n          11.593161204173759,\n          3168370403.79134,\n          6.414445110506583e+39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.183086327397696e+44,\n        \"min\": 4.477614403798695e-23,\n        \"max\": 4.8731191895148944e+45,\n        \"num_unique_values\": 65,\n        \"samples\": [\n          23.39588284848099,\n          59175526745.752846,\n          3.686298089210936e+16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.164502287321019e+39,\n        \"min\": 5.859537771353713e-20,\n        \"max\": 2.131096998007693e+40,\n        \"num_unique_values\": 73,\n        \"samples\": [\n          89121250529.1765,\n          6.288919953150146e+27,\n          1228.7202065698707\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.720752429603234e+62,\n        \"min\": 1.5047328861908964e-20,\n        \"max\": 6.0112237170158815e+63,\n        \"num_unique_values\": 70,\n        \"samples\": [\n          64277018467227.586,\n          0.2150463134729476,\n          4.619880215468928e+22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2552357523514228e+78,\n        \"min\": 4.324642299420083e-24,\n        \"max\": 7.989535679346312e+78,\n        \"num_unique_values\": 66,\n        \"samples\": [\n          2.765646283570351e-06,\n          19805.454492569563,\n          0.215205248357592\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 6,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0920595872523723e+77,\n        \"min\": 79443656651.54543,\n        \"max\": 1.331589279891052e+78,\n        \"num_unique_values\": 69,\n        \"samples\": [\n          1.2847950973766968e+18,\n          7.860585488701836e+32,\n          2.9029303124582993e+25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_ts = scaler.fit_transform(ts)"
      ],
      "metadata": {
        "id": "XLJ2n4loWYfO"
      },
      "id": "XLJ2n4loWYfO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = RNN(learning_rate=884e-1,epochs=100,hidden_units=240)\n",
        "rnn.train(scaled_ts[:,:-1] , scaled_ts[:,-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ULeeaxjaWrB7",
        "outputId": "3867833c-49a0-48fc-eb9d-8331922a71a3"
      },
      "id": "ULeeaxjaWrB7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ = ]  the loss for epoch 1 is  0.008057636762393124\n",
            "[ == ]  the loss for epoch 2 is  0.0069477598682008345\n",
            "[ === ]  the loss for epoch 3 is  0.006853982108288168\n",
            "[ ==== ]  the loss for epoch 4 is  0.006791184755137329\n",
            "[ ===== ]  the loss for epoch 5 is  0.006747470093872564\n",
            "[ ====== ]  the loss for epoch 6 is  0.006715291391462415\n",
            "[ ======= ]  the loss for epoch 7 is  0.0066903064574946455\n",
            "[ ======== ]  the loss for epoch 8 is  0.006670170049466736\n",
            "[ ========= ]  the loss for epoch 9 is  0.0066542966359733205\n",
            "[ ========== ]  the loss for epoch 10 is  0.006641364360278651\n",
            "[ =========== ]  the loss for epoch 11 is  0.00662977384805305\n",
            "[ ============ ]  the loss for epoch 12 is  0.00661843440059632\n",
            "[ ============= ]  the loss for epoch 13 is  0.006607895041225597\n",
            "[ ============== ]  the loss for epoch 14 is  0.006598545317273746\n",
            "[ =============== ]  the loss for epoch 15 is  0.006590112632614184\n",
            "[ ================ ]  the loss for epoch 16 is  0.006582442382361539\n",
            "[ ================= ]  the loss for epoch 17 is  0.006575801095600037\n",
            "[ ================== ]  the loss for epoch 18 is  0.006569661864868015\n",
            "[ =================== ]  the loss for epoch 19 is  0.006563873368721735\n",
            "[ ==================== ]  the loss for epoch 20 is  0.006558534006202771\n",
            "[ ===================== ]  the loss for epoch 21 is  0.006553618799774776\n",
            "[ ====================== ]  the loss for epoch 22 is  0.006549045614294201\n",
            "[ ======================= ]  the loss for epoch 23 is  0.0065448281337911\n",
            "[ ======================== ]  the loss for epoch 24 is  0.0065408274581894\n",
            "[ ========================= ]  the loss for epoch 25 is  0.006537026730536455\n",
            "[ ========================== ]  the loss for epoch 26 is  0.006533413356703052\n",
            "[ =========================== ]  the loss for epoch 27 is  0.006529976962412258\n",
            "[ ============================ ]  the loss for epoch 28 is  0.006526708772400788\n",
            "[ ============================= ]  the loss for epoch 29 is  0.006523600832027807\n",
            "[ ============================== ]  the loss for epoch 30 is  0.006520644406067196\n",
            "[ =============================== ]  the loss for epoch 31 is  0.006517826051926388\n",
            "[ ================================ ]  the loss for epoch 32 is  0.006515117184045003\n",
            "[ ================================= ]  the loss for epoch 33 is  0.006512444682307209\n",
            "[ ================================== ]  the loss for epoch 34 is  0.006509647158983574\n",
            "[ =================================== ]  the loss for epoch 35 is  0.006506898747113507\n",
            "[ ==================================== ]  the loss for epoch 36 is  0.006504382090442906\n",
            "[ ===================================== ]  the loss for epoch 37 is  0.006501957588899773\n",
            "[ ====================================== ]  the loss for epoch 38 is  0.006499618412242805\n",
            "[ ======================================= ]  the loss for epoch 39 is  0.00649736069572253\n",
            "[ ======================================== ]  the loss for epoch 40 is  0.006495180881232801\n",
            "[ ========================================= ]  the loss for epoch 41 is  0.006493074999283986\n",
            "[ ========================================== ]  the loss for epoch 42 is  0.006491037445303492\n",
            "[ =========================================== ]  the loss for epoch 43 is  0.00648905610591147\n",
            "[ ============================================ ]  the loss for epoch 44 is  0.006487091152845346\n",
            "[ ============================================= ]  the loss for epoch 45 is  0.006485099987251444\n",
            "[ ============================================== ]  the loss for epoch 46 is  0.006483274210393936\n",
            "[ =============================================== ]  the loss for epoch 47 is  0.006481530442487005\n",
            "[ ================================================ ]  the loss for epoch 48 is  0.00647983113608595\n",
            "[ ================================================= ]  the loss for epoch 49 is  0.006478172635765317\n",
            "[ ================================================== ]  the loss for epoch 50 is  0.006476552853862074\n",
            "[ =================================================== ]  the loss for epoch 51 is  0.006474970114294346\n",
            "[ ==================================================== ]  the loss for epoch 52 is  0.006473422934941111\n",
            "[ ===================================================== ]  the loss for epoch 53 is  0.006471909961547887\n",
            "[ ====================================================== ]  the loss for epoch 54 is  0.006470429940202096\n",
            "[ ======================================================= ]  the loss for epoch 55 is  0.006468981702569754\n",
            "[ ======================================================== ]  the loss for epoch 56 is  0.006467564156224198\n",
            "[ ========================================================= ]  the loss for epoch 57 is  0.006466176277328371\n",
            "[ ========================================================== ]  the loss for epoch 58 is  0.006464817104528578\n",
            "[ =========================================================== ]  the loss for epoch 59 is  0.006463485733495365\n",
            "[ ============================================================ ]  the loss for epoch 60 is  0.006462181311759772\n",
            "[ ============================================================= ]  the loss for epoch 61 is  0.006460903033546763\n",
            "[ ============================================================== ]  the loss for epoch 62 is  0.0064596501342613225\n",
            "[ =============================================================== ]  the loss for epoch 63 is  0.0064584218841315265\n",
            "[ ================================================================ ]  the loss for epoch 64 is  0.006457217580193444\n",
            "[ ================================================================= ]  the loss for epoch 65 is  0.006456036535156728\n",
            "[ ================================================================== ]  the loss for epoch 66 is  0.0064548780603424045\n",
            "[ =================================================================== ]  the loss for epoch 67 is  0.006453741436911151\n",
            "[ ==================================================================== ]  the loss for epoch 68 is  0.006452625862551355\n",
            "[ ===================================================================== ]  the loss for epoch 69 is  0.006451530342575337\n",
            "[ ====================================================================== ]  the loss for epoch 70 is  0.006450453442209628\n",
            "[ ======================================================================= ]  the loss for epoch 71 is  0.006449392648916095\n",
            "[ ======================================================================== ]  the loss for epoch 72 is  0.006448342484355152\n",
            "[ ========================================================================= ]  the loss for epoch 73 is  0.0064472882395636396\n",
            "[ ========================================================================== ]  the loss for epoch 74 is  0.006446190677905941\n",
            "[ =========================================================================== ]  the loss for epoch 75 is  0.006445059806500581\n",
            "[ ============================================================================ ]  the loss for epoch 76 is  0.0064440502888265284\n",
            "[ ============================================================================= ]  the loss for epoch 77 is  0.006443084162940046\n",
            "[ ============================================================================== ]  the loss for epoch 78 is  0.006442135760803952\n",
            "[ =============================================================================== ]  the loss for epoch 79 is  0.006441202066225372\n",
            "[ ================================================================================ ]  the loss for epoch 80 is  0.00644028202096361\n",
            "[ ================================================================================= ]  the loss for epoch 81 is  0.006439375021950541\n",
            "[ ================================================================================== ]  the loss for epoch 82 is  0.006438480625005555\n",
            "[ =================================================================================== ]  the loss for epoch 83 is  0.006437598457749156\n",
            "[ ==================================================================================== ]  the loss for epoch 84 is  0.006436728187335145\n",
            "[ ===================================================================================== ]  the loss for epoch 85 is  0.00643586950641308\n",
            "[ ====================================================================================== ]  the loss for epoch 86 is  0.0064350221262074\n",
            "[ ======================================================================================= ]  the loss for epoch 87 is  0.006434185772721314\n",
            "[ ======================================================================================== ]  the loss for epoch 88 is  0.00643336018444425\n",
            "[ ========================================================================================= ]  the loss for epoch 89 is  0.006432545110838907\n",
            "[ ========================================================================================== ]  the loss for epoch 90 is  0.006431740311259109\n",
            "[ =========================================================================================== ]  the loss for epoch 91 is  0.0064309455541191355\n",
            "[ ============================================================================================ ]  the loss for epoch 92 is  0.006430160616217301\n",
            "[ ============================================================================================= ]  the loss for epoch 93 is  0.00642938528215811\n",
            "[ ============================================================================================== ]  the loss for epoch 94 is  0.006428619343839679\n",
            "[ =============================================================================================== ]  the loss for epoch 95 is  0.006427862599985321\n",
            "[ ================================================================================================ ]  the loss for epoch 96 is  0.006427114855705223\n",
            "[ ================================================================================================= ]  the loss for epoch 97 is  0.006426375922078099\n",
            "[ ================================================================================================== ]  the loss for epoch 98 is  0.0064256456157450684\n",
            "[ =================================================================================================== ]  the loss for epoch 99 is  0.0064249237585091885\n",
            "[ ==================================================================================================== ]  the loss for epoch 100 is  0.006424210176934605\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "782ceaa4-3f44-4ef1-a8ea-654208de1eb0",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "782ceaa4-3f44-4ef1-a8ea-654208de1eb0"
      },
      "source": [
        "# 3. REAL TIME RECURRENT LEARNING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f56ed82-6671-470e-8a42-13feefdb6b1d",
      "metadata": {
        "id": "6f56ed82-6671-470e-8a42-13feefdb6b1d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09352d8a-3550-46f8-95b2-63e13a808331",
      "metadata": {
        "id": "09352d8a-3550-46f8-95b2-63e13a808331"
      },
      "outputs": [],
      "source": [
        "class RNN_RTRL:\n",
        "    def __init__(self,n_features,learning_rate=0.01,hidden_units=10):\n",
        "        self.learning_rate= learning_rate\n",
        "        self.hidden_units=hidden_units\n",
        "        self.cache = {}\n",
        "        limit = np.sqrt( 6 / ( n_features+self.hidden_units ))\n",
        "        self.hidden_weights = np.random.uniform(-limit, limit, (self.hidden_units , self.hidden_units) )\n",
        "\n",
        "        self.input_weights = np.random.uniform(-limit, limit , ( self.hidden_units, n_features) )\n",
        "\n",
        "    def loss(self, predicted , target):\n",
        "        return (1/2*self.hidden_units) * np.square(target - predicted)\n",
        "\n",
        "    def sigmoid(self, X):\n",
        "        return 1/(1+np.exp(-X))\n",
        "\n",
        "    def train(self,X , target ):\n",
        "        \"\"\"trains real time recurrent logic\"\"\"\n",
        "        self.cache.clear()\n",
        "\n",
        "\n",
        "        self.X = X\n",
        "\n",
        "        self.target = target\n",
        "\n",
        "        #for simplicity we assume offline learning\n",
        "\n",
        "        self.timesteps , n_features = self.X.shape\n",
        "\n",
        "        # limit = np.sqrt( 6 / ( n_features+self.hidden_units ))\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        Glorot init Draws samples from a uniform distribution within `[-limit, limit]`, where\n",
        "        `limit = sqrt(6 / (fan_in + fan_out))` (`fan_in` is the number of input\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        #sensitivity matrices\n",
        "        self.sensitivity_tensor = np.zeros(shape=(self.hidden_units ,self.hidden_units , self.hidden_units))\n",
        "\n",
        "        self.hidden_state = np.zeros(self.hidden_units)\n",
        "\n",
        "        self.activation = np.zeros(self.hidden_units)\n",
        "\n",
        "        self.cache[\"activations\"] = [self.activation ]\n",
        "        self.cache[\"losses\"] = []\n",
        "\n",
        "        sigmoid_derivative = lambda activation: activation * (1 - activation)\n",
        "\n",
        "        self.gradients = np.zeros( (self.hidden_units , self.hidden_units) )\n",
        "\n",
        "        for timestep in range(self.timesteps):\n",
        "\n",
        "            self.hidden_state = np.dot(self.input_weights , self.X[timestep] ) + np.dot(self.hidden_weights , self.activation)\n",
        "\n",
        "            self.activation = self.sigmoid( self.hidden_state )\n",
        "\n",
        "            #computing gradients\n",
        "            error = self.target[timestep] - self.activation\n",
        "\n",
        "            loss  = self.loss(self.activation, self.target[timestep] )\n",
        "\n",
        "            self.cache[\"losses\"].append( np.mean(loss) )\n",
        "\n",
        "            for u in range(self.hidden_units):\n",
        "                for v in range(self.hidden_units):\n",
        "                    temp = self.cache[\"activations\"][-1][u] + np.dot( self.hidden_weights , self.sensitivity_tensor[u][v] )\n",
        "\n",
        "                    self.sensitivity_tensor[u][v] = np.multiply( sigmoid_derivative(self.activation) , temp)\n",
        "\n",
        "                    self.gradients[u][v] += np.dot(error, self.sensitivity_tensor[u][v])\n",
        "\n",
        "            self.hidden_weights += self.gradients  * self.learning_rate\n",
        "\n",
        "            self.cache[\"activations\"].append( self.activation )\n",
        "            print( f\"\\t the loss for timestep {timestep} is: {np.mean(loss)}\")\n",
        "\n",
        "\n",
        "        plt.plot( range(self.timesteps) , self.cache[\"losses\"] )\n",
        "\n",
        "        plt.xlabel('X-axis ,  timestep')\n",
        "\n",
        "        plt.ylabel('Y-axis ,  Loss')\n",
        "\n",
        "        plt.savefig(f\"loss{str(datetime.datetime.now()).replace('.','-').replace(':','-')}.pdf\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c6e63fd-c398-44de-aeea-9b4c3870a39a",
      "metadata": {
        "id": "8c6e63fd-c398-44de-aeea-9b4c3870a39a"
      },
      "outputs": [],
      "source": [
        "rtrl = RNN_RTRL(n_features=scaled_ts.shape[-1]-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0608226b-181b-42f0-8f2c-4394e82ebb38",
      "metadata": {
        "id": "0608226b-181b-42f0-8f2c-4394e82ebb38"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "data=fetch_california_housing()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd297ff8-105a-47e0-935f-6278b14b6f6a",
      "metadata": {
        "id": "fd297ff8-105a-47e0-935f-6278b14b6f6a"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "X = data.data\n",
        "Y = data.target\n",
        "df = pd.DataFrame(X)\n",
        "df.iloc[: ,-1] = Y\n",
        "scaler = StandardScaler()\n",
        "df = scaler.fit_transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(scaled_ts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_uyki-wC94i",
        "outputId": "815350f7-572a-4753-82c5-9cd6ac290ed9"
      },
      "id": "v_uyki-wC94i",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_rtrl = []\n",
        "for _ in range(200):\n",
        "  rtrl.train(scaled_ts[:,:-1] , scaled_ts[:,-1])\n",
        "  loss_rtrl.append(np.mean(rtrl.cache['losses']))\n",
        "plt.plot(loss_rtrl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Pw7jBXzHk_n3",
        "outputId": "1e2045ba-c1ee-4893-ff7c-6ffb6736af2e"
      },
      "id": "Pw7jBXzHk_n3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\t the loss for timestep 40 is: 0.5261118052446884\n",
            "\t the loss for timestep 41 is: 0.6003708346496085\n",
            "\t the loss for timestep 42 is: 0.5022699281840081\n",
            "\t the loss for timestep 43 is: 0.6439981974488684\n",
            "\t the loss for timestep 44 is: 0.45870942845574547\n",
            "\t the loss for timestep 45 is: 0.6854021897494187\n",
            "\t the loss for timestep 46 is: 0.4279760697106297\n",
            "\t the loss for timestep 47 is: 0.7725332817861984\n",
            "\t the loss for timestep 48 is: 0.46447039339659674\n",
            "\t the loss for timestep 49 is: 0.7918128687923905\n",
            "\t the loss for timestep 50 is: 0.4005099479432671\n",
            "\t the loss for timestep 51 is: 0.8716191316021608\n",
            "\t the loss for timestep 52 is: 0.36663642799377366\n",
            "\t the loss for timestep 53 is: 0.9811703514857811\n",
            "\t the loss for timestep 54 is: 0.3497610655501199\n",
            "\t the loss for timestep 55 is: 1.0684164499164954\n",
            "\t the loss for timestep 56 is: 0.35434378052197185\n",
            "\t the loss for timestep 57 is: 1.100293402994383\n",
            "\t the loss for timestep 58 is: 0.3833757434569762\n",
            "\t the loss for timestep 59 is: 1.0733177345923521\n",
            "\t the loss for timestep 60 is: 0.43377445639890855\n",
            "\t the loss for timestep 61 is: 1.0115445875809759\n",
            "\t the loss for timestep 62 is: 0.6353266312457851\n",
            "\t the loss for timestep 63 is: 1.460002354167166\n",
            "\t the loss for timestep 64 is: 1.8873505724396402\n",
            "\t the loss for timestep 65 is: 1.532529526229116\n",
            "\t the loss for timestep 66 is: 0.7782252836068437\n",
            "\t the loss for timestep 67 is: 0.8182123731762273\n",
            "\t the loss for timestep 68 is: 0.7128720374806974\n",
            "\t the loss for timestep 69 is: 0.8020500497746564\n",
            "\t the loss for timestep 70 is: 0.7484003016425361\n",
            "\t the loss for timestep 71 is: 0.8074067021816385\n",
            "\t the loss for timestep 72 is: 0.7824404236765032\n",
            "\t the loss for timestep 73 is: 0.8212232090833332\n",
            "\t the loss for timestep 74 is: 0.8106204703956218\n",
            "\t the loss for timestep 75 is: 0.8340190385863521\n",
            "\t the loss for timestep 76 is: 0.8318901177121972\n",
            "\t the loss for timestep 77 is: 0.8460404762720348\n",
            "\t the loss for timestep 78 is: 0.8472919371399714\n",
            "\t the loss for timestep 79 is: 1.3586549080550345\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.8913832891067835\n",
            "\t the loss for timestep 2 is: 0.9511735386335547\n",
            "\t the loss for timestep 3 is: 0.8235549082826363\n",
            "\t the loss for timestep 4 is: 0.8874007319856604\n",
            "\t the loss for timestep 5 is: 1.094752535775974\n",
            "\t the loss for timestep 6 is: 0.6915427657827664\n",
            "\t the loss for timestep 7 is: 0.8044647803850026\n",
            "\t the loss for timestep 8 is: 0.8372234964082026\n",
            "\t the loss for timestep 9 is: 0.8211885588902762\n",
            "\t the loss for timestep 10 is: 0.8225229216387598\n",
            "\t the loss for timestep 11 is: 0.8077625889328102\n",
            "\t the loss for timestep 12 is: 0.8029359972917638\n",
            "\t the loss for timestep 13 is: 0.7889859915590973\n",
            "\t the loss for timestep 14 is: 0.780729112100705\n",
            "\t the loss for timestep 15 is: 0.7667598615463403\n",
            "\t the loss for timestep 16 is: 0.7562891214238812\n",
            "\t the loss for timestep 17 is: 0.7420048722114476\n",
            "\t the loss for timestep 18 is: 0.7301265172636303\n",
            "\t the loss for timestep 19 is: 0.7155603351609431\n",
            "\t the loss for timestep 20 is: 0.7028889770163669\n",
            "\t the loss for timestep 21 is: 0.6882250335733457\n",
            "\t the loss for timestep 22 is: 0.6752649120002575\n",
            "\t the loss for timestep 23 is: 0.6607360045604247\n",
            "\t the loss for timestep 24 is: 0.6479083808272675\n",
            "\t the loss for timestep 25 is: 0.6337327855097208\n",
            "\t the loss for timestep 26 is: 0.6213879196927505\n",
            "\t the loss for timestep 27 is: 0.6077283162214516\n",
            "\t the loss for timestep 28 is: 0.5961547287619916\n",
            "\t the loss for timestep 29 is: 0.5830902619065886\n",
            "\t the loss for timestep 30 is: 0.572540705532811\n",
            "\t the loss for timestep 31 is: 0.5600386604163914\n",
            "\t the loss for timestep 32 is: 0.5507725923267397\n",
            "\t the loss for timestep 33 is: 0.5386447674104219\n",
            "\t the loss for timestep 34 is: 177.77287006224853\n",
            "\t the loss for timestep 35 is: 183.6665986100442\n",
            "\t the loss for timestep 36 is: 0.43281850256280185\n",
            "\t the loss for timestep 37 is: 0.6898540955054082\n",
            "\t the loss for timestep 38 is: 0.34593550244079696\n",
            "\t the loss for timestep 39 is: 0.9271100574820478\n",
            "\t the loss for timestep 40 is: 0.2836124231898544\n",
            "\t the loss for timestep 41 is: 1.0922124831541706\n",
            "\t the loss for timestep 42 is: 0.20722576058364792\n",
            "\t the loss for timestep 43 is: 1.4809761154283498\n",
            "\t the loss for timestep 44 is: 0.1597784887718671\n",
            "\t the loss for timestep 45 is: 1.789467632561189\n",
            "\t the loss for timestep 46 is: 0.14561992734099355\n",
            "\t the loss for timestep 47 is: 1.688611165066364\n",
            "\t the loss for timestep 48 is: 0.15015613119300739\n",
            "\t the loss for timestep 49 is: 1.8757997011861565\n",
            "\t the loss for timestep 50 is: 0.1393383662111571\n",
            "\t the loss for timestep 51 is: 1.9872758618328201\n",
            "\t the loss for timestep 52 is: 0.13620636565184618\n",
            "\t the loss for timestep 53 is: 2.0232845763063425\n",
            "\t the loss for timestep 54 is: 0.13463875166305728\n",
            "\t the loss for timestep 55 is: 2.0418871309428233\n",
            "\t the loss for timestep 56 is: 0.13351998237490506\n",
            "\t the loss for timestep 57 is: 2.055549599336488\n",
            "\t the loss for timestep 58 is: 0.13264078348874686\n",
            "\t the loss for timestep 59 is: 2.066575193430297\n",
            "\t the loss for timestep 60 is: 0.13193460081346467\n",
            "\t the loss for timestep 61 is: 2.0756357028198167\n",
            "\t the loss for timestep 62 is: 0.13297910642243077\n",
            "\t the loss for timestep 63 is: 2.2812019294197015\n",
            "\t the loss for timestep 64 is: 0.31942173593682066\n",
            "\t the loss for timestep 65 is: 2.607333351595089\n",
            "\t the loss for timestep 66 is: 0.13433209519004347\n",
            "\t the loss for timestep 67 is: 2.042555397126717\n",
            "\t the loss for timestep 68 is: 0.1304130698378844\n",
            "\t the loss for timestep 69 is: 2.095654355907635\n",
            "\t the loss for timestep 70 is: 0.12995982503263934\n",
            "\t the loss for timestep 71 is: 2.122573343701471\n",
            "\t the loss for timestep 72 is: 0.12967536783541736\n",
            "\t the loss for timestep 73 is: 2.106069670417202\n",
            "\t the loss for timestep 74 is: 0.12956401222612235\n",
            "\t the loss for timestep 75 is: 2.107568526486866\n",
            "\t the loss for timestep 76 is: 0.12942044112572498\n",
            "\t the loss for timestep 77 is: 2.1095807602280305\n",
            "\t the loss for timestep 78 is: 0.12929792548203953\n",
            "\t the loss for timestep 79 is: 3.0821356068773564\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.12915884276529116\n",
            "\t the loss for timestep 2 is: 2.1133502350145132\n",
            "\t the loss for timestep 3 is: 0.12919043521401702\n",
            "\t the loss for timestep 4 is: 2.11286466676916\n",
            "\t the loss for timestep 5 is: 0.1323803367609227\n",
            "\t the loss for timestep 6 is: 3.5106956862989187\n",
            "\t the loss for timestep 7 is: 0.12830647544474838\n",
            "\t the loss for timestep 8 is: 2.1264642745925784\n",
            "\t the loss for timestep 9 is: 0.1291651377460943\n",
            "\t the loss for timestep 10 is: 2.1132619178322694\n",
            "\t the loss for timestep 11 is: 0.12919534047906275\n",
            "\t the loss for timestep 12 is: 2.1128051906985568\n",
            "\t the loss for timestep 13 is: 0.1291983393929202\n",
            "\t the loss for timestep 14 is: 2.1127604815160943\n",
            "\t the loss for timestep 15 is: 0.1292006955056453\n",
            "\t the loss for timestep 16 is: 2.1127297498520132\n",
            "\t the loss for timestep 17 is: 0.12920328309007495\n",
            "\t the loss for timestep 18 is: 2.1126960896792744\n",
            "\t the loss for timestep 19 is: 0.12920614260155933\n",
            "\t the loss for timestep 20 is: 2.112658893428855\n",
            "\t the loss for timestep 21 is: 0.1292092783243635\n",
            "\t the loss for timestep 22 is: 2.1126183904742177\n",
            "\t the loss for timestep 23 is: 0.129212693480714\n",
            "\t the loss for timestep 24 is: 2.112573696853828\n",
            "\t the loss for timestep 25 is: 0.12921639215730196\n",
            "\t the loss for timestep 26 is: 2.1125259142814854\n",
            "\t the loss for timestep 27 is: 0.12922037772988088\n",
            "\t the loss for timestep 28 is: 2.1124738180029636\n",
            "\t the loss for timestep 29 is: 0.12922465519087595\n",
            "\t the loss for timestep 30 is: 2.1124182597472916\n",
            "\t the loss for timestep 31 is: 0.12922922867131753\n",
            "\t the loss for timestep 32 is: 2.112358881917735\n",
            "\t the loss for timestep 33 is: 0.12923410340408942\n",
            "\t the loss for timestep 34 is: 162.14646615088407\n",
            "\t the loss for timestep 35 is: 194.6201344399743\n",
            "\t the loss for timestep 36 is: 1.9859348609060627\n",
            "\t the loss for timestep 37 is: 0.12960267563217429\n",
            "\t the loss for timestep 38 is: 2.106746383313911\n",
            "\t the loss for timestep 39 is: 0.12948498458367635\n",
            "\t the loss for timestep 40 is: 2.2085704128844634\n",
            "\t the loss for timestep 41 is: 0.12912857745923542\n",
            "\t the loss for timestep 42 is: 2.1476742983408754\n",
            "\t the loss for timestep 43 is: 0.1293047875601031\n",
            "\t the loss for timestep 44 is: 2.1114294945408583\n",
            "\t the loss for timestep 45 is: 0.12935026914821718\n",
            "\t the loss for timestep 46 is: 2.1107679928647975\n",
            "\t the loss for timestep 47 is: 0.12936373079413455\n",
            "\t the loss for timestep 48 is: 1.8301173174059109\n",
            "\t the loss for timestep 49 is: 0.13191931603385884\n",
            "\t the loss for timestep 50 is: 2.0733070953907413\n",
            "\t the loss for timestep 51 is: 0.1295331786226439\n",
            "\t the loss for timestep 52 is: 2.108184090565953\n",
            "\t the loss for timestep 53 is: 0.1294653025875719\n",
            "\t the loss for timestep 54 is: 2.109253522600869\n",
            "\t the loss for timestep 55 is: 0.12949209196141503\n",
            "\t the loss for timestep 56 is: 2.108913557955027\n",
            "\t the loss for timestep 57 is: 0.12952388682955432\n",
            "\t the loss for timestep 58 is: 2.108503077419844\n",
            "\t the loss for timestep 59 is: 0.12955715179758293\n",
            "\t the loss for timestep 60 is: 2.1080757984220986\n",
            "\t the loss for timestep 61 is: 0.1295918052997865\n",
            "\t the loss for timestep 62 is: 1.9487687750085523\n",
            "\t the loss for timestep 63 is: 0.16179486040888572\n",
            "\t the loss for timestep 64 is: 3.0571715662786656\n",
            "\t the loss for timestep 65 is: 0.14564056314679003\n",
            "\t the loss for timestep 66 is: 2.0386067688527976\n",
            "\t the loss for timestep 67 is: 0.1301170778632457\n",
            "\t the loss for timestep 68 is: 2.100314607796428\n",
            "\t the loss for timestep 69 is: 0.12977913693931303\n",
            "\t the loss for timestep 70 is: 2.1258095301857165\n",
            "\t the loss for timestep 71 is: 0.12974727727158253\n",
            "\t the loss for timestep 72 is: 2.105779664857457\n",
            "\t the loss for timestep 73 is: 0.12986770611944215\n",
            "\t the loss for timestep 74 is: 2.1041854877019377\n",
            "\t the loss for timestep 75 is: 0.12993021686158485\n",
            "\t the loss for timestep 76 is: 2.103409584106066\n",
            "\t the loss for timestep 77 is: 0.12999279349451925\n",
            "\t the loss for timestep 78 is: 2.1026432900679657\n",
            "\t the loss for timestep 79 is: 0.14147374507394977\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.12999682096831722\n",
            "\t the loss for timestep 2 is: 2.1027143526791625\n",
            "\t the loss for timestep 3 is: 0.1300905540664521\n",
            "\t the loss for timestep 4 is: 2.1013955991924886\n",
            "\t the loss for timestep 5 is: 0.13581002681871573\n",
            "\t the loss for timestep 6 is: 3.4714608608180955\n",
            "\t the loss for timestep 7 is: 0.12845486316825855\n",
            "\t the loss for timestep 8 is: 2.124484358199768\n",
            "\t the loss for timestep 9 is: 0.13001900914063153\n",
            "\t the loss for timestep 10 is: 2.102429023540552\n",
            "\t the loss for timestep 11 is: 0.13010676237228136\n",
            "\t the loss for timestep 12 is: 2.1012116124000153\n",
            "\t the loss for timestep 13 is: 0.13011786905096234\n",
            "\t the loss for timestep 14 is: 2.101067926473358\n",
            "\t the loss for timestep 15 is: 0.13012570900724074\n",
            "\t the loss for timestep 16 is: 2.1009757486593554\n",
            "\t the loss for timestep 17 is: 0.13013420661860947\n",
            "\t the loss for timestep 18 is: 2.100876479683113\n",
            "\t the loss for timestep 19 is: 0.13014360383798326\n",
            "\t the loss for timestep 20 is: 2.1007667892659647\n",
            "\t the loss for timestep 21 is: 0.13015393008279547\n",
            "\t the loss for timestep 22 is: 2.100646616591213\n",
            "\t the loss for timestep 23 is: 0.13016520482367194\n",
            "\t the loss for timestep 24 is: 2.1005149229029985\n",
            "\t the loss for timestep 25 is: 0.13017744986320154\n",
            "\t the loss for timestep 26 is: 2.1003726321671237\n",
            "\t the loss for timestep 27 is: 0.1301906874355956\n",
            "\t the loss for timestep 28 is: 2.1002183434729975\n",
            "\t the loss for timestep 29 is: 0.13020494362755267\n",
            "\t the loss for timestep 30 is: 2.100052703146848\n",
            "\t the loss for timestep 31 is: 0.1302202454370892\n",
            "\t the loss for timestep 32 is: 2.0998751346480313\n",
            "\t the loss for timestep 33 is: 0.13023662307595626\n",
            "\t the loss for timestep 34 is: 162.20654716390584\n",
            "\t the loss for timestep 35 is: 194.15783127273988\n",
            "\t the loss for timestep 36 is: 1.8457005650201956\n",
            "\t the loss for timestep 37 is: 0.13180064927028642\n",
            "\t the loss for timestep 38 is: 2.078448975892666\n",
            "\t the loss for timestep 39 is: 0.13094465035308894\n",
            "\t the loss for timestep 40 is: 2.190604081422186\n",
            "\t the loss for timestep 41 is: 0.1302101740369443\n",
            "\t the loss for timestep 42 is: 2.1342176304016554\n",
            "\t the loss for timestep 43 is: 0.1306111859298648\n",
            "\t the loss for timestep 44 is: 2.095393985276976\n",
            "\t the loss for timestep 45 is: 0.13075683778842168\n",
            "\t the loss for timestep 46 is: 2.093580918102044\n",
            "\t the loss for timestep 47 is: 0.13081614471274955\n",
            "\t the loss for timestep 48 is: 1.8172446554558146\n",
            "\t the loss for timestep 49 is: 0.13600299428990337\n",
            "\t the loss for timestep 50 is: 2.027420710286572\n",
            "\t the loss for timestep 51 is: 0.13153914105882875\n",
            "\t the loss for timestep 52 is: 2.0839693610667425\n",
            "\t the loss for timestep 53 is: 0.13134653261410656\n",
            "\t the loss for timestep 54 is: 2.0867805787377876\n",
            "\t the loss for timestep 55 is: 0.13148641755244445\n",
            "\t the loss for timestep 56 is: 2.08526288579378\n",
            "\t the loss for timestep 57 is: 0.13166279949141363\n",
            "\t the loss for timestep 58 is: 2.0833104530442634\n",
            "\t the loss for timestep 59 is: 0.1318542541818077\n",
            "\t the loss for timestep 60 is: 2.081209255924993\n",
            "\t the loss for timestep 61 is: 0.13206023525499863\n",
            "\t the loss for timestep 62 is: 1.937594650554604\n",
            "\t the loss for timestep 63 is: 0.20951212337786154\n",
            "\t the loss for timestep 64 is: 2.877930908490078\n",
            "\t the loss for timestep 65 is: 0.20878955384937958\n",
            "\t the loss for timestep 66 is: 1.6685191015302092\n",
            "\t the loss for timestep 67 is: 0.13912201233625257\n",
            "\t the loss for timestep 68 is: 1.9963484040401902\n",
            "\t the loss for timestep 69 is: 0.13378285824151537\n",
            "\t the loss for timestep 70 is: 2.080168639805449\n",
            "\t the loss for timestep 71 is: 0.13334076041552287\n",
            "\t the loss for timestep 72 is: 2.065785871701218\n",
            "\t the loss for timestep 73 is: 0.13384559595424445\n",
            "\t the loss for timestep 74 is: 2.060646387554272\n",
            "\t the loss for timestep 75 is: 0.13429587254964126\n",
            "\t the loss for timestep 76 is: 2.0562054014035582\n",
            "\t the loss for timestep 77 is: 0.1347803541626734\n",
            "\t the loss for timestep 78 is: 2.0515281697060095\n",
            "\t the loss for timestep 79 is: 0.17957108676217598\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.13471169972549255\n",
            "\t the loss for timestep 2 is: 2.053244558836364\n",
            "\t the loss for timestep 3 is: 0.135546430098535\n",
            "\t the loss for timestep 4 is: 2.0438824961681012\n",
            "\t the loss for timestep 5 is: 0.15953130412969496\n",
            "\t the loss for timestep 6 is: 3.2566915430293077\n",
            "\t the loss for timestep 7 is: 0.12999586001450855\n",
            "\t the loss for timestep 8 is: 2.1070717898740563\n",
            "\t the loss for timestep 9 is: 0.13503260072628046\n",
            "\t the loss for timestep 10 is: 2.049934231428284\n",
            "\t the loss for timestep 11 is: 0.13575695862700585\n",
            "\t the loss for timestep 12 is: 2.042011959549465\n",
            "\t the loss for timestep 13 is: 0.13593011019987244\n",
            "\t the loss for timestep 14 is: 2.0402767104222215\n",
            "\t the loss for timestep 15 is: 0.13603747928206927\n",
            "\t the loss for timestep 16 is: 2.039305959466395\n",
            "\t the loss for timestep 17 is: 0.13614614878886502\n",
            "\t the loss for timestep 18 is: 2.0383515462364525\n",
            "\t the loss for timestep 19 is: 0.13626608935543322\n",
            "\t the loss for timestep 20 is: 2.037305431297246\n",
            "\t the loss for timestep 21 is: 0.13639934779062807\n",
            "\t the loss for timestep 22 is: 2.0361482302220315\n",
            "\t the loss for timestep 23 is: 0.13654695128484212\n",
            "\t the loss for timestep 24 is: 2.0348712197483922\n",
            "\t the loss for timestep 25 is: 0.13670989096065325\n",
            "\t the loss for timestep 26 is: 2.0334685250022497\n",
            "\t the loss for timestep 27 is: 0.13688926858372094\n",
            "\t the loss for timestep 28 is: 2.0319313983233145\n",
            "\t the loss for timestep 29 is: 0.13708633696867967\n",
            "\t the loss for timestep 30 is: 2.0302521606365174\n",
            "\t the loss for timestep 31 is: 0.13730252627267445\n",
            "\t the loss for timestep 32 is: 2.0284208040566885\n",
            "\t the loss for timestep 33 is: 0.1375394657027406\n",
            "\t the loss for timestep 34 is: 162.56039462959257\n",
            "\t the loss for timestep 35 is: 191.45031152691627\n",
            "\t the loss for timestep 36 is: 1.2815328857217003\n",
            "\t the loss for timestep 37 is: 0.1696409651400507\n",
            "\t the loss for timestep 38 is: 1.731465342198075\n",
            "\t the loss for timestep 39 is: 0.15160561835498593\n",
            "\t the loss for timestep 40 is: 2.0027669565784545\n",
            "\t the loss for timestep 41 is: 0.14320528112864914\n",
            "\t the loss for timestep 42 is: 2.0132437175804503\n",
            "\t the loss for timestep 43 is: 0.14601778675659566\n",
            "\t the loss for timestep 44 is: 1.9597367323090409\n",
            "\t the loss for timestep 45 is: 0.14909863478706248\n",
            "\t the loss for timestep 46 is: 1.937035567480871\n",
            "\t the loss for timestep 47 is: 0.15144098014834168\n",
            "\t the loss for timestep 48 is: 1.695674865862788\n",
            "\t the loss for timestep 49 is: 0.18906596589909289\n",
            "\t the loss for timestep 50 is: 1.6819226846139455\n",
            "\t the loss for timestep 51 is: 0.17608714648307772\n",
            "\t the loss for timestep 52 is: 1.7599918450377328\n",
            "\t the loss for timestep 53 is: 0.17825401219391207\n",
            "\t the loss for timestep 54 is: 1.759216204212296\n",
            "\t the loss for timestep 55 is: 0.18681977885924286\n",
            "\t the loss for timestep 56 is: 1.7214362368041065\n",
            "\t the loss for timestep 57 is: 0.20024818648860668\n",
            "\t the loss for timestep 58 is: 1.6635823185049237\n",
            "\t the loss for timestep 59 is: 0.21890418668853787\n",
            "\t the loss for timestep 60 is: 1.59101379186224\n",
            "\t the loss for timestep 61 is: 0.24417138957668025\n",
            "\t the loss for timestep 62 is: 1.7164733294313357\n",
            "\t the loss for timestep 63 is: 0.8527350455943582\n",
            "\t the loss for timestep 64 is: 2.303031870332597\n",
            "\t the loss for timestep 65 is: 1.2464901660131902\n",
            "\t the loss for timestep 66 is: 0.7516678837610533\n",
            "\t the loss for timestep 67 is: 0.6946012302863434\n",
            "\t the loss for timestep 68 is: 0.7162803380829252\n",
            "\t the loss for timestep 69 is: 0.7047482158572208\n",
            "\t the loss for timestep 70 is: 0.7387397170619515\n",
            "\t the loss for timestep 71 is: 0.7258030362860934\n",
            "\t the loss for timestep 72 is: 0.751098405358537\n",
            "\t the loss for timestep 73 is: 0.751079188495405\n",
            "\t the loss for timestep 74 is: 0.7702250917869433\n",
            "\t the loss for timestep 75 is: 0.7734511291362266\n",
            "\t the loss for timestep 76 is: 0.7893430997484977\n",
            "\t the loss for timestep 77 is: 0.7950078408011285\n",
            "\t the loss for timestep 78 is: 0.8081921740554382\n",
            "\t the loss for timestep 79 is: 2.1839876817807897\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.41857262575100684\n",
            "\t the loss for timestep 2 is: 1.2871315621567718\n",
            "\t the loss for timestep 3 is: 0.5901510781650448\n",
            "\t the loss for timestep 4 is: 1.0324995166614515\n",
            "\t the loss for timestep 5 is: 1.7720260185578733\n",
            "\t the loss for timestep 6 is: 1.3052582382687195\n",
            "\t the loss for timestep 7 is: 0.609580404466087\n",
            "\t the loss for timestep 8 is: 1.0070515306328898\n",
            "\t the loss for timestep 9 is: 0.6782681324609847\n",
            "\t the loss for timestep 10 is: 0.9029100583525714\n",
            "\t the loss for timestep 11 is: 0.7170610849892736\n",
            "\t the loss for timestep 12 is: 0.8470576506518952\n",
            "\t the loss for timestep 13 is: 0.7331166719956714\n",
            "\t the loss for timestep 14 is: 0.8105669888306112\n",
            "\t the loss for timestep 15 is: 0.7358000795000235\n",
            "\t the loss for timestep 16 is: 0.7833569546401273\n",
            "\t the loss for timestep 17 is: 0.730676773781398\n",
            "\t the loss for timestep 18 is: 0.7607569427606122\n",
            "\t the loss for timestep 19 is: 0.7209352473130882\n",
            "\t the loss for timestep 20 is: 0.7405685675691294\n",
            "\t the loss for timestep 21 is: 0.7084364044140705\n",
            "\t the loss for timestep 22 is: 0.7217615720505385\n",
            "\t the loss for timestep 23 is: 0.6943012101638837\n",
            "\t the loss for timestep 24 is: 0.7038774792036308\n",
            "\t the loss for timestep 25 is: 0.6792264419997422\n",
            "\t the loss for timestep 26 is: 0.6867436404747818\n",
            "\t the loss for timestep 27 is: 0.6636522041742788\n",
            "\t the loss for timestep 28 is: 0.6703324101841955\n",
            "\t the loss for timestep 29 is: 0.6478492744568429\n",
            "\t the loss for timestep 30 is: 0.6546974884934436\n",
            "\t the loss for timestep 31 is: 0.6319629081223652\n",
            "\t the loss for timestep 32 is: 0.6399489300125458\n",
            "\t the loss for timestep 33 is: 0.6160277994042264\n",
            "\t the loss for timestep 34 is: 172.00400885607058\n",
            "\t the loss for timestep 35 is: 181.2358169805513\n",
            "\t the loss for timestep 36 is: 0.5150609986866048\n",
            "\t the loss for timestep 37 is: 0.7636377773219756\n",
            "\t the loss for timestep 38 is: 0.4790484230114627\n",
            "\t the loss for timestep 39 is: 0.8629053718758508\n",
            "\t the loss for timestep 40 is: 0.4643909463853017\n",
            "\t the loss for timestep 41 is: 0.8444948696788886\n",
            "\t the loss for timestep 42 is: 0.43517032590980886\n",
            "\t the loss for timestep 43 is: 0.9020317235605864\n",
            "\t the loss for timestep 44 is: 0.3943236978880518\n",
            "\t the loss for timestep 45 is: 0.9591779193283803\n",
            "\t the loss for timestep 46 is: 0.36297529019152114\n",
            "\t the loss for timestep 47 is: 0.9990831253112458\n",
            "\t the loss for timestep 48 is: 0.41121069886080275\n",
            "\t the loss for timestep 49 is: 0.9999641690994491\n",
            "\t the loss for timestep 50 is: 0.35073178661670873\n",
            "\t the loss for timestep 51 is: 1.0731498924444138\n",
            "\t the loss for timestep 52 is: 0.31904333073017654\n",
            "\t the loss for timestep 53 is: 1.164516604726735\n",
            "\t the loss for timestep 54 is: 0.29480606824373834\n",
            "\t the loss for timestep 55 is: 1.2526006235185476\n",
            "\t the loss for timestep 56 is: 0.2778069925897345\n",
            "\t the loss for timestep 57 is: 1.3251417881672929\n",
            "\t the loss for timestep 58 is: 0.2687984258535994\n",
            "\t the loss for timestep 59 is: 1.3736765566136961\n",
            "\t the loss for timestep 60 is: 0.2674422298650208\n",
            "\t the loss for timestep 61 is: 1.396089150888108\n",
            "\t the loss for timestep 62 is: 0.4290278608602054\n",
            "\t the loss for timestep 63 is: 1.6166057886137253\n",
            "\t the loss for timestep 64 is: 1.5794686446748172\n",
            "\t the loss for timestep 65 is: 1.7389527166937142\n",
            "\t the loss for timestep 66 is: 0.478571280708162\n",
            "\t the loss for timestep 67 is: 0.9825116925197716\n",
            "\t the loss for timestep 68 is: 0.4223345570889331\n",
            "\t the loss for timestep 69 is: 1.0082255690781543\n",
            "\t the loss for timestep 70 is: 0.4161446112979347\n",
            "\t the loss for timestep 71 is: 1.0407098353596012\n",
            "\t the loss for timestep 72 is: 0.4122720560777351\n",
            "\t the loss for timestep 73 is: 1.063487684554141\n",
            "\t the loss for timestep 74 is: 0.4157574836018437\n",
            "\t the loss for timestep 75 is: 1.0743364591629867\n",
            "\t the loss for timestep 76 is: 0.4227708246365774\n",
            "\t the loss for timestep 77 is: 1.0774499072795523\n",
            "\t the loss for timestep 78 is: 0.4328501566985672\n",
            "\t the loss for timestep 79 is: 2.453533791741626\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.2618361314584057\n",
            "\t the loss for timestep 2 is: 1.5853550864788095\n",
            "\t the loss for timestep 3 is: 0.3205587752809847\n",
            "\t the loss for timestep 4 is: 1.3877946404403354\n",
            "\t the loss for timestep 5 is: 0.7580295052985383\n",
            "\t the loss for timestep 6 is: 1.6101410123953748\n",
            "\t the loss for timestep 7 is: 0.3468541120339512\n",
            "\t the loss for timestep 8 is: 1.330360121276385\n",
            "\t the loss for timestep 9 is: 0.3629190735536999\n",
            "\t the loss for timestep 10 is: 1.2527539710871776\n",
            "\t the loss for timestep 11 is: 0.3796975583551104\n",
            "\t the loss for timestep 12 is: 1.2043321858191995\n",
            "\t the loss for timestep 13 is: 0.39023340724598155\n",
            "\t the loss for timestep 14 is: 1.1725881196923182\n",
            "\t the loss for timestep 15 is: 0.3966128631708172\n",
            "\t the loss for timestep 16 is: 1.1519585274346948\n",
            "\t the loss for timestep 17 is: 0.4000143671772995\n",
            "\t the loss for timestep 18 is: 1.1392131584190932\n",
            "\t the loss for timestep 19 is: 0.40140682243246745\n",
            "\t the loss for timestep 20 is: 1.1321680569829247\n",
            "\t the loss for timestep 21 is: 0.4017064138622065\n",
            "\t the loss for timestep 22 is: 1.1290478811241917\n",
            "\t the loss for timestep 23 is: 0.40188063626080056\n",
            "\t the loss for timestep 24 is: 1.128137833396282\n",
            "\t the loss for timestep 25 is: 0.4030166707015045\n",
            "\t the loss for timestep 26 is: 1.1275944810351997\n",
            "\t the loss for timestep 27 is: 0.40636904442859834\n",
            "\t the loss for timestep 28 is: 1.1253809068450806\n",
            "\t the loss for timestep 29 is: 0.4133888941193599\n",
            "\t the loss for timestep 30 is: 1.1193505693704202\n",
            "\t the loss for timestep 31 is: 0.4257297005357111\n",
            "\t the loss for timestep 32 is: 1.1074968550324742\n",
            "\t the loss for timestep 33 is: 0.44520194410539454\n",
            "\t the loss for timestep 34 is: 168.06358410767774\n",
            "\t the loss for timestep 35 is: 181.60005014492916\n",
            "\t the loss for timestep 36 is: 0.7679068176680792\n",
            "\t the loss for timestep 37 is: 0.7245909665296546\n",
            "\t the loss for timestep 38 is: 0.7430533719853094\n",
            "\t the loss for timestep 39 is: 0.8008909988603696\n",
            "\t the loss for timestep 40 is: 0.7830658290891184\n",
            "\t the loss for timestep 41 is: 0.7645427503732275\n",
            "\t the loss for timestep 42 is: 0.7926751735870063\n",
            "\t the loss for timestep 43 is: 0.7875858517196761\n",
            "\t the loss for timestep 44 is: 0.7939183655283125\n",
            "\t the loss for timestep 45 is: 0.7992530609254043\n",
            "\t the loss for timestep 46 is: 0.8086548499492453\n",
            "\t the loss for timestep 47 is: 0.7896118307674567\n",
            "\t the loss for timestep 48 is: 0.9051888457319158\n",
            "\t the loss for timestep 49 is: 0.8670443904355043\n",
            "\t the loss for timestep 50 is: 0.8272059730270446\n",
            "\t the loss for timestep 51 is: 0.8649765032446451\n",
            "\t the loss for timestep 52 is: 0.8413656776066982\n",
            "\t the loss for timestep 53 is: 0.868966721261242\n",
            "\t the loss for timestep 54 is: 0.8591748538752808\n",
            "\t the loss for timestep 55 is: 0.8755492797154959\n",
            "\t the loss for timestep 56 is: 0.872362227914109\n",
            "\t the loss for timestep 57 is: 0.8818984640018186\n",
            "\t the loss for timestep 58 is: 0.8816002775091759\n",
            "\t the loss for timestep 59 is: 0.8869151012465011\n",
            "\t the loss for timestep 60 is: 0.8873146629109445\n",
            "\t the loss for timestep 61 is: 0.8898216366577676\n",
            "\t the loss for timestep 62 is: 1.319931838120715\n",
            "\t the loss for timestep 63 is: 1.3171940647615288\n",
            "\t the loss for timestep 64 is: 2.301737009799046\n",
            "\t the loss for timestep 65 is: 2.0710289845720453\n",
            "\t the loss for timestep 66 is: 0.7967387864382763\n",
            "\t the loss for timestep 67 is: 0.9684597867703955\n",
            "\t the loss for timestep 68 is: 0.832291086979145\n",
            "\t the loss for timestep 69 is: 0.9081100409033273\n",
            "\t the loss for timestep 70 is: 0.8600154467028809\n",
            "\t the loss for timestep 71 is: 0.8803461558336032\n",
            "\t the loss for timestep 72 is: 0.8457965344386846\n",
            "\t the loss for timestep 73 is: 0.8597808093838817\n",
            "\t the loss for timestep 74 is: 0.8392122456366232\n",
            "\t the loss for timestep 75 is: 0.840859196366378\n",
            "\t the loss for timestep 76 is: 0.8266920991998369\n",
            "\t the loss for timestep 77 is: 0.8228011365377024\n",
            "\t the loss for timestep 78 is: 0.8111500035604482\n",
            "\t the loss for timestep 79 is: 2.3995135200772792\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.42757796258009356\n",
            "\t the loss for timestep 2 is: 1.2714049865194021\n",
            "\t the loss for timestep 3 is: 0.5741639596658865\n",
            "\t the loss for timestep 4 is: 1.0198274227067914\n",
            "\t the loss for timestep 5 is: 1.9982953441408438\n",
            "\t the loss for timestep 6 is: 1.441463489498262\n",
            "\t the loss for timestep 7 is: 0.507459438406359\n",
            "\t the loss for timestep 8 is: 1.0684329121803624\n",
            "\t the loss for timestep 9 is: 0.61805581326897\n",
            "\t the loss for timestep 10 is: 0.9319074512279366\n",
            "\t the loss for timestep 11 is: 0.6671127180656986\n",
            "\t the loss for timestep 12 is: 0.859921939890735\n",
            "\t the loss for timestep 13 is: 0.6924919812779989\n",
            "\t the loss for timestep 14 is: 0.8155586496168953\n",
            "\t the loss for timestep 15 is: 0.7028079416127182\n",
            "\t the loss for timestep 16 is: 0.7846601150666805\n",
            "\t the loss for timestep 17 is: 0.703911164167413\n",
            "\t the loss for timestep 18 is: 0.760776273703353\n",
            "\t the loss for timestep 19 is: 0.6993202503795609\n",
            "\t the loss for timestep 20 is: 0.7407539976476493\n",
            "\t the loss for timestep 21 is: 0.691153592426847\n",
            "\t the loss for timestep 22 is: 0.7230036704795273\n",
            "\t the loss for timestep 23 is: 0.6807006722657828\n",
            "\t the loss for timestep 24 is: 0.7067261511400088\n",
            "\t the loss for timestep 25 is: 0.6687557625988853\n",
            "\t the loss for timestep 26 is: 0.6915427989216177\n",
            "\t the loss for timestep 27 is: 0.6558046824257008\n",
            "\t the loss for timestep 28 is: 0.6773127467469571\n",
            "\t the loss for timestep 29 is: 0.6421255444455131\n",
            "\t the loss for timestep 30 is: 0.6640475352912043\n",
            "\t the loss for timestep 31 is: 0.6278366258406469\n",
            "\t the loss for timestep 32 is: 0.6518805749830083\n",
            "\t the loss for timestep 33 is: 0.6129076728585048\n",
            "\t the loss for timestep 34 is: 171.6815795460575\n",
            "\t the loss for timestep 35 is: 182.74460798400645\n",
            "\t the loss for timestep 36 is: 0.6055019968546166\n",
            "\t the loss for timestep 37 is: 0.6546780108970159\n",
            "\t the loss for timestep 38 is: 0.5842441992294208\n",
            "\t the loss for timestep 39 is: 0.7093840361295694\n",
            "\t the loss for timestep 40 is: 0.5862587832231233\n",
            "\t the loss for timestep 41 is: 0.6798290199071819\n",
            "\t the loss for timestep 42 is: 0.57472123914163\n",
            "\t the loss for timestep 43 is: 0.6955353712278167\n",
            "\t the loss for timestep 44 is: 0.5533304474405932\n",
            "\t the loss for timestep 45 is: 0.7067964597828045\n",
            "\t the loss for timestep 46 is: 0.5394369636295121\n",
            "\t the loss for timestep 47 is: 0.7143339320275129\n",
            "\t the loss for timestep 48 is: 0.6173344294469075\n",
            "\t the loss for timestep 49 is: 0.7273953436033029\n",
            "\t the loss for timestep 50 is: 0.5376002725557634\n",
            "\t the loss for timestep 51 is: 0.7355774961052209\n",
            "\t the loss for timestep 52 is: 0.5181211640889444\n",
            "\t the loss for timestep 53 is: 0.7586875979906216\n",
            "\t the loss for timestep 54 is: 0.5000927285073743\n",
            "\t the loss for timestep 55 is: 0.7861891861664602\n",
            "\t the loss for timestep 56 is: 0.4796414061364567\n",
            "\t the loss for timestep 57 is: 0.8185344576802581\n",
            "\t the loss for timestep 58 is: 0.45657057524526296\n",
            "\t the loss for timestep 59 is: 0.8569106412619514\n",
            "\t the loss for timestep 60 is: 0.4306809808879766\n",
            "\t the loss for timestep 61 is: 0.9030667180256028\n",
            "\t the loss for timestep 62 is: 0.7522268868889079\n",
            "\t the loss for timestep 63 is: 1.2751960016674861\n",
            "\t the loss for timestep 64 is: 1.7342520920471203\n",
            "\t the loss for timestep 65 is: 1.3987262521734238\n",
            "\t the loss for timestep 66 is: 0.5407535329018764\n",
            "\t the loss for timestep 67 is: 0.7890816718768106\n",
            "\t the loss for timestep 68 is: 0.4503640294947234\n",
            "\t the loss for timestep 69 is: 0.8231794260603662\n",
            "\t the loss for timestep 70 is: 0.4124721414321785\n",
            "\t the loss for timestep 71 is: 0.8898472719070121\n",
            "\t the loss for timestep 72 is: 0.36817360640999774\n",
            "\t the loss for timestep 73 is: 0.9841711999153444\n",
            "\t the loss for timestep 74 is: 0.3241352789208579\n",
            "\t the loss for timestep 75 is: 1.1047976533333572\n",
            "\t the loss for timestep 76 is: 0.28165056555101786\n",
            "\t the loss for timestep 77 is: 1.247379031420078\n",
            "\t the loss for timestep 78 is: 0.245107090061911\n",
            "\t the loss for timestep 79 is: 2.7009597291158913\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.16940349162850651\n",
            "\t the loss for timestep 2 is: 1.8083421102537716\n",
            "\t the loss for timestep 3 is: 0.18396866792475203\n",
            "\t the loss for timestep 4 is: 1.7170740205797048\n",
            "\t the loss for timestep 5 is: 0.21400265587143194\n",
            "\t the loss for timestep 6 is: 2.879568536614783\n",
            "\t the loss for timestep 7 is: 0.15364395605993494\n",
            "\t the loss for timestep 8 is: 1.9151203906987289\n",
            "\t the loss for timestep 9 is: 0.17870225909410528\n",
            "\t the loss for timestep 10 is: 1.7526678848717094\n",
            "\t the loss for timestep 11 is: 0.18812227949974775\n",
            "\t the loss for timestep 12 is: 1.6975885452803214\n",
            "\t the loss for timestep 13 is: 0.1920967537366292\n",
            "\t the loss for timestep 14 is: 1.676398496593496\n",
            "\t the loss for timestep 15 is: 0.1939505046561635\n",
            "\t the loss for timestep 16 is: 1.668075133096535\n",
            "\t the loss for timestep 17 is: 0.19493345910675894\n",
            "\t the loss for timestep 18 is: 1.665080661428553\n",
            "\t the loss for timestep 19 is: 0.19556360121340804\n",
            "\t the loss for timestep 20 is: 1.6643664785198702\n",
            "\t the loss for timestep 21 is: 0.19607885480128256\n",
            "\t the loss for timestep 22 is: 1.664556323930277\n",
            "\t the loss for timestep 23 is: 0.19661008570323832\n",
            "\t the loss for timestep 24 is: 1.664911523235262\n",
            "\t the loss for timestep 25 is: 0.19725196929281683\n",
            "\t the loss for timestep 26 is: 1.6649223476639203\n",
            "\t the loss for timestep 27 is: 0.19809475440189733\n",
            "\t the loss for timestep 28 is: 1.66413041690389\n",
            "\t the loss for timestep 29 is: 0.19924053386635684\n",
            "\t the loss for timestep 30 is: 1.6620534821142747\n",
            "\t the loss for timestep 31 is: 0.20081548987776143\n",
            "\t the loss for timestep 32 is: 1.6581379513882428\n",
            "\t the loss for timestep 33 is: 0.2029819338302355\n",
            "\t the loss for timestep 34 is: 164.6094743375549\n",
            "\t the loss for timestep 35 is: 185.1750306753766\n",
            "\t the loss for timestep 36 is: 0.743056465812118\n",
            "\t the loss for timestep 37 is: 0.4950387692485682\n",
            "\t the loss for timestep 38 is: 0.7619887091954386\n",
            "\t the loss for timestep 39 is: 0.5360048372840414\n",
            "\t the loss for timestep 40 is: 0.836939748264153\n",
            "\t the loss for timestep 41 is: 0.4693897031134952\n",
            "\t the loss for timestep 42 is: 0.8820922866078653\n",
            "\t the loss for timestep 43 is: 0.46492218126815155\n",
            "\t the loss for timestep 44 is: 0.9035024463307992\n",
            "\t the loss for timestep 45 is: 0.45144615243017816\n",
            "\t the loss for timestep 46 is: 0.9416455548031554\n",
            "\t the loss for timestep 47 is: 0.4192213375560402\n",
            "\t the loss for timestep 48 is: 1.0264183215406444\n",
            "\t the loss for timestep 49 is: 0.5215654189328242\n",
            "\t the loss for timestep 50 is: 0.9107119332569125\n",
            "\t the loss for timestep 51 is: 0.5192788149496707\n",
            "\t the loss for timestep 52 is: 0.9046625640633682\n",
            "\t the loss for timestep 53 is: 0.5458138534089002\n",
            "\t the loss for timestep 54 is: 0.894964426980768\n",
            "\t the loss for timestep 55 is: 0.5816899295895823\n",
            "\t the loss for timestep 56 is: 0.878543916210843\n",
            "\t the loss for timestep 57 is: 0.6248275002653251\n",
            "\t the loss for timestep 58 is: 0.8603789827746567\n",
            "\t the loss for timestep 59 is: 0.6719770266911399\n",
            "\t the loss for timestep 60 is: 0.8453863564797451\n",
            "\t the loss for timestep 61 is: 0.7191434678863124\n",
            "\t the loss for timestep 62 is: 1.2501511833051262\n",
            "\t the loss for timestep 63 is: 1.2009515173448524\n",
            "\t the loss for timestep 64 is: 2.2319803815242\n",
            "\t the loss for timestep 65 is: 1.7096627182667308\n",
            "\t the loss for timestep 66 is: 0.7579570894009178\n",
            "\t the loss for timestep 67 is: 0.910399820516574\n",
            "\t the loss for timestep 68 is: 0.8160201944914494\n",
            "\t the loss for timestep 69 is: 0.8918613436038632\n",
            "\t the loss for timestep 70 is: 0.8711463666549102\n",
            "\t the loss for timestep 71 is: 0.8998482771938674\n",
            "\t the loss for timestep 72 is: 0.8886627526380757\n",
            "\t the loss for timestep 73 is: 0.9132398700756825\n",
            "\t the loss for timestep 74 is: 0.9157726970059704\n",
            "\t the loss for timestep 75 is: 0.9292873407916116\n",
            "\t the loss for timestep 76 is: 0.9362864533652868\n",
            "\t the loss for timestep 77 is: 0.9456158747067935\n",
            "\t the loss for timestep 78 is: 0.9527568298338915\n",
            "\t the loss for timestep 79 is: 2.5240442701484374\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.8214092309486201\n",
            "\t the loss for timestep 2 is: 1.0747934453815857\n",
            "\t the loss for timestep 3 is: 0.9183582153731124\n",
            "\t the loss for timestep 4 is: 0.9718492508794732\n",
            "\t the loss for timestep 5 is: 2.3702106650483596\n",
            "\t the loss for timestep 6 is: 1.7202075528944067\n",
            "\t the loss for timestep 7 is: 0.642826122255765\n",
            "\t the loss for timestep 8 is: 1.1027988446550074\n",
            "\t the loss for timestep 9 is: 0.842098854916968\n",
            "\t the loss for timestep 10 is: 0.9453604873177472\n",
            "\t the loss for timestep 11 is: 0.8682737405844799\n",
            "\t the loss for timestep 12 is: 0.8919715755224923\n",
            "\t the loss for timestep 13 is: 0.8590505365656366\n",
            "\t the loss for timestep 14 is: 0.8588144879570313\n",
            "\t the loss for timestep 15 is: 0.8383684256572657\n",
            "\t the loss for timestep 16 is: 0.8303190496828267\n",
            "\t the loss for timestep 17 is: 0.8139943163318405\n",
            "\t the loss for timestep 18 is: 0.8031655466824439\n",
            "\t the loss for timestep 19 is: 0.7885176351725289\n",
            "\t the loss for timestep 20 is: 0.7767431067431816\n",
            "\t the loss for timestep 21 is: 0.7630311498404162\n",
            "\t the loss for timestep 22 is: 0.751095313010538\n",
            "\t the loss for timestep 23 is: 0.7381051322221043\n",
            "\t the loss for timestep 24 is: 0.726392812546224\n",
            "\t the loss for timestep 25 is: 0.7140731748131172\n",
            "\t the loss for timestep 26 is: 0.7027896672172558\n",
            "\t the loss for timestep 27 is: 0.6911316512145176\n",
            "\t the loss for timestep 28 is: 0.6803888024110675\n",
            "\t the loss for timestep 29 is: 0.6693854735136092\n",
            "\t the loss for timestep 30 is: 0.6592414299243874\n",
            "\t the loss for timestep 31 is: 0.6488749622095855\n",
            "\t the loss for timestep 32 is: 0.6393557278014219\n",
            "\t the loss for timestep 33 is: 0.6295943491120892\n",
            "\t the loss for timestep 34 is: 172.00074211763612\n",
            "\t the loss for timestep 35 is: 183.18790390395867\n",
            "\t the loss for timestep 36 is: 0.6136398587120147\n",
            "\t the loss for timestep 37 is: 0.6292009647331659\n",
            "\t the loss for timestep 38 is: 0.5927916785318115\n",
            "\t the loss for timestep 39 is: 0.6725465563092993\n",
            "\t the loss for timestep 40 is: 0.5933441544011798\n",
            "\t the loss for timestep 41 is: 0.6380839775210785\n",
            "\t the loss for timestep 42 is: 0.5799330361342447\n",
            "\t the loss for timestep 43 is: 0.6462473504094126\n",
            "\t the loss for timestep 44 is: 0.556117036390003\n",
            "\t the loss for timestep 45 is: 0.6524550358753584\n",
            "\t the loss for timestep 46 is: 0.5387575031850427\n",
            "\t the loss for timestep 47 is: 0.6679273580439805\n",
            "\t the loss for timestep 48 is: 0.6168252676775886\n",
            "\t the loss for timestep 49 is: 0.6710212284674523\n",
            "\t the loss for timestep 50 is: 0.5248314894057692\n",
            "\t the loss for timestep 51 is: 0.6834999051273516\n",
            "\t the loss for timestep 52 is: 0.49614077491136177\n",
            "\t the loss for timestep 53 is: 0.7180120328042835\n",
            "\t the loss for timestep 54 is: 0.463568324113899\n",
            "\t the loss for timestep 55 is: 0.7688908344793337\n",
            "\t the loss for timestep 56 is: 0.4227323598453796\n",
            "\t the loss for timestep 57 is: 0.843220559806937\n",
            "\t the loss for timestep 58 is: 0.37343306016958555\n",
            "\t the loss for timestep 59 is: 0.9514128350122366\n",
            "\t the loss for timestep 60 is: 0.317641930634599\n",
            "\t the loss for timestep 61 is: 1.1051663920620085\n",
            "\t the loss for timestep 62 is: 0.4836806876460969\n",
            "\t the loss for timestep 63 is: 1.4728514215360795\n",
            "\t the loss for timestep 64 is: 1.4490486402936436\n",
            "\t the loss for timestep 65 is: 1.6000216587847915\n",
            "\t the loss for timestep 66 is: 0.3534437712159001\n",
            "\t the loss for timestep 67 is: 1.0091777394355803\n",
            "\t the loss for timestep 68 is: 0.24762627466312667\n",
            "\t the loss for timestep 69 is: 1.2932804166354006\n",
            "\t the loss for timestep 70 is: 0.18742960189609886\n",
            "\t the loss for timestep 71 is: 1.6379532260839689\n",
            "\t the loss for timestep 72 is: 0.15607655132473633\n",
            "\t the loss for timestep 73 is: 1.8481978162087844\n",
            "\t the loss for timestep 74 is: 0.14434649145170747\n",
            "\t the loss for timestep 75 is: 1.9463789263347482\n",
            "\t the loss for timestep 76 is: 0.13908530398823948\n",
            "\t the loss for timestep 77 is: 1.9945685914094011\n",
            "\t the loss for timestep 78 is: 0.13611526697659726\n",
            "\t the loss for timestep 79 is: 3.0436608886681213\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.1332962836195347\n",
            "\t the loss for timestep 2 is: 2.057650919207402\n",
            "\t the loss for timestep 3 is: 0.1338718297416126\n",
            "\t the loss for timestep 4 is: 2.0500488834833153\n",
            "\t the loss for timestep 5 is: 0.137818778965045\n",
            "\t the loss for timestep 6 is: 3.4589259960994037\n",
            "\t the loss for timestep 7 is: 0.12946772938456386\n",
            "\t the loss for timestep 8 is: 2.1098833061258957\n",
            "\t the loss for timestep 9 is: 0.13347071633001611\n",
            "\t the loss for timestep 10 is: 2.055485661239993\n",
            "\t the loss for timestep 11 is: 0.1339469698268334\n",
            "\t the loss for timestep 12 is: 2.049286606351815\n",
            "\t the loss for timestep 13 is: 0.134026500072769\n",
            "\t the loss for timestep 14 is: 2.048333923709448\n",
            "\t the loss for timestep 15 is: 0.13406370613019852\n",
            "\t the loss for timestep 16 is: 2.047959291302017\n",
            "\t the loss for timestep 17 is: 0.13410023112711594\n",
            "\t the loss for timestep 18 is: 2.047612910528737\n",
            "\t the loss for timestep 19 is: 0.1341411916940922\n",
            "\t the loss for timestep 20 is: 2.047228474750092\n",
            "\t the loss for timestep 21 is: 0.13418736129823478\n",
            "\t the loss for timestep 22 is: 2.0467970397576125\n",
            "\t the loss for timestep 23 is: 0.13423902265503804\n",
            "\t the loss for timestep 24 is: 2.046315114984903\n",
            "\t the loss for timestep 25 is: 0.1342964331871971\n",
            "\t the loss for timestep 26 is: 2.0457816699343727\n",
            "\t the loss for timestep 27 is: 0.1343598740043508\n",
            "\t the loss for timestep 28 is: 2.0451932088072047\n",
            "\t the loss for timestep 29 is: 0.1344296578632361\n",
            "\t the loss for timestep 30 is: 2.044548106564909\n",
            "\t the loss for timestep 31 is: 0.13450615216871734\n",
            "\t the loss for timestep 32 is: 2.043843021996317\n",
            "\t the loss for timestep 33 is: 0.13458976222309132\n",
            "\t the loss for timestep 34 is: 162.50466407780235\n",
            "\t the loss for timestep 35 is: 191.95968726481564\n",
            "\t the loss for timestep 36 is: 1.222751189885221\n",
            "\t the loss for timestep 37 is: 0.16025559065570188\n",
            "\t the loss for timestep 38 is: 1.7593530532597978\n",
            "\t the loss for timestep 39 is: 0.14461201071104607\n",
            "\t the loss for timestep 40 is: 2.035654075968446\n",
            "\t the loss for timestep 41 is: 0.137038541664614\n",
            "\t the loss for timestep 42 is: 2.052440497738274\n",
            "\t the loss for timestep 43 is: 0.13897247025282183\n",
            "\t the loss for timestep 44 is: 1.999399424060813\n",
            "\t the loss for timestep 45 is: 0.1400382866808949\n",
            "\t the loss for timestep 46 is: 1.9899421632496346\n",
            "\t the loss for timestep 47 is: 0.13954797636706556\n",
            "\t the loss for timestep 48 is: 1.7469787146634226\n",
            "\t the loss for timestep 49 is: 0.16259561852020105\n",
            "\t the loss for timestep 50 is: 1.7936703718267992\n",
            "\t the loss for timestep 51 is: 0.15057767740645175\n",
            "\t the loss for timestep 52 is: 1.89763501282408\n",
            "\t the loss for timestep 53 is: 0.15016883947092124\n",
            "\t the loss for timestep 54 is: 1.9071538179834\n",
            "\t the loss for timestep 55 is: 0.1527878917842995\n",
            "\t the loss for timestep 56 is: 1.8904577779978524\n",
            "\t the loss for timestep 57 is: 0.15668750597351078\n",
            "\t the loss for timestep 58 is: 1.8653503828514169\n",
            "\t the loss for timestep 59 is: 0.16156980334868354\n",
            "\t the loss for timestep 60 is: 1.8358452864481343\n",
            "\t the loss for timestep 61 is: 0.16750502398284522\n",
            "\t the loss for timestep 62 is: 1.8217642474582747\n",
            "\t the loss for timestep 63 is: 0.6193623931214709\n",
            "\t the loss for timestep 64 is: 2.3607211229458356\n",
            "\t the loss for timestep 65 is: 1.0522168988426615\n",
            "\t the loss for timestep 66 is: 0.6497945168018596\n",
            "\t the loss for timestep 67 is: 0.5694654968186204\n",
            "\t the loss for timestep 68 is: 0.5936554175261448\n",
            "\t the loss for timestep 69 is: 0.5584086054796012\n",
            "\t the loss for timestep 70 is: 0.6097057065324325\n",
            "\t the loss for timestep 71 is: 0.5547936923020849\n",
            "\t the loss for timestep 72 is: 0.6271186540435917\n",
            "\t the loss for timestep 73 is: 0.5535930178537412\n",
            "\t the loss for timestep 74 is: 0.6497394429028807\n",
            "\t the loss for timestep 75 is: 0.5473982396513495\n",
            "\t the loss for timestep 76 is: 0.676241432728192\n",
            "\t the loss for timestep 77 is: 0.5381570232592161\n",
            "\t the loss for timestep 78 is: 0.7076317824904812\n",
            "\t the loss for timestep 79 is: 1.6514872486124688\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.19964873856398085\n",
            "\t the loss for timestep 2 is: 1.7182332218552205\n",
            "\t the loss for timestep 3 is: 0.22923651761952168\n",
            "\t the loss for timestep 4 is: 1.5841861009368474\n",
            "\t the loss for timestep 5 is: 0.3199889887753599\n",
            "\t the loss for timestep 6 is: 2.4849975904192996\n",
            "\t the loss for timestep 7 is: 0.19186669065408096\n",
            "\t the loss for timestep 8 is: 1.7588893749261516\n",
            "\t the loss for timestep 9 is: 0.2250041570462875\n",
            "\t the loss for timestep 10 is: 1.6062525308547024\n",
            "\t the loss for timestep 11 is: 0.24106587670503962\n",
            "\t the loss for timestep 12 is: 1.5397319239902\n",
            "\t the loss for timestep 13 is: 0.24936429278155264\n",
            "\t the loss for timestep 14 is: 1.5075756346948201\n",
            "\t the loss for timestep 15 is: 0.25378602715161597\n",
            "\t the loss for timestep 16 is: 1.4919812002514632\n",
            "\t the loss for timestep 17 is: 0.2561288068473069\n",
            "\t the loss for timestep 18 is: 1.4851698433980398\n",
            "\t the loss for timestep 19 is: 0.25740120875132694\n",
            "\t the loss for timestep 20 is: 1.4830533533853727\n",
            "\t the loss for timestep 21 is: 0.2582740363380815\n",
            "\t the loss for timestep 22 is: 1.48308912494557\n",
            "\t the loss for timestep 23 is: 0.2592807114848928\n",
            "\t the loss for timestep 24 is: 1.4834030805364449\n",
            "\t the loss for timestep 25 is: 0.2609220776776627\n",
            "\t the loss for timestep 26 is: 1.4823889709521054\n",
            "\t the loss for timestep 27 is: 0.26373546189535413\n",
            "\t the loss for timestep 28 is: 1.4785046976315537\n",
            "\t the loss for timestep 29 is: 0.26835415771305704\n",
            "\t the loss for timestep 30 is: 1.4701792792163526\n",
            "\t the loss for timestep 31 is: 0.27557509598244445\n",
            "\t the loss for timestep 32 is: 1.455776872900198\n",
            "\t the loss for timestep 33 is: 0.2864442476245216\n",
            "\t the loss for timestep 34 is: 166.13169060872366\n",
            "\t the loss for timestep 35 is: 184.28942492458071\n",
            "\t the loss for timestep 36 is: 0.9013030807277648\n",
            "\t the loss for timestep 37 is: 0.554043302485421\n",
            "\t the loss for timestep 38 is: 0.873906919923799\n",
            "\t the loss for timestep 39 is: 0.6142937137695348\n",
            "\t the loss for timestep 40 is: 0.9164073822971244\n",
            "\t the loss for timestep 41 is: 0.5695312446453372\n",
            "\t the loss for timestep 42 is: 0.9224147764851607\n",
            "\t the loss for timestep 43 is: 0.5882779898365278\n",
            "\t the loss for timestep 44 is: 0.9025682336864197\n",
            "\t the loss for timestep 45 is: 0.6017904351597579\n",
            "\t the loss for timestep 46 is: 0.899940380778868\n",
            "\t the loss for timestep 47 is: 0.622202369499311\n",
            "\t the loss for timestep 48 is: 0.9698182070971588\n",
            "\t the loss for timestep 49 is: 0.7013953205674567\n",
            "\t the loss for timestep 50 is: 0.8488037273862977\n",
            "\t the loss for timestep 51 is: 0.7131431269916837\n",
            "\t the loss for timestep 52 is: 0.8379113543813496\n",
            "\t the loss for timestep 53 is: 0.7345174534315702\n",
            "\t the loss for timestep 54 is: 0.8348909336322174\n",
            "\t the loss for timestep 55 is: 0.7558207147660119\n",
            "\t the loss for timestep 56 is: 0.8326150420005412\n",
            "\t the loss for timestep 57 is: 0.775094677773468\n",
            "\t the loss for timestep 58 is: 0.8314310629410679\n",
            "\t the loss for timestep 59 is: 0.7917059830069348\n",
            "\t the loss for timestep 60 is: 0.8313800136875245\n",
            "\t the loss for timestep 61 is: 0.8053587997089826\n",
            "\t the loss for timestep 62 is: 1.2324572524027029\n",
            "\t the loss for timestep 63 is: 1.2383286006094951\n",
            "\t the loss for timestep 64 is: 2.3112828658157083\n",
            "\t the loss for timestep 65 is: 2.030160490729357\n",
            "\t the loss for timestep 66 is: 0.7012065098601378\n",
            "\t the loss for timestep 67 is: 0.9738764409262608\n",
            "\t the loss for timestep 68 is: 0.7384400068868641\n",
            "\t the loss for timestep 69 is: 0.9133407736484676\n",
            "\t the loss for timestep 70 is: 0.787651636215436\n",
            "\t the loss for timestep 71 is: 0.8787965517385622\n",
            "\t the loss for timestep 72 is: 0.7981569753301001\n",
            "\t the loss for timestep 73 is: 0.8579830436697955\n",
            "\t the loss for timestep 74 is: 0.8117563397075707\n",
            "\t the loss for timestep 75 is: 0.8428485518716673\n",
            "\t the loss for timestep 76 is: 0.8164886211328712\n",
            "\t the loss for timestep 77 is: 0.8315340573438835\n",
            "\t the loss for timestep 78 is: 0.8156150094291921\n",
            "\t the loss for timestep 79 is: 2.463683491964241\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.40670716176800276\n",
            "\t the loss for timestep 2 is: 1.3093205200984614\n",
            "\t the loss for timestep 3 is: 0.5717567575325797\n",
            "\t the loss for timestep 4 is: 1.0471913792917813\n",
            "\t the loss for timestep 5 is: 2.1007483595639256\n",
            "\t the loss for timestep 6 is: 1.4629795348894032\n",
            "\t the loss for timestep 7 is: 0.4947154433194382\n",
            "\t the loss for timestep 8 is: 1.1058418276542994\n",
            "\t the loss for timestep 9 is: 0.6177307613756695\n",
            "\t the loss for timestep 10 is: 0.9587253814037897\n",
            "\t the loss for timestep 11 is: 0.6736331324814396\n",
            "\t the loss for timestep 12 is: 0.8801123258047715\n",
            "\t the loss for timestep 13 is: 0.7020506674795017\n",
            "\t the loss for timestep 14 is: 0.8320252242497925\n",
            "\t the loss for timestep 15 is: 0.7134754341783844\n",
            "\t the loss for timestep 16 is: 0.7987302317565993\n",
            "\t the loss for timestep 17 is: 0.7146707711753468\n",
            "\t the loss for timestep 18 is: 0.7730866104015645\n",
            "\t the loss for timestep 19 is: 0.7096394775484902\n",
            "\t the loss for timestep 20 is: 0.7516211952237388\n",
            "\t the loss for timestep 21 is: 0.7007553990088355\n",
            "\t the loss for timestep 22 is: 0.7325952112845424\n",
            "\t the loss for timestep 23 is: 0.6894465619595744\n",
            "\t the loss for timestep 24 is: 0.7151407939686305\n",
            "\t the loss for timestep 25 is: 0.676585450464948\n",
            "\t the loss for timestep 26 is: 0.6988486841692371\n",
            "\t the loss for timestep 27 is: 0.662704046686362\n",
            "\t the loss for timestep 28 is: 0.6835651766814548\n",
            "\t the loss for timestep 29 is: 0.648108934149371\n",
            "\t the loss for timestep 30 is: 0.6692969692951911\n",
            "\t the loss for timestep 31 is: 0.6329364509981003\n",
            "\t the loss for timestep 32 is: 0.6561761156868414\n",
            "\t the loss for timestep 33 is: 0.6171676379150222\n",
            "\t the loss for timestep 34 is: 171.9826749848174\n",
            "\t the loss for timestep 35 is: 183.8711083400652\n",
            "\t the loss for timestep 36 is: 0.6759061744241992\n",
            "\t the loss for timestep 37 is: 0.5815859094677542\n",
            "\t the loss for timestep 38 is: 0.6669227253640234\n",
            "\t the loss for timestep 39 is: 0.6075427440427486\n",
            "\t the loss for timestep 40 is: 0.6888034668922816\n",
            "\t the loss for timestep 41 is: 0.5650863721235078\n",
            "\t the loss for timestep 42 is: 0.6986335304051183\n",
            "\t the loss for timestep 43 is: 0.5525069438735012\n",
            "\t the loss for timestep 44 is: 0.7039331861560202\n",
            "\t the loss for timestep 45 is: 0.5354112511791015\n",
            "\t the loss for timestep 46 is: 0.724180088168732\n",
            "\t the loss for timestep 47 is: 0.5222497789947951\n",
            "\t the loss for timestep 48 is: 0.8265658172363567\n",
            "\t the loss for timestep 49 is: 0.537739633782914\n",
            "\t the loss for timestep 50 is: 0.7485820765338265\n",
            "\t the loss for timestep 51 is: 0.5174001744533998\n",
            "\t the loss for timestep 52 is: 0.7717937085414304\n",
            "\t the loss for timestep 53 is: 0.5080504057955808\n",
            "\t the loss for timestep 54 is: 0.8007158693502406\n",
            "\t the loss for timestep 55 is: 0.5036957482541131\n",
            "\t the loss for timestep 56 is: 0.8282743195258337\n",
            "\t the loss for timestep 57 is: 0.5071776891293529\n",
            "\t the loss for timestep 58 is: 0.8507773388341198\n",
            "\t the loss for timestep 59 is: 0.5217551234341522\n",
            "\t the loss for timestep 60 is: 0.8647708609575349\n",
            "\t the loss for timestep 61 is: 0.5501286560296778\n",
            "\t the loss for timestep 62 is: 1.349500056524008\n",
            "\t the loss for timestep 63 is: 1.1980511064866226\n",
            "\t the loss for timestep 64 is: 2.1338829859120114\n",
            "\t the loss for timestep 65 is: 1.3928683239934023\n",
            "\t the loss for timestep 66 is: 0.8374232813818651\n",
            "\t the loss for timestep 67 is: 0.8100770342249792\n",
            "\t the loss for timestep 68 is: 0.784508708975837\n",
            "\t the loss for timestep 69 is: 0.8120840286952482\n",
            "\t the loss for timestep 70 is: 0.8164206333085909\n",
            "\t the loss for timestep 71 is: 0.8364651262337712\n",
            "\t the loss for timestep 72 is: 0.842764694417537\n",
            "\t the loss for timestep 73 is: 0.8647301076351812\n",
            "\t the loss for timestep 74 is: 0.872351930886258\n",
            "\t the loss for timestep 75 is: 0.8890741824301742\n",
            "\t the loss for timestep 76 is: 0.898138177070512\n",
            "\t the loss for timestep 77 is: 0.9109129920876496\n",
            "\t the loss for timestep 78 is: 0.919443947635096\n",
            "\t the loss for timestep 79 is: 1.9320345127332235\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.7585390270324786\n",
            "\t the loss for timestep 2 is: 1.1801866645692205\n",
            "\t the loss for timestep 3 is: 0.8337267978295791\n",
            "\t the loss for timestep 4 is: 1.012783275612915\n",
            "\t the loss for timestep 5 is: 1.6002145363897775\n",
            "\t the loss for timestep 6 is: 1.1497320802084083\n",
            "\t the loss for timestep 7 is: 0.8112071737833926\n",
            "\t the loss for timestep 8 is: 0.9900341418820003\n",
            "\t the loss for timestep 9 is: 0.8374536443765634\n",
            "\t the loss for timestep 10 is: 0.9179463228517569\n",
            "\t the loss for timestep 11 is: 0.8392412339525283\n",
            "\t the loss for timestep 12 is: 0.8735834660519917\n",
            "\t the loss for timestep 13 is: 0.8248904305696305\n",
            "\t the loss for timestep 14 is: 0.8369905572748435\n",
            "\t the loss for timestep 15 is: 0.8022411952002878\n",
            "\t the loss for timestep 16 is: 0.8032057096956402\n",
            "\t the loss for timestep 17 is: 0.7754460779139417\n",
            "\t the loss for timestep 18 is: 0.7707773354773202\n",
            "\t the loss for timestep 19 is: 0.7469089113278732\n",
            "\t the loss for timestep 20 is: 0.7395306636414235\n",
            "\t the loss for timestep 21 is: 0.7181173971052383\n",
            "\t the loss for timestep 22 is: 0.709699965963873\n",
            "\t the loss for timestep 23 is: 0.690018363849288\n",
            "\t the loss for timestep 24 is: 0.681585903953687\n",
            "\t the loss for timestep 25 is: 0.6631923899160109\n",
            "\t the loss for timestep 26 is: 0.6554298190351726\n",
            "\t the loss for timestep 27 is: 0.6379506008434258\n",
            "\t the loss for timestep 28 is: 0.6313847674585986\n",
            "\t the loss for timestep 29 is: 0.6143958673658287\n",
            "\t the loss for timestep 30 is: 0.6095382401550126\n",
            "\t the loss for timestep 31 is: 0.5924625275839718\n",
            "\t the loss for timestep 32 is: 0.5899575458346737\n",
            "\t the loss for timestep 33 is: 0.5719268099571855\n",
            "\t the loss for timestep 34 is: 173.2605582525353\n",
            "\t the loss for timestep 35 is: 182.44893987596342\n",
            "\t the loss for timestep 36 is: 0.46876651759864085\n",
            "\t the loss for timestep 37 is: 0.7125977928417945\n",
            "\t the loss for timestep 38 is: 0.4053416243789575\n",
            "\t the loss for timestep 39 is: 0.8674556364197563\n",
            "\t the loss for timestep 40 is: 0.3531423168262829\n",
            "\t the loss for timestep 41 is: 0.9420317638590401\n",
            "\t the loss for timestep 42 is: 0.28253013189655274\n",
            "\t the loss for timestep 43 is: 1.1746463522605446\n",
            "\t the loss for timestep 44 is: 0.21494772967432282\n",
            "\t the loss for timestep 45 is: 1.4576452111240914\n",
            "\t the loss for timestep 46 is: 0.1768674333685266\n",
            "\t the loss for timestep 47 is: 1.5258595117971538\n",
            "\t the loss for timestep 48 is: 0.18392574015052027\n",
            "\t the loss for timestep 49 is: 1.6657413337968427\n",
            "\t the loss for timestep 50 is: 0.1594624399284556\n",
            "\t the loss for timestep 51 is: 1.8350805129495318\n",
            "\t the loss for timestep 52 is: 0.15104394815019279\n",
            "\t the loss for timestep 53 is: 1.9059477800249085\n",
            "\t the loss for timestep 54 is: 0.14787886513706583\n",
            "\t the loss for timestep 55 is: 1.9334951175288466\n",
            "\t the loss for timestep 56 is: 0.1463275707187586\n",
            "\t the loss for timestep 57 is: 1.9469317971147404\n",
            "\t the loss for timestep 58 is: 0.1452941676529511\n",
            "\t the loss for timestep 59 is: 1.955853471828119\n",
            "\t the loss for timestep 60 is: 0.14446965850143767\n",
            "\t the loss for timestep 61 is: 1.9630198593778245\n",
            "\t the loss for timestep 62 is: 0.15711291898216195\n",
            "\t the loss for timestep 63 is: 2.1354115584928186\n",
            "\t the loss for timestep 64 is: 0.6369959466897657\n",
            "\t the loss for timestep 65 is: 2.3490716883608895\n",
            "\t the loss for timestep 66 is: 0.16430467817131808\n",
            "\t the loss for timestep 67 is: 1.798251909492071\n",
            "\t the loss for timestep 68 is: 0.14644604002678147\n",
            "\t the loss for timestep 69 is: 1.9416746695332425\n",
            "\t the loss for timestep 70 is: 0.14238939397756692\n",
            "\t the loss for timestep 71 is: 2.000120506464151\n",
            "\t the loss for timestep 72 is: 0.14083751222287422\n",
            "\t the loss for timestep 73 is: 1.9959363172106748\n",
            "\t the loss for timestep 74 is: 0.14068840295928653\n",
            "\t the loss for timestep 75 is: 1.9973142187323591\n",
            "\t the loss for timestep 76 is: 0.14042862012012663\n",
            "\t the loss for timestep 77 is: 1.9998505222699712\n",
            "\t the loss for timestep 78 is: 0.14018002961033144\n",
            "\t the loss for timestep 79 is: 3.0348909855595503\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.13793889394802528\n",
            "\t the loss for timestep 2 is: 2.025038089943736\n",
            "\t the loss for timestep 3 is: 0.13956242176319647\n",
            "\t the loss for timestep 4 is: 2.008569885066972\n",
            "\t the loss for timestep 5 is: 0.17505032869053178\n",
            "\t the loss for timestep 6 is: 3.1572849251634643\n",
            "\t the loss for timestep 7 is: 0.13161324190895893\n",
            "\t the loss for timestep 8 is: 2.091036752766432\n",
            "\t the loss for timestep 9 is: 0.13867736689412619\n",
            "\t the loss for timestep 10 is: 2.0181048475369927\n",
            "\t the loss for timestep 11 is: 0.14002187840245722\n",
            "\t the loss for timestep 12 is: 2.004913888050373\n",
            "\t the loss for timestep 13 is: 0.14041413391681343\n",
            "\t the loss for timestep 14 is: 2.001394442937466\n",
            "\t the loss for timestep 15 is: 0.14065491989990464\n",
            "\t the loss for timestep 16 is: 1.9994612854091602\n",
            "\t the loss for timestep 17 is: 0.14089075968658354\n",
            "\t the loss for timestep 18 is: 1.9976503368488694\n",
            "\t the loss for timestep 19 is: 0.14115061544262758\n",
            "\t the loss for timestep 20 is: 1.9956812113285618\n",
            "\t the loss for timestep 21 is: 0.14144195403173168\n",
            "\t the loss for timestep 22 is: 1.9934896918911285\n",
            "\t the loss for timestep 23 is: 0.14176857361580464\n",
            "\t the loss for timestep 24 is: 1.991048728180963\n",
            "\t the loss for timestep 25 is: 0.14213400615033542\n",
            "\t the loss for timestep 26 is: 1.9883379164942898\n",
            "\t the loss for timestep 27 is: 0.14254219656300618\n",
            "\t the loss for timestep 28 is: 1.985333099922523\n",
            "\t the loss for timestep 29 is: 0.1429977447442338\n",
            "\t the loss for timestep 30 is: 1.9820087546474585\n",
            "\t the loss for timestep 31 is: 0.14350606062706278\n",
            "\t the loss for timestep 32 is: 1.978333993522331\n",
            "\t the loss for timestep 33 is: 0.14407350947546715\n",
            "\t the loss for timestep 34 is: 162.81464725574898\n",
            "\t the loss for timestep 35 is: 190.1425174803249\n",
            "\t the loss for timestep 36 is: 1.1220901221190445\n",
            "\t the loss for timestep 37 is: 0.2118194934356063\n",
            "\t the loss for timestep 38 is: 1.4818595262725442\n",
            "\t the loss for timestep 39 is: 0.18358723257544837\n",
            "\t the loss for timestep 40 is: 1.7971029397692262\n",
            "\t the loss for timestep 41 is: 0.16162995954258058\n",
            "\t the loss for timestep 42 is: 1.8827747950450018\n",
            "\t the loss for timestep 43 is: 0.164490284980201\n",
            "\t the loss for timestep 44 is: 1.8433314923161555\n",
            "\t the loss for timestep 45 is: 0.17056023510648638\n",
            "\t the loss for timestep 46 is: 1.8106722533418462\n",
            "\t the loss for timestep 47 is: 0.17364237546151365\n",
            "\t the loss for timestep 48 is: 1.603968697188406\n",
            "\t the loss for timestep 49 is: 0.24333839435623666\n",
            "\t the loss for timestep 50 is: 1.4911725331088967\n",
            "\t the loss for timestep 51 is: 0.23886199957481927\n",
            "\t the loss for timestep 52 is: 1.5060237677171027\n",
            "\t the loss for timestep 53 is: 0.2558230659744482\n",
            "\t the loss for timestep 54 is: 1.467112274017437\n",
            "\t the loss for timestep 55 is: 0.28645621496468643\n",
            "\t the loss for timestep 56 is: 1.3922031485265491\n",
            "\t the loss for timestep 57 is: 0.33221319908429053\n",
            "\t the loss for timestep 58 is: 1.2956496317467399\n",
            "\t the loss for timestep 59 is: 0.3956036653605552\n",
            "\t the loss for timestep 60 is: 1.1899825290054686\n",
            "\t the loss for timestep 61 is: 0.47796604104590895\n",
            "\t the loss for timestep 62 is: 1.504061656783136\n",
            "\t the loss for timestep 63 is: 1.1817181080036627\n",
            "\t the loss for timestep 64 is: 2.2694980039662105\n",
            "\t the loss for timestep 65 is: 1.6446469715151284\n",
            "\t the loss for timestep 66 is: 0.8417046463534712\n",
            "\t the loss for timestep 67 is: 0.9128248228435835\n",
            "\t the loss for timestep 68 is: 0.845553981458908\n",
            "\t the loss for timestep 69 is: 0.9099165415143569\n",
            "\t the loss for timestep 70 is: 0.9036030691795224\n",
            "\t the loss for timestep 71 is: 0.9361743422102557\n",
            "\t the loss for timestep 72 is: 0.9389469339783119\n",
            "\t the loss for timestep 73 is: 0.9695116971533382\n",
            "\t the loss for timestep 74 is: 0.981189544274708\n",
            "\t the loss for timestep 75 is: 1.0022266662640744\n",
            "\t the loss for timestep 76 is: 1.0175065347460208\n",
            "\t the loss for timestep 77 is: 1.0342712406019374\n",
            "\t the loss for timestep 78 is: 1.048842878135685\n",
            "\t the loss for timestep 79 is: 2.426004947624711\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.8887207841597793\n",
            "\t the loss for timestep 2 is: 1.152940191085222\n",
            "\t the loss for timestep 3 is: 1.0313059760906513\n",
            "\t the loss for timestep 4 is: 1.063992875427663\n",
            "\t the loss for timestep 5 is: 2.275809005825205\n",
            "\t the loss for timestep 6 is: 1.6550658173320696\n",
            "\t the loss for timestep 7 is: 0.7749239610524399\n",
            "\t the loss for timestep 8 is: 1.154232330894891\n",
            "\t the loss for timestep 9 is: 0.9386968136464405\n",
            "\t the loss for timestep 10 is: 1.0090193921339072\n",
            "\t the loss for timestep 11 is: 0.949670394241072\n",
            "\t the loss for timestep 12 is: 0.9548615540592174\n",
            "\t the loss for timestep 13 is: 0.9263157142468014\n",
            "\t the loss for timestep 14 is: 0.9153683695239547\n",
            "\t the loss for timestep 15 is: 0.894174118814108\n",
            "\t the loss for timestep 16 is: 0.8789024425861914\n",
            "\t the loss for timestep 17 is: 0.8600147085870086\n",
            "\t the loss for timestep 18 is: 0.8436688287556944\n",
            "\t the loss for timestep 19 is: 0.8259651644745608\n",
            "\t the loss for timestep 20 is: 0.8096882649141792\n",
            "\t the loss for timestep 21 is: 0.7929570347476563\n",
            "\t the loss for timestep 22 is: 0.7772393640566018\n",
            "\t the loss for timestep 23 is: 0.7614734882897277\n",
            "\t the loss for timestep 24 is: 0.7465462678612237\n",
            "\t the loss for timestep 25 is: 0.7317632900496801\n",
            "\t the loss for timestep 26 is: 0.7177308768853359\n",
            "\t the loss for timestep 27 is: 0.7039293364439396\n",
            "\t the loss for timestep 28 is: 0.6908244337970845\n",
            "\t the loss for timestep 29 is: 0.6779789930793674\n",
            "\t the loss for timestep 30 is: 0.6657929444081742\n",
            "\t the loss for timestep 31 is: 0.653858521252821\n",
            "\t the loss for timestep 32 is: 0.6425585767410664\n",
            "\t the loss for timestep 33 is: 0.6314765470741748\n",
            "\t the loss for timestep 34 is: 172.16677035905556\n",
            "\t the loss for timestep 35 is: 181.73413104262505\n",
            "\t the loss for timestep 36 is: 0.5461611116966363\n",
            "\t the loss for timestep 37 is: 0.7177095777931216\n",
            "\t the loss for timestep 38 is: 0.500749331228704\n",
            "\t the loss for timestep 39 is: 0.8047105225818448\n",
            "\t the loss for timestep 40 is: 0.47197954558532584\n",
            "\t the loss for timestep 41 is: 0.797916439435524\n",
            "\t the loss for timestep 42 is: 0.42718113604685276\n",
            "\t the loss for timestep 43 is: 0.8747358746337699\n",
            "\t the loss for timestep 44 is: 0.36587027084959456\n",
            "\t the loss for timestep 45 is: 0.9796393811189608\n",
            "\t the loss for timestep 46 is: 0.30880666863721584\n",
            "\t the loss for timestep 47 is: 1.0867625677845076\n",
            "\t the loss for timestep 48 is: 0.33399590605906104\n",
            "\t the loss for timestep 49 is: 1.140777536269835\n",
            "\t the loss for timestep 50 is: 0.25279169604691154\n",
            "\t the loss for timestep 51 is: 1.350248875351077\n",
            "\t the loss for timestep 52 is: 0.21016381044201532\n",
            "\t the loss for timestep 53 is: 1.5589035469741144\n",
            "\t the loss for timestep 54 is: 0.18680305148398363\n",
            "\t the loss for timestep 55 is: 1.6991878424314013\n",
            "\t the loss for timestep 56 is: 0.17696556472405647\n",
            "\t the loss for timestep 57 is: 1.7655130594011552\n",
            "\t the loss for timestep 58 is: 0.17455029223697505\n",
            "\t the loss for timestep 59 is: 1.7853951280396008\n",
            "\t the loss for timestep 60 is: 0.17587038880076283\n",
            "\t the loss for timestep 61 is: 1.781597640904128\n",
            "\t the loss for timestep 62 is: 0.24833961716774047\n",
            "\t the loss for timestep 63 is: 1.908657673882128\n",
            "\t the loss for timestep 64 is: 1.2426372365409368\n",
            "\t the loss for timestep 65 is: 1.9321688317512504\n",
            "\t the loss for timestep 66 is: 0.32953015529137986\n",
            "\t the loss for timestep 67 is: 1.190582123971192\n",
            "\t the loss for timestep 68 is: 0.26127523667839475\n",
            "\t the loss for timestep 69 is: 1.362473999513123\n",
            "\t the loss for timestep 70 is: 0.2347639994332315\n",
            "\t the loss for timestep 71 is: 1.5034049545833585\n",
            "\t the loss for timestep 72 is: 0.22267546233872534\n",
            "\t the loss for timestep 73 is: 1.5591311906419132\n",
            "\t the loss for timestep 74 is: 0.22266736576073026\n",
            "\t the loss for timestep 75 is: 1.5684385733276118\n",
            "\t the loss for timestep 76 is: 0.2275708142188538\n",
            "\t the loss for timestep 77 is: 1.5548494004151425\n",
            "\t the loss for timestep 78 is: 0.23516577881832826\n",
            "\t the loss for timestep 79 is: 2.777587536719433\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.19885085551937381\n",
            "\t the loss for timestep 2 is: 1.7062006934641272\n",
            "\t the loss for timestep 3 is: 0.2263453743223936\n",
            "\t the loss for timestep 4 is: 1.577658950997391\n",
            "\t the loss for timestep 5 is: 0.289569510400798\n",
            "\t the loss for timestep 6 is: 2.56964751411561\n",
            "\t the loss for timestep 7 is: 0.18923859439898408\n",
            "\t the loss for timestep 8 is: 1.7583693239348475\n",
            "\t the loss for timestep 9 is: 0.22093622062287094\n",
            "\t the loss for timestep 10 is: 1.6053251209873074\n",
            "\t the loss for timestep 11 is: 0.23522349464816825\n",
            "\t the loss for timestep 12 is: 1.5437988727634662\n",
            "\t the loss for timestep 13 is: 0.2417146439662278\n",
            "\t the loss for timestep 14 is: 1.5175689418220852\n",
            "\t the loss for timestep 15 is: 0.24438845503183412\n",
            "\t the loss for timestep 16 is: 1.5080818707929722\n",
            "\t the loss for timestep 17 is: 0.2450127309894686\n",
            "\t the loss for timestep 18 is: 1.5075058206601621\n",
            "\t the loss for timestep 19 is: 0.24453271172922272\n",
            "\t the loss for timestep 20 is: 1.5118722509146678\n",
            "\t the loss for timestep 21 is: 0.24354102854436416\n",
            "\t the loss for timestep 22 is: 1.518804708448402\n",
            "\t the loss for timestep 23 is: 0.24247771149278705\n",
            "\t the loss for timestep 24 is: 1.526607429154954\n",
            "\t the loss for timestep 25 is: 0.24172647714294002\n",
            "\t the loss for timestep 26 is: 1.5338586975119728\n",
            "\t the loss for timestep 27 is: 0.24166959205640226\n",
            "\t the loss for timestep 28 is: 1.5392088717021024\n",
            "\t the loss for timestep 29 is: 0.24272765277404146\n",
            "\t the loss for timestep 30 is: 1.5412853532887505\n",
            "\t the loss for timestep 31 is: 0.24540094760312647\n",
            "\t the loss for timestep 32 is: 1.538637474802801\n",
            "\t the loss for timestep 33 is: 0.25032181434503775\n",
            "\t the loss for timestep 34 is: 165.54118127054159\n",
            "\t the loss for timestep 35 is: 184.8787320260006\n",
            "\t the loss for timestep 36 is: 0.8936945691576206\n",
            "\t the loss for timestep 37 is: 0.5133782357024852\n",
            "\t the loss for timestep 38 is: 0.8806349667175877\n",
            "\t the loss for timestep 39 is: 0.557113309878581\n",
            "\t the loss for timestep 40 is: 0.9423165025703735\n",
            "\t the loss for timestep 41 is: 0.4990531797119303\n",
            "\t the loss for timestep 42 is: 0.9715553052667548\n",
            "\t the loss for timestep 43 is: 0.5001256631290436\n",
            "\t the loss for timestep 44 is: 0.972714408430504\n",
            "\t the loss for timestep 45 is: 0.4970576912869923\n",
            "\t the loss for timestep 46 is: 0.9903544161397301\n",
            "\t the loss for timestep 47 is: 0.5386745867242935\n",
            "\t the loss for timestep 48 is: 1.0487613237847748\n",
            "\t the loss for timestep 49 is: 0.592405965131742\n",
            "\t the loss for timestep 50 is: 0.9154097271411384\n",
            "\t the loss for timestep 51 is: 0.5991215832354377\n",
            "\t the loss for timestep 52 is: 0.9056467081041658\n",
            "\t the loss for timestep 53 is: 0.621702583256754\n",
            "\t the loss for timestep 54 is: 0.8990765342532789\n",
            "\t the loss for timestep 55 is: 0.6502173294556383\n",
            "\t the loss for timestep 56 is: 0.889213095728086\n",
            "\t the loss for timestep 57 is: 0.6823907070979567\n",
            "\t the loss for timestep 58 is: 0.8781991597662223\n",
            "\t the loss for timestep 59 is: 0.7162628035361284\n",
            "\t the loss for timestep 60 is: 0.8682274902819781\n",
            "\t the loss for timestep 61 is: 0.7496146121242654\n",
            "\t the loss for timestep 62 is: 1.279138820022942\n",
            "\t the loss for timestep 63 is: 1.1955927997372238\n",
            "\t the loss for timestep 64 is: 2.28948669348473\n",
            "\t the loss for timestep 65 is: 2.0569267776621487\n",
            "\t the loss for timestep 66 is: 0.7267753207323613\n",
            "\t the loss for timestep 67 is: 0.973983557548072\n",
            "\t the loss for timestep 68 is: 0.7614392923397032\n",
            "\t the loss for timestep 69 is: 0.9265462206172085\n",
            "\t the loss for timestep 70 is: 0.8212203923984953\n",
            "\t the loss for timestep 71 is: 0.9029143568857407\n",
            "\t the loss for timestep 72 is: 0.8396992731719569\n",
            "\t the loss for timestep 73 is: 0.8922942788414805\n",
            "\t the loss for timestep 74 is: 0.8625637794672112\n",
            "\t the loss for timestep 75 is: 0.8878661343732951\n",
            "\t the loss for timestep 76 is: 0.8753300805996551\n",
            "\t the loss for timestep 77 is: 0.886889325863191\n",
            "\t the loss for timestep 78 is: 0.8817178265287714\n",
            "\t the loss for timestep 79 is: 2.539357400062142\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.51418673084486\n",
            "\t the loss for timestep 2 is: 1.2318047993087884\n",
            "\t the loss for timestep 3 is: 0.7135104724933298\n",
            "\t the loss for timestep 4 is: 1.004186315767914\n",
            "\t the loss for timestep 5 is: 2.3358693112380684\n",
            "\t the loss for timestep 6 is: 1.5784049216835794\n",
            "\t the loss for timestep 7 is: 0.5316162160839212\n",
            "\t the loss for timestep 8 is: 1.1354731728510603\n",
            "\t the loss for timestep 9 is: 0.7021603121248303\n",
            "\t the loss for timestep 10 is: 0.963807168451867\n",
            "\t the loss for timestep 11 is: 0.7618022002410414\n",
            "\t the loss for timestep 12 is: 0.8856038821689296\n",
            "\t the loss for timestep 13 is: 0.7808543346802698\n",
            "\t the loss for timestep 14 is: 0.8410947511818246\n",
            "\t the loss for timestep 15 is: 0.7801526645439437\n",
            "\t the loss for timestep 16 is: 0.8097429097914377\n",
            "\t the loss for timestep 17 is: 0.7699263140193848\n",
            "\t the loss for timestep 18 is: 0.7839867362431795\n",
            "\t the loss for timestep 19 is: 0.7550040896845989\n",
            "\t the loss for timestep 20 is: 0.7608480123377694\n",
            "\t the loss for timestep 21 is: 0.7377627046390577\n",
            "\t the loss for timestep 22 is: 0.7391410113616033\n",
            "\t the loss for timestep 23 is: 0.7194499996908065\n",
            "\t the loss for timestep 24 is: 0.7184159399414006\n",
            "\t the loss for timestep 25 is: 0.7007660451154499\n",
            "\t the loss for timestep 26 is: 0.6985308656493894\n",
            "\t the loss for timestep 27 is: 0.6821226360020531\n",
            "\t the loss for timestep 28 is: 0.6794708474299209\n",
            "\t the loss for timestep 29 is: 0.6637640229399208\n",
            "\t the loss for timestep 30 is: 0.6612730407875755\n",
            "\t the loss for timestep 31 is: 0.64582442627792\n",
            "\t the loss for timestep 32 is: 0.6439984700030863\n",
            "\t the loss for timestep 33 is: 0.6283536869720405\n",
            "\t the loss for timestep 34 is: 172.38992087405035\n",
            "\t the loss for timestep 35 is: 184.47021302412816\n",
            "\t the loss for timestep 36 is: 0.7117984448825492\n",
            "\t the loss for timestep 37 is: 0.5388058826402284\n",
            "\t the loss for timestep 38 is: 0.7098756924729562\n",
            "\t the loss for timestep 39 is: 0.5434750929997826\n",
            "\t the loss for timestep 40 is: 0.7482357449374295\n",
            "\t the loss for timestep 41 is: 0.4917803480437358\n",
            "\t the loss for timestep 42 is: 0.7805099776791672\n",
            "\t the loss for timestep 43 is: 0.4578444936258599\n",
            "\t the loss for timestep 44 is: 0.8221450699051589\n",
            "\t the loss for timestep 45 is: 0.418925012913829\n",
            "\t the loss for timestep 46 is: 0.8935093425754677\n",
            "\t the loss for timestep 47 is: 0.3959039052319617\n",
            "\t the loss for timestep 48 is: 1.0138529421224665\n",
            "\t the loss for timestep 49 is: 0.3992727865385098\n",
            "\t the loss for timestep 50 is: 0.9678145495788465\n",
            "\t the loss for timestep 51 is: 0.36102721776842306\n",
            "\t the loss for timestep 52 is: 1.0590302035437527\n",
            "\t the loss for timestep 53 is: 0.339320792048088\n",
            "\t the loss for timestep 54 is: 1.1444014862042595\n",
            "\t the loss for timestep 55 is: 0.3348029720170829\n",
            "\t the loss for timestep 56 is: 1.1954313192177373\n",
            "\t the loss for timestep 57 is: 0.3539993834963179\n",
            "\t the loss for timestep 58 is: 1.1956970306926686\n",
            "\t the loss for timestep 59 is: 0.4037629408929423\n",
            "\t the loss for timestep 60 is: 1.147207403697411\n",
            "\t the loss for timestep 61 is: 0.4891806245515369\n",
            "\t the loss for timestep 62 is: 1.50886830215698\n",
            "\t the loss for timestep 63 is: 1.279254674678981\n",
            "\t the loss for timestep 64 is: 2.2161859171785805\n",
            "\t the loss for timestep 65 is: 1.4811446602048413\n",
            "\t the loss for timestep 66 is: 1.0001188476995855\n",
            "\t the loss for timestep 67 is: 0.9465144326750531\n",
            "\t the loss for timestep 68 is: 0.9588357801508314\n",
            "\t the loss for timestep 69 is: 0.984862472942248\n",
            "\t the loss for timestep 70 is: 1.0259612580200956\n",
            "\t the loss for timestep 71 is: 1.0567507094763335\n",
            "\t the loss for timestep 72 is: 1.0904261926845802\n",
            "\t the loss for timestep 73 is: 1.1265781247214899\n",
            "\t the loss for timestep 74 is: 1.1579711059994242\n",
            "\t the loss for timestep 75 is: 1.1886100108436122\n",
            "\t the loss for timestep 76 is: 1.2161746739497707\n",
            "\t the loss for timestep 77 is: 1.2412429875521658\n",
            "\t the loss for timestep 78 is: 1.2632413802745233\n",
            "\t the loss for timestep 79 is: 2.000582452256738\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 1.25896091938332\n",
            "\t the loss for timestep 2 is: 1.3565681431855394\n",
            "\t the loss for timestep 3 is: 1.2786944009309786\n",
            "\t the loss for timestep 4 is: 1.2908875512100435\n",
            "\t the loss for timestep 5 is: 1.97818110176332\n",
            "\t the loss for timestep 6 is: 1.6236577022635696\n",
            "\t the loss for timestep 7 is: 1.1510586082430916\n",
            "\t the loss for timestep 8 is: 1.272566206899418\n",
            "\t the loss for timestep 9 is: 1.1755132995159303\n",
            "\t the loss for timestep 10 is: 1.1777616936908706\n",
            "\t the loss for timestep 11 is: 1.134042363643743\n",
            "\t the loss for timestep 12 is: 1.110427685717958\n",
            "\t the loss for timestep 13 is: 1.0740298042773484\n",
            "\t the loss for timestep 14 is: 1.0422394584749006\n",
            "\t the loss for timestep 15 is: 1.0063529561296791\n",
            "\t the loss for timestep 16 is: 0.9720143615662732\n",
            "\t the loss for timestep 17 is: 0.936647208718426\n",
            "\t the loss for timestep 18 is: 0.9025936230039144\n",
            "\t the loss for timestep 19 is: 0.8690141551009825\n",
            "\t the loss for timestep 20 is: 0.8370752279532374\n",
            "\t the loss for timestep 21 is: 0.8064186429834116\n",
            "\t the loss for timestep 22 is: 0.7776630330827008\n",
            "\t the loss for timestep 23 is: 0.7505455410480601\n",
            "\t the loss for timestep 24 is: 0.7253878297192172\n",
            "\t the loss for timestep 25 is: 0.701919822921688\n",
            "\t the loss for timestep 26 is: 0.680306365816567\n",
            "\t the loss for timestep 27 is: 0.6602562052169839\n",
            "\t the loss for timestep 28 is: 0.641867373531635\n",
            "\t the loss for timestep 29 is: 0.6248326188476564\n",
            "\t the loss for timestep 30 is: 0.6092425508842935\n",
            "\t the loss for timestep 31 is: 0.5947698359290919\n",
            "\t the loss for timestep 32 is: 0.58154281189437\n",
            "\t the loss for timestep 33 is: 0.5691951351277951\n",
            "\t the loss for timestep 34 is: 173.1117925301573\n",
            "\t the loss for timestep 35 is: 183.18725712127824\n",
            "\t the loss for timestep 36 is: 0.48167426550198833\n",
            "\t the loss for timestep 37 is: 0.647896476064807\n",
            "\t the loss for timestep 38 is: 0.4239472228704882\n",
            "\t the loss for timestep 39 is: 0.7686177009147963\n",
            "\t the loss for timestep 40 is: 0.35749658964106285\n",
            "\t the loss for timestep 41 is: 0.8647289021082376\n",
            "\t the loss for timestep 42 is: 0.27453033442767605\n",
            "\t the loss for timestep 43 is: 1.1416455052052903\n",
            "\t the loss for timestep 44 is: 0.1965743907256315\n",
            "\t the loss for timestep 45 is: 1.527959540774492\n",
            "\t the loss for timestep 46 is: 0.1557152438136175\n",
            "\t the loss for timestep 47 is: 1.6316877501963902\n",
            "\t the loss for timestep 48 is: 0.15766058245995346\n",
            "\t the loss for timestep 49 is: 1.8301012577957727\n",
            "\t the loss for timestep 50 is: 0.14035050666200438\n",
            "\t the loss for timestep 51 is: 1.9907391799986225\n",
            "\t the loss for timestep 52 is: 0.13619643400811893\n",
            "\t the loss for timestep 53 is: 2.0344351162184426\n",
            "\t the loss for timestep 54 is: 0.13468407123249096\n",
            "\t the loss for timestep 55 is: 2.0503603963424872\n",
            "\t the loss for timestep 56 is: 0.13374822426562064\n",
            "\t the loss for timestep 57 is: 2.0602285503044495\n",
            "\t the loss for timestep 58 is: 0.13302541714557223\n",
            "\t the loss for timestep 59 is: 2.067965257414826\n",
            "\t the loss for timestep 60 is: 0.1324368602872209\n",
            "\t the loss for timestep 61 is: 2.0743743550975795\n",
            "\t the loss for timestep 62 is: 0.14421514328284868\n",
            "\t the loss for timestep 63 is: 2.1997796063587356\n",
            "\t the loss for timestep 64 is: 0.2471853068807593\n",
            "\t the loss for timestep 65 is: 2.8118003906706095\n",
            "\t the loss for timestep 66 is: 0.1326588921847111\n",
            "\t the loss for timestep 67 is: 2.0703330309071983\n",
            "\t the loss for timestep 68 is: 0.13103322092816613\n",
            "\t the loss for timestep 69 is: 2.0899549011443086\n",
            "\t the loss for timestep 70 is: 0.1307380330076285\n",
            "\t the loss for timestep 71 is: 2.1139516909142126\n",
            "\t the loss for timestep 72 is: 0.13040051878551878\n",
            "\t the loss for timestep 73 is: 2.0976583810798575\n",
            "\t the loss for timestep 74 is: 0.13032724600617712\n",
            "\t the loss for timestep 75 is: 2.0983166990096818\n",
            "\t the loss for timestep 76 is: 0.13018671157824652\n",
            "\t the loss for timestep 77 is: 2.0999403533584333\n",
            "\t the loss for timestep 78 is: 0.1300605732276132\n",
            "\t the loss for timestep 79 is: 3.078911501812635\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.12985634325434764\n",
            "\t the loss for timestep 2 is: 2.1042098487615095\n",
            "\t the loss for timestep 3 is: 0.1299407422141401\n",
            "\t the loss for timestep 4 is: 2.1030021932687406\n",
            "\t the loss for timestep 5 is: 0.13883879690911377\n",
            "\t the loss for timestep 6 is: 3.444487963749496\n",
            "\t the loss for timestep 7 is: 0.12840703052511937\n",
            "\t the loss for timestep 8 is: 2.12507221232138\n",
            "\t the loss for timestep 9 is: 0.12987629515169657\n",
            "\t the loss for timestep 10 is: 2.1039520949037316\n",
            "\t the loss for timestep 11 is: 0.12995747137213487\n",
            "\t the loss for timestep 12 is: 2.1028085229560696\n",
            "\t the loss for timestep 13 is: 0.12996842128395886\n",
            "\t the loss for timestep 14 is: 2.102664893895472\n",
            "\t the loss for timestep 15 is: 0.1299765299169525\n",
            "\t the loss for timestep 16 is: 2.1025673406611416\n",
            "\t the loss for timestep 17 is: 0.12998531202314711\n",
            "\t the loss for timestep 18 is: 2.102462199778894\n",
            "\t the loss for timestep 19 is: 0.1299949789626001\n",
            "\t the loss for timestep 20 is: 2.102346523285574\n",
            "\t the loss for timestep 21 is: 0.1300055592867093\n",
            "\t the loss for timestep 22 is: 2.1022202601081976\n",
            "\t the loss for timestep 23 is: 0.1300170734008616\n",
            "\t the loss for timestep 24 is: 2.102082356724441\n",
            "\t the loss for timestep 25 is: 0.1300295445305008\n",
            "\t the loss for timestep 26 is: 2.101933719455289\n",
            "\t the loss for timestep 27 is: 0.13004299496387156\n",
            "\t the loss for timestep 28 is: 2.101772944476635\n",
            "\t the loss for timestep 29 is: 0.13005745467086965\n",
            "\t the loss for timestep 30 is: 2.101600621051974\n",
            "\t the loss for timestep 31 is: 0.13007294942223988\n",
            "\t the loss for timestep 32 is: 2.1014161900421984\n",
            "\t the loss for timestep 33 is: 0.13008951148156667\n",
            "\t the loss for timestep 34 is: 162.1905643325154\n",
            "\t the loss for timestep 35 is: 194.920208502404\n",
            "\t the loss for timestep 36 is: 2.099730770708218\n",
            "\t the loss for timestep 37 is: 0.1301268716938696\n",
            "\t the loss for timestep 38 is: 2.1007619682062937\n",
            "\t the loss for timestep 39 is: 0.13014335336357552\n",
            "\t the loss for timestep 40 is: 2.2004832198805913\n",
            "\t the loss for timestep 41 is: 0.12991553590136112\n",
            "\t the loss for timestep 42 is: 2.1374073050974234\n",
            "\t the loss for timestep 43 is: 0.13005587618754264\n",
            "\t the loss for timestep 44 is: 2.1019419976453433\n",
            "\t the loss for timestep 45 is: 0.1301903301949319\n",
            "\t the loss for timestep 46 is: 2.100045220788229\n",
            "\t the loss for timestep 47 is: 0.13045468207814717\n",
            "\t the loss for timestep 48 is: 1.8193469172054502\n",
            "\t the loss for timestep 49 is: 0.13318526008726625\n",
            "\t the loss for timestep 50 is: 2.0589058701971084\n",
            "\t the loss for timestep 51 is: 0.13044792102743694\n",
            "\t the loss for timestep 52 is: 2.0966228559053945\n",
            "\t the loss for timestep 53 is: 0.13030607833448465\n",
            "\t the loss for timestep 54 is: 2.098654279296089\n",
            "\t the loss for timestep 55 is: 0.13032491146228695\n",
            "\t the loss for timestep 56 is: 2.098457840503305\n",
            "\t the loss for timestep 57 is: 0.13035482520784766\n",
            "\t the loss for timestep 58 is: 2.09811220630474\n",
            "\t the loss for timestep 59 is: 0.13038699210087645\n",
            "\t the loss for timestep 60 is: 2.0977409648426\n",
            "\t the loss for timestep 61 is: 0.13042095592063654\n",
            "\t the loss for timestep 62 is: 1.943681540037718\n",
            "\t the loss for timestep 63 is: 0.14750346894669553\n",
            "\t the loss for timestep 64 is: 3.15690216802943\n",
            "\t the loss for timestep 65 is: 0.15191716964029173\n",
            "\t the loss for timestep 66 is: 1.9840083018309507\n",
            "\t the loss for timestep 67 is: 0.13130415683368374\n",
            "\t the loss for timestep 68 is: 2.0856844003765582\n",
            "\t the loss for timestep 69 is: 0.13064701479827884\n",
            "\t the loss for timestep 70 is: 2.115198871675648\n",
            "\t the loss for timestep 71 is: 0.13057823208675928\n",
            "\t the loss for timestep 72 is: 2.095699094518936\n",
            "\t the loss for timestep 73 is: 0.1307163649283734\n",
            "\t the loss for timestep 74 is: 2.0940027167099253\n",
            "\t the loss for timestep 75 is: 0.13078870831091466\n",
            "\t the loss for timestep 76 is: 2.0931773878505204\n",
            "\t the loss for timestep 77 is: 0.13086015666228695\n",
            "\t the loss for timestep 78 is: 2.0923762338413976\n",
            "\t the loss for timestep 79 is: 0.19481075252649935\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.13078230653766043\n",
            "\t the loss for timestep 2 is: 2.0935575552639096\n",
            "\t the loss for timestep 3 is: 0.13096355051763034\n",
            "\t the loss for timestep 4 is: 2.0911620312272956\n",
            "\t the loss for timestep 5 is: 0.14533620962215374\n",
            "\t the loss for timestep 6 is: 3.386357274026544\n",
            "\t the loss for timestep 7 is: 0.12859022111194512\n",
            "\t the loss for timestep 8 is: 2.1227825108653864\n",
            "\t the loss for timestep 9 is: 0.1308311821015035\n",
            "\t the loss for timestep 10 is: 2.092974010255511\n",
            "\t the loss for timestep 11 is: 0.13100335553657041\n",
            "\t the loss for timestep 12 is: 2.0907369159585123\n",
            "\t the loss for timestep 13 is: 0.13103153968543094\n",
            "\t the loss for timestep 14 is: 2.090399838465413\n",
            "\t the loss for timestep 15 is: 0.13105123663863177\n",
            "\t the loss for timestep 16 is: 2.0901830127225685\n",
            "\t the loss for timestep 17 is: 0.1310723266975609\n",
            "\t the loss for timestep 18 is: 2.089952863015564\n",
            "\t the loss for timestep 19 is: 0.13109560727520658\n",
            "\t the loss for timestep 20 is: 2.089699135025252\n",
            "\t the loss for timestep 21 is: 0.1311212002916929\n",
            "\t the loss for timestep 22 is: 2.0894207782398504\n",
            "\t the loss for timestep 23 is: 0.1311491846342655\n",
            "\t the loss for timestep 24 is: 2.089116219731316\n",
            "\t the loss for timestep 25 is: 0.13117964569675183\n",
            "\t the loss for timestep 26 is: 2.0887858184760657\n",
            "\t the loss for timestep 27 is: 0.13121267291637287\n",
            "\t the loss for timestep 28 is: 2.088427595756124\n",
            "\t the loss for timestep 29 is: 0.13124837325332522\n",
            "\t the loss for timestep 30 is: 2.0880414690566456\n",
            "\t the loss for timestep 31 is: 0.13128685416570338\n",
            "\t the loss for timestep 32 is: 2.0876261812617534\n",
            "\t the loss for timestep 33 is: 0.13132823986615383\n",
            "\t the loss for timestep 34 is: 162.25279835981456\n",
            "\t the loss for timestep 35 is: 194.83558674664044\n",
            "\t the loss for timestep 36 is: 2.074740435749022\n",
            "\t the loss for timestep 37 is: 0.13148927056496917\n",
            "\t the loss for timestep 38 is: 2.0852872700769316\n",
            "\t the loss for timestep 39 is: 0.13148303958083069\n",
            "\t the loss for timestep 40 is: 2.1854405599266236\n",
            "\t the loss for timestep 41 is: 0.1311350984755157\n",
            "\t the loss for timestep 42 is: 2.1236003994104267\n",
            "\t the loss for timestep 43 is: 0.13136956317336076\n",
            "\t the loss for timestep 44 is: 2.0872523119198165\n",
            "\t the loss for timestep 45 is: 0.13160751430412623\n",
            "\t the loss for timestep 46 is: 2.084245968353813\n",
            "\t the loss for timestep 47 is: 0.13212678244981868\n",
            "\t the loss for timestep 48 is: 1.8056515888471645\n",
            "\t the loss for timestep 49 is: 0.13631177580306694\n",
            "\t the loss for timestep 50 is: 2.0262075779864785\n",
            "\t the loss for timestep 51 is: 0.13224255295541745\n",
            "\t the loss for timestep 52 is: 2.0766959378518237\n",
            "\t the loss for timestep 53 is: 0.13194197844655725\n",
            "\t the loss for timestep 54 is: 2.080635139370444\n",
            "\t the loss for timestep 55 is: 0.13199274113923068\n",
            "\t the loss for timestep 56 is: 2.0801811628990587\n",
            "\t the loss for timestep 57 is: 0.13207981621195533\n",
            "\t the loss for timestep 58 is: 2.0792891230188806\n",
            "\t the loss for timestep 59 is: 0.13217566779206188\n",
            "\t the loss for timestep 60 is: 2.0783063630911647\n",
            "\t the loss for timestep 61 is: 0.1322782240869198\n",
            "\t the loss for timestep 62 is: 1.9350131562377109\n",
            "\t the loss for timestep 63 is: 0.16109275901397352\n",
            "\t the loss for timestep 64 is: 3.090605641114542\n",
            "\t the loss for timestep 65 is: 0.18257521051874387\n",
            "\t the loss for timestep 66 is: 1.7845422834172453\n",
            "\t the loss for timestep 67 is: 0.13640103563935518\n",
            "\t the loss for timestep 68 is: 2.029033609418309\n",
            "\t the loss for timestep 69 is: 0.13321650882697103\n",
            "\t the loss for timestep 70 is: 2.087493074970545\n",
            "\t the loss for timestep 71 is: 0.13290965730500534\n",
            "\t the loss for timestep 72 is: 2.0711142701070977\n",
            "\t the loss for timestep 73 is: 0.13321794211918464\n",
            "\t the loss for timestep 74 is: 2.06795359082395\n",
            "\t the loss for timestep 75 is: 0.13345815405833342\n",
            "\t the loss for timestep 76 is: 2.065598864313702\n",
            "\t the loss for timestep 77 is: 0.13370782395564693\n",
            "\t the loss for timestep 78 is: 2.063194965196813\n",
            "\t the loss for timestep 79 is: 0.2675352770282159\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.13345435464486383\n",
            "\t the loss for timestep 2 is: 2.0665949777801953\n",
            "\t the loss for timestep 3 is: 0.13406078167712213\n",
            "\t the loss for timestep 4 is: 2.059657048354932\n",
            "\t the loss for timestep 5 is: 0.16630115994234806\n",
            "\t the loss for timestep 6 is: 3.2314596692833453\n",
            "\t the loss for timestep 7 is: 0.12936810719415534\n",
            "\t the loss for timestep 8 is: 2.114060788438194\n",
            "\t the loss for timestep 9 is: 0.13366700840655915\n",
            "\t the loss for timestep 10 is: 2.0643854205652787\n",
            "\t the loss for timestep 11 is: 0.1342234668757814\n",
            "\t the loss for timestep 12 is: 2.05817046683884\n",
            "\t the loss for timestep 13 is: 0.13435253980063872\n",
            "\t the loss for timestep 14 is: 2.056848125169407\n",
            "\t the loss for timestep 15 is: 0.13443765474908834\n",
            "\t the loss for timestep 16 is: 2.0560504301622204\n",
            "\t the loss for timestep 17 is: 0.1345261396096506\n",
            "\t the loss for timestep 18 is: 2.0552375405498866\n",
            "\t the loss for timestep 19 is: 0.1346243662470213\n",
            "\t the loss for timestep 20 is: 2.0543392548335655\n",
            "\t the loss for timestep 21 is: 0.13473365772916246\n",
            "\t the loss for timestep 22 is: 2.053343224263218\n",
            "\t the loss for timestep 23 is: 0.13485477754452893\n",
            "\t the loss for timestep 24 is: 2.0522426841041694\n",
            "\t the loss for timestep 25 is: 0.13498850433992265\n",
            "\t the loss for timestep 26 is: 2.051033059185674\n",
            "\t the loss for timestep 27 is: 0.1351357011716031\n",
            "\t the loss for timestep 28 is: 2.0497069930035994\n",
            "\t the loss for timestep 29 is: 0.1352973610652812\n",
            "\t the loss for timestep 30 is: 2.0482582581307316\n",
            "\t the loss for timestep 31 is: 0.13547458997354553\n",
            "\t the loss for timestep 32 is: 2.046678771226044\n",
            "\t the loss for timestep 33 is: 0.13566865255294783\n",
            "\t the loss for timestep 34 is: 162.44192046865751\n",
            "\t the loss for timestep 35 is: 194.44571536966788\n",
            "\t the loss for timestep 36 is: 1.9771918704145937\n",
            "\t the loss for timestep 37 is: 0.13710136203780512\n",
            "\t the loss for timestep 38 is: 2.030572424548768\n",
            "\t the loss for timestep 39 is: 0.1366641724069357\n",
            "\t the loss for timestep 40 is: 2.135892557500193\n",
            "\t the loss for timestep 41 is: 0.13592522156244535\n",
            "\t the loss for timestep 42 is: 2.0776817753181174\n",
            "\t the loss for timestep 43 is: 0.13660524962697862\n",
            "\t the loss for timestep 44 is: 2.0379831821609953\n",
            "\t the loss for timestep 45 is: 0.13739319466401717\n",
            "\t the loss for timestep 46 is: 2.0303009727379413\n",
            "\t the loss for timestep 47 is: 0.13905337731984233\n",
            "\t the loss for timestep 48 is: 1.7595663345667423\n",
            "\t the loss for timestep 49 is: 0.1487336875682866\n",
            "\t the loss for timestep 50 is: 1.9214642369938726\n",
            "\t the loss for timestep 51 is: 0.140881135031418\n",
            "\t the loss for timestep 52 is: 1.998126558768229\n",
            "\t the loss for timestep 53 is: 0.13986116898352546\n",
            "\t the loss for timestep 54 is: 2.0093219593716474\n",
            "\t the loss for timestep 55 is: 0.14022228628995936\n",
            "\t the loss for timestep 56 is: 2.007028596142657\n",
            "\t the loss for timestep 57 is: 0.14090310701374845\n",
            "\t the loss for timestep 58 is: 2.0018199484889694\n",
            "\t the loss for timestep 59 is: 0.14171726435711607\n",
            "\t the loss for timestep 60 is: 1.9955904968080485\n",
            "\t the loss for timestep 61 is: 0.14264112968192322\n",
            "\t the loss for timestep 62 is: 1.8970201699357667\n",
            "\t the loss for timestep 63 is: 0.23072903033642148\n",
            "\t the loss for timestep 64 is: 2.8780214810614315\n",
            "\t the loss for timestep 65 is: 0.4130885784210463\n",
            "\t the loss for timestep 66 is: 1.1479603917719212\n",
            "\t the loss for timestep 67 is: 0.21229541447673966\n",
            "\t the loss for timestep 68 is: 1.4873812500406134\n",
            "\t the loss for timestep 69 is: 0.1711470198202965\n",
            "\t the loss for timestep 70 is: 1.7858750663577694\n",
            "\t the loss for timestep 71 is: 0.1564132871829867\n",
            "\t the loss for timestep 72 is: 1.885432580748753\n",
            "\t the loss for timestep 73 is: 0.15466395288103976\n",
            "\t the loss for timestep 74 is: 1.9049306348529456\n",
            "\t the loss for timestep 75 is: 0.15678080614860723\n",
            "\t the loss for timestep 76 is: 1.89444002723257\n",
            "\t the loss for timestep 77 is: 0.16064980352103406\n",
            "\t the loss for timestep 78 is: 1.8725903270466557\n",
            "\t the loss for timestep 79 is: 0.7996959637371315\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.15633107488102704\n",
            "\t the loss for timestep 2 is: 1.9097114762858165\n",
            "\t the loss for timestep 3 is: 0.1658975833044604\n",
            "\t the loss for timestep 4 is: 1.8432662799524002\n",
            "\t the loss for timestep 5 is: 0.4320718492323019\n",
            "\t the loss for timestep 6 is: 2.3132030565220174\n",
            "\t the loss for timestep 7 is: 0.15472500640845582\n",
            "\t the loss for timestep 8 is: 1.9189907390554044\n",
            "\t the loss for timestep 9 is: 0.16664011309371066\n",
            "\t the loss for timestep 10 is: 1.8415342321925376\n",
            "\t the loss for timestep 11 is: 0.1720673444430337\n",
            "\t the loss for timestep 12 is: 1.8082306958291667\n",
            "\t the loss for timestep 13 is: 0.17558734475844417\n",
            "\t the loss for timestep 14 is: 1.7888503061998022\n",
            "\t the loss for timestep 15 is: 0.17868064873661887\n",
            "\t the loss for timestep 16 is: 1.773402268449259\n",
            "\t the loss for timestep 17 is: 0.1819855351037437\n",
            "\t the loss for timestep 18 is: 1.7579648385340172\n",
            "\t the loss for timestep 19 is: 0.1858432687094685\n",
            "\t the loss for timestep 20 is: 1.7407698933988276\n",
            "\t the loss for timestep 21 is: 0.1905029752041763\n",
            "\t the loss for timestep 22 is: 1.7208436187478635\n",
            "\t the loss for timestep 23 is: 0.19621108011599053\n",
            "\t the loss for timestep 24 is: 1.6974848067699924\n",
            "\t the loss for timestep 25 is: 0.20326059214664371\n",
            "\t the loss for timestep 26 is: 1.6700565825010947\n",
            "\t the loss for timestep 27 is: 0.2120294561831634\n",
            "\t the loss for timestep 28 is: 1.6378985034752334\n",
            "\t the loss for timestep 29 is: 0.22302127604102756\n",
            "\t the loss for timestep 30 is: 1.60030698185652\n",
            "\t the loss for timestep 31 is: 0.2369145799996386\n",
            "\t the loss for timestep 32 is: 1.5565567930091464\n",
            "\t the loss for timestep 33 is: 0.2546229947110422\n",
            "\t the loss for timestep 34 is: 165.18506937111331\n",
            "\t the loss for timestep 35 is: 186.06744866499827\n",
            "\t the loss for timestep 36 is: 1.0388179836849338\n",
            "\t the loss for timestep 37 is: 0.467254988495431\n",
            "\t the loss for timestep 38 is: 1.02534832442003\n",
            "\t the loss for timestep 39 is: 0.5311504547578365\n",
            "\t the loss for timestep 40 is: 1.0591256747638043\n",
            "\t the loss for timestep 41 is: 0.5499538298469007\n",
            "\t the loss for timestep 42 is: 1.0302075429419357\n",
            "\t the loss for timestep 43 is: 0.6235026885708377\n",
            "\t the loss for timestep 44 is: 0.9823646940257719\n",
            "\t the loss for timestep 45 is: 0.7033280211662698\n",
            "\t the loss for timestep 46 is: 0.9594932026285852\n",
            "\t the loss for timestep 47 is: 0.760850701264595\n",
            "\t the loss for timestep 48 is: 1.0180555932811788\n",
            "\t the loss for timestep 49 is: 0.9343851908639843\n",
            "\t the loss for timestep 50 is: 0.9517141389501316\n",
            "\t the loss for timestep 51 is: 0.9685463581524916\n",
            "\t the loss for timestep 52 is: 0.987937450318908\n",
            "\t the loss for timestep 53 is: 1.0159106414286985\n",
            "\t the loss for timestep 54 is: 1.0403915222760496\n",
            "\t the loss for timestep 55 is: 1.0670431540464207\n",
            "\t the loss for timestep 56 is: 1.0922105280698156\n",
            "\t the loss for timestep 57 is: 1.1174177879327873\n",
            "\t the loss for timestep 58 is: 1.1413661279772467\n",
            "\t the loss for timestep 59 is: 1.1641104798852413\n",
            "\t the loss for timestep 60 is: 1.1850390559431232\n",
            "\t the loss for timestep 61 is: 1.2038103694363118\n",
            "\t the loss for timestep 62 is: 1.548645655700443\n",
            "\t the loss for timestep 63 is: 1.7948077648981162\n",
            "\t the loss for timestep 64 is: 2.673451115260635\n",
            "\t the loss for timestep 65 is: 2.415281967857543\n",
            "\t the loss for timestep 66 is: 1.379233604101282\n",
            "\t the loss for timestep 67 is: 1.2848989623072844\n",
            "\t the loss for timestep 68 is: 1.2769098510401704\n",
            "\t the loss for timestep 69 is: 1.251184053062383\n",
            "\t the loss for timestep 70 is: 1.252001635949775\n",
            "\t the loss for timestep 71 is: 1.229671193571583\n",
            "\t the loss for timestep 72 is: 1.2029649718200817\n",
            "\t the loss for timestep 73 is: 1.1886699631397442\n",
            "\t the loss for timestep 74 is: 1.1635218944005241\n",
            "\t the loss for timestep 75 is: 1.1392907705008153\n",
            "\t the loss for timestep 76 is: 1.1128488044231584\n",
            "\t the loss for timestep 77 is: 1.085704868300788\n",
            "\t the loss for timestep 78 is: 1.0579012547168216\n",
            "\t the loss for timestep 79 is: 2.4269863208026403\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.7408205748920309\n",
            "\t the loss for timestep 2 is: 1.1869368399083207\n",
            "\t the loss for timestep 3 is: 0.9298143174576703\n",
            "\t the loss for timestep 4 is: 1.0379427558123067\n",
            "\t the loss for timestep 5 is: 2.2358900698395834\n",
            "\t the loss for timestep 6 is: 1.5904659334631774\n",
            "\t the loss for timestep 7 is: 0.7325427927589604\n",
            "\t the loss for timestep 8 is: 1.1378913515265974\n",
            "\t the loss for timestep 9 is: 0.8742226003611521\n",
            "\t the loss for timestep 10 is: 0.9908039938690358\n",
            "\t the loss for timestep 11 is: 0.9015198619068061\n",
            "\t the loss for timestep 12 is: 0.9326595778677442\n",
            "\t the loss for timestep 13 is: 0.8915715652507222\n",
            "\t the loss for timestep 14 is: 0.8944362236200536\n",
            "\t the loss for timestep 15 is: 0.8688926709985809\n",
            "\t the loss for timestep 16 is: 0.8616814348516625\n",
            "\t the loss for timestep 17 is: 0.8418479259251666\n",
            "\t the loss for timestep 18 is: 0.830794513266867\n",
            "\t the loss for timestep 19 is: 0.8134741375058571\n",
            "\t the loss for timestep 20 is: 0.8010035650000796\n",
            "\t the loss for timestep 21 is: 0.7851010214481249\n",
            "\t the loss for timestep 22 is: 0.7722823796283012\n",
            "\t the loss for timestep 23 is: 0.7574100438736596\n",
            "\t the loss for timestep 24 is: 0.744766518058222\n",
            "\t the loss for timestep 25 is: 0.730779622192245\n",
            "\t the loss for timestep 26 is: 0.7185852302229073\n",
            "\t the loss for timestep 27 is: 0.7054173742455998\n",
            "\t the loss for timestep 28 is: 0.6938188669400788\n",
            "\t the loss for timestep 29 is: 0.6814226561484993\n",
            "\t the loss for timestep 30 is: 0.6704986135888802\n",
            "\t the loss for timestep 31 is: 0.6588229886185054\n",
            "\t the loss for timestep 32 is: 0.648614941347102\n",
            "\t the loss for timestep 33 is: 0.6375967302265826\n",
            "\t the loss for timestep 34 is: 172.22282816139563\n",
            "\t the loss for timestep 35 is: 181.50413078750398\n",
            "\t the loss for timestep 36 is: 0.5469832056354993\n",
            "\t the loss for timestep 37 is: 0.7364157085429666\n",
            "\t the loss for timestep 38 is: 0.5013234705291456\n",
            "\t the loss for timestep 39 is: 0.8309368266804642\n",
            "\t the loss for timestep 40 is: 0.4767598516846487\n",
            "\t the loss for timestep 41 is: 0.8146167175870704\n",
            "\t the loss for timestep 42 is: 0.43539062548011376\n",
            "\t the loss for timestep 43 is: 0.8850289498090211\n",
            "\t the loss for timestep 44 is: 0.37815123494987707\n",
            "\t the loss for timestep 45 is: 0.9744236375488671\n",
            "\t the loss for timestep 46 is: 0.32698483533660705\n",
            "\t the loss for timestep 47 is: 1.0579913588359493\n",
            "\t the loss for timestep 48 is: 0.3617054397619418\n",
            "\t the loss for timestep 49 is: 1.0912081988566888\n",
            "\t the loss for timestep 50 is: 0.28150445609218666\n",
            "\t the loss for timestep 51 is: 1.2590408660345518\n",
            "\t the loss for timestep 52 is: 0.23756851959814318\n",
            "\t the loss for timestep 53 is: 1.4426688629382274\n",
            "\t the loss for timestep 54 is: 0.21007237037801638\n",
            "\t the loss for timestep 55 is: 1.586435238357602\n",
            "\t the loss for timestep 56 is: 0.19649428284325293\n",
            "\t the loss for timestep 57 is: 1.6683439831164062\n",
            "\t the loss for timestep 58 is: 0.19239558869328013\n",
            "\t the loss for timestep 59 is: 1.6996469743752143\n",
            "\t the loss for timestep 60 is: 0.19397173045339372\n",
            "\t the loss for timestep 61 is: 1.6997527324898958\n",
            "\t the loss for timestep 62 is: 0.30092346348379156\n",
            "\t the loss for timestep 63 is: 1.815481277906914\n",
            "\t the loss for timestep 64 is: 1.3847780967211627\n",
            "\t the loss for timestep 65 is: 1.898359758468604\n",
            "\t the loss for timestep 66 is: 0.38792397362371356\n",
            "\t the loss for timestep 67 is: 1.1100839005509253\n",
            "\t the loss for timestep 68 is: 0.3126741969600425\n",
            "\t the loss for timestep 69 is: 1.2258031421609727\n",
            "\t the loss for timestep 70 is: 0.28761301897742186\n",
            "\t the loss for timestep 71 is: 1.3370557120241051\n",
            "\t the loss for timestep 72 is: 0.2734265530358539\n",
            "\t the loss for timestep 73 is: 1.3976635344925723\n",
            "\t the loss for timestep 74 is: 0.2715603760990588\n",
            "\t the loss for timestep 75 is: 1.4199140774991825\n",
            "\t the loss for timestep 76 is: 0.2759062936406548\n",
            "\t the loss for timestep 77 is: 1.41822414108269\n",
            "\t the loss for timestep 78 is: 0.2842320571439905\n",
            "\t the loss for timestep 79 is: 2.696385904953119\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.21947367158077374\n",
            "\t the loss for timestep 2 is: 1.6641505026793912\n",
            "\t the loss for timestep 3 is: 0.25846027283452333\n",
            "\t the loss for timestep 4 is: 1.5092025475826116\n",
            "\t the loss for timestep 5 is: 0.42639938503187497\n",
            "\t the loss for timestep 6 is: 2.156093266480709\n",
            "\t the loss for timestep 7 is: 0.23268285129551583\n",
            "\t the loss for timestep 8 is: 1.6172285730720564\n",
            "\t the loss for timestep 9 is: 0.2615200718638387\n",
            "\t the loss for timestep 10 is: 1.497791656264846\n",
            "\t the loss for timestep 11 is: 0.27718682102883846\n",
            "\t the loss for timestep 12 is: 1.4403485480774991\n",
            "\t the loss for timestep 13 is: 0.28504046310588166\n",
            "\t the loss for timestep 14 is: 1.4118553810581647\n",
            "\t the loss for timestep 15 is: 0.2885131855151208\n",
            "\t the loss for timestep 16 is: 1.399184290114712\n",
            "\t the loss for timestep 17 is: 0.28931025929977366\n",
            "\t the loss for timestep 18 is: 1.3960264941397154\n",
            "\t the loss for timestep 19 is: 0.28852069435873273\n",
            "\t the loss for timestep 20 is: 1.398683108815339\n",
            "\t the loss for timestep 21 is: 0.28697722879735205\n",
            "\t the loss for timestep 22 is: 1.4045169620662699\n",
            "\t the loss for timestep 23 is: 0.2854226347352614\n",
            "\t the loss for timestep 24 is: 1.4112855768448214\n",
            "\t the loss for timestep 25 is: 0.2845987044888438\n",
            "\t the loss for timestep 26 is: 1.4168359861677025\n",
            "\t the loss for timestep 27 is: 0.28530932184021796\n",
            "\t the loss for timestep 28 is: 1.4189660300266413\n",
            "\t the loss for timestep 29 is: 0.2884833320585273\n",
            "\t the loss for timestep 30 is: 1.415394861959876\n",
            "\t the loss for timestep 31 is: 0.2952579617817329\n",
            "\t the loss for timestep 32 is: 1.4038040288377895\n",
            "\t the loss for timestep 33 is: 0.30709372657308665\n",
            "\t the loss for timestep 34 is: 166.3341461034907\n",
            "\t the loss for timestep 35 is: 183.81909070520229\n",
            "\t the loss for timestep 36 is: 0.891705502012352\n",
            "\t the loss for timestep 37 is: 0.5811905151284524\n",
            "\t the loss for timestep 38 is: 0.8592011801946589\n",
            "\t the loss for timestep 39 is: 0.6463862933315296\n",
            "\t the loss for timestep 40 is: 0.8959138557511812\n",
            "\t the loss for timestep 41 is: 0.6157839132108279\n",
            "\t the loss for timestep 42 is: 0.895829446143803\n",
            "\t the loss for timestep 43 is: 0.6447687417398452\n",
            "\t the loss for timestep 44 is: 0.8763305400492453\n",
            "\t the loss for timestep 45 is: 0.6707366803166176\n",
            "\t the loss for timestep 46 is: 0.871237790542126\n",
            "\t the loss for timestep 47 is: 0.7188877095216989\n",
            "\t the loss for timestep 48 is: 0.9556659292050911\n",
            "\t the loss for timestep 49 is: 0.7821407079066133\n",
            "\t the loss for timestep 50 is: 0.8372006057215472\n",
            "\t the loss for timestep 51 is: 0.7992360458026371\n",
            "\t the loss for timestep 52 is: 0.8378896870312529\n",
            "\t the loss for timestep 53 is: 0.8195229320466529\n",
            "\t the loss for timestep 54 is: 0.8476574895412993\n",
            "\t the loss for timestep 55 is: 0.8388365000613455\n",
            "\t the loss for timestep 56 is: 0.8582107881748702\n",
            "\t the loss for timestep 57 is: 0.8557257801198185\n",
            "\t the loss for timestep 58 is: 0.8690156263426827\n",
            "\t the loss for timestep 59 is: 0.8701730665916948\n",
            "\t the loss for timestep 60 is: 0.8793918422963521\n",
            "\t the loss for timestep 61 is: 0.8821957623816734\n",
            "\t the loss for timestep 62 is: 1.3015847251264512\n",
            "\t the loss for timestep 63 is: 1.295438476994258\n",
            "\t the loss for timestep 64 is: 2.364211865215399\n",
            "\t the loss for timestep 65 is: 2.135865021823141\n",
            "\t the loss for timestep 66 is: 0.7947022371026379\n",
            "\t the loss for timestep 67 is: 0.9948663094012474\n",
            "\t the loss for timestep 68 is: 0.8519895262818578\n",
            "\t the loss for timestep 69 is: 0.9438180417228151\n",
            "\t the loss for timestep 70 is: 0.8961380893305064\n",
            "\t the loss for timestep 71 is: 0.9227003530559126\n",
            "\t the loss for timestep 72 is: 0.8916097091574218\n",
            "\t the loss for timestep 73 is: 0.9098317904312048\n",
            "\t the loss for timestep 74 is: 0.8950495559121977\n",
            "\t the loss for timestep 75 is: 0.8989707844063263\n",
            "\t the loss for timestep 76 is: 0.8902987759527224\n",
            "\t the loss for timestep 77 is: 0.8882425892880723\n",
            "\t the loss for timestep 78 is: 0.8810367382841037\n",
            "\t the loss for timestep 79 is: 2.5153712235663965\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.5303238729875968\n",
            "\t the loss for timestep 2 is: 1.207042281086083\n",
            "\t the loss for timestep 3 is: 0.7113982810468151\n",
            "\t the loss for timestep 4 is: 0.9870777323588136\n",
            "\t the loss for timestep 5 is: 2.285438401091925\n",
            "\t the loss for timestep 6 is: 1.5727204734355715\n",
            "\t the loss for timestep 7 is: 0.5379146932507299\n",
            "\t the loss for timestep 8 is: 1.1148150436030355\n",
            "\t the loss for timestep 9 is: 0.6996168593153765\n",
            "\t the loss for timestep 10 is: 0.949108819847087\n",
            "\t the loss for timestep 11 is: 0.754758659447296\n",
            "\t the loss for timestep 12 is: 0.8744259918611998\n",
            "\t the loss for timestep 13 is: 0.7728283827745693\n",
            "\t the loss for timestep 14 is: 0.8318614067023177\n",
            "\t the loss for timestep 15 is: 0.7723604694647788\n",
            "\t the loss for timestep 16 is: 0.8018583829109567\n",
            "\t the loss for timestep 17 is: 0.762830717755716\n",
            "\t the loss for timestep 18 is: 0.777222733645294\n",
            "\t the loss for timestep 19 is: 0.7487724063568721\n",
            "\t the loss for timestep 20 is: 0.7551023731002193\n",
            "\t the loss for timestep 21 is: 0.7324411867724704\n",
            "\t the loss for timestep 22 is: 0.7343513887241568\n",
            "\t the loss for timestep 23 is: 0.7150311653629571\n",
            "\t the loss for timestep 24 is: 0.7145298834993233\n",
            "\t the loss for timestep 25 is: 0.6972167135198989\n",
            "\t the loss for timestep 26 is: 0.6954962381597417\n",
            "\t the loss for timestep 27 is: 0.6793967664204293\n",
            "\t the loss for timestep 28 is: 0.6772336743281377\n",
            "\t the loss for timestep 29 is: 0.6618093548003747\n",
            "\t the loss for timestep 30 is: 0.6597776141582815\n",
            "\t the loss for timestep 31 is: 0.644586293704078\n",
            "\t the loss for timestep 32 is: 0.6431878095857376\n",
            "\t the loss for timestep 33 is: 0.6277777049212355\n",
            "\t the loss for timestep 34 is: 172.18109061032484\n",
            "\t the loss for timestep 35 is: 183.82193079748646\n",
            "\t the loss for timestep 36 is: 0.6631446940936063\n",
            "\t the loss for timestep 37 is: 0.5861310134121469\n",
            "\t the loss for timestep 38 is: 0.6519275025288327\n",
            "\t the loss for timestep 39 is: 0.6116636468859349\n",
            "\t the loss for timestep 40 is: 0.6694513938090062\n",
            "\t the loss for timestep 41 is: 0.568888741631968\n",
            "\t the loss for timestep 42 is: 0.675968300626219\n",
            "\t the loss for timestep 43 is: 0.5554178104613776\n",
            "\t the loss for timestep 44 is: 0.6787419650459193\n",
            "\t the loss for timestep 45 is: 0.5365159020093785\n",
            "\t the loss for timestep 46 is: 0.6970426177714276\n",
            "\t the loss for timestep 47 is: 0.5229377286912849\n",
            "\t the loss for timestep 48 is: 0.8027645368394827\n",
            "\t the loss for timestep 49 is: 0.5268880926497118\n",
            "\t the loss for timestep 50 is: 0.7291617020181711\n",
            "\t the loss for timestep 51 is: 0.4993145255102817\n",
            "\t the loss for timestep 52 is: 0.7598241813372326\n",
            "\t the loss for timestep 53 is: 0.4799130006294143\n",
            "\t the loss for timestep 54 is: 0.8016245429997806\n",
            "\t the loss for timestep 55 is: 0.46292175403454605\n",
            "\t the loss for timestep 56 is: 0.8482267742549172\n",
            "\t the loss for timestep 57 is: 0.4523122460548744\n",
            "\t the loss for timestep 58 is: 0.8937948469503322\n",
            "\t the loss for timestep 59 is: 0.45369869757879566\n",
            "\t the loss for timestep 60 is: 0.9291454732746487\n",
            "\t the loss for timestep 61 is: 0.4735122944900289\n",
            "\t the loss for timestep 62 is: 1.4082643528886467\n",
            "\t the loss for timestep 63 is: 1.1418219214351957\n",
            "\t the loss for timestep 64 is: 2.1386309203878153\n",
            "\t the loss for timestep 65 is: 1.305055592323233\n",
            "\t the loss for timestep 66 is: 0.856775252332666\n",
            "\t the loss for timestep 67 is: 0.7809980037247212\n",
            "\t the loss for timestep 68 is: 0.7986168628522907\n",
            "\t the loss for timestep 69 is: 0.7978875828396297\n",
            "\t the loss for timestep 70 is: 0.832343260925789\n",
            "\t the loss for timestep 71 is: 0.8382662282601198\n",
            "\t the loss for timestep 72 is: 0.8644876254645952\n",
            "\t the loss for timestep 73 is: 0.881672206134499\n",
            "\t the loss for timestep 74 is: 0.9027119366254246\n",
            "\t the loss for timestep 75 is: 0.9203915427377632\n",
            "\t the loss for timestep 76 is: 0.9390997094064133\n",
            "\t the loss for timestep 77 is: 0.9557568458646515\n",
            "\t the loss for timestep 78 is: 0.9718997088661462\n",
            "\t the loss for timestep 79 is: 1.8793990728682277\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.8974361066683441\n",
            "\t the loss for timestep 2 is: 1.1714602719881522\n",
            "\t the loss for timestep 3 is: 0.9346470104375448\n",
            "\t the loss for timestep 4 is: 1.0378795208666691\n",
            "\t the loss for timestep 5 is: 1.6443568745908794\n",
            "\t the loss for timestep 6 is: 1.203628969676556\n",
            "\t the loss for timestep 7 is: 0.8789664042414579\n",
            "\t the loss for timestep 8 is: 1.0281378381936395\n",
            "\t the loss for timestep 9 is: 0.903610202760406\n",
            "\t the loss for timestep 10 is: 0.9546558881195507\n",
            "\t the loss for timestep 11 is: 0.8957030203637645\n",
            "\t the loss for timestep 12 is: 0.9083310770140104\n",
            "\t the loss for timestep 13 is: 0.8714756860373345\n",
            "\t the loss for timestep 14 is: 0.8677174131728526\n",
            "\t the loss for timestep 15 is: 0.8395453514577115\n",
            "\t the loss for timestep 16 is: 0.8284959542146211\n",
            "\t the loss for timestep 17 is: 0.8042284039485905\n",
            "\t the loss for timestep 18 is: 0.7900329491488811\n",
            "\t the loss for timestep 19 is: 0.7680137707516436\n",
            "\t the loss for timestep 20 is: 0.7527822525960334\n",
            "\t the loss for timestep 21 is: 0.7324872474374466\n",
            "\t the loss for timestep 22 is: 0.7173908064952628\n",
            "\t the loss for timestep 23 is: 0.6986691833346391\n",
            "\t the loss for timestep 24 is: 0.6843819371426101\n",
            "\t the loss for timestep 25 is: 0.6671602555845684\n",
            "\t the loss for timestep 26 is: 0.6540683922193192\n",
            "\t the loss for timestep 27 is: 0.6382400788286771\n",
            "\t the loss for timestep 28 is: 0.6265637230174974\n",
            "\t the loss for timestep 29 is: 0.6119509071646454\n",
            "\t the loss for timestep 30 is: 0.6018376056463074\n",
            "\t the loss for timestep 31 is: 0.5881694906988059\n",
            "\t the loss for timestep 32 is: 0.5797774099400238\n",
            "\t the loss for timestep 33 is: 0.5666549906976006\n",
            "\t the loss for timestep 34 is: 173.38382399731591\n",
            "\t the loss for timestep 35 is: 182.63820737661445\n",
            "\t the loss for timestep 36 is: 0.45712935694066265\n",
            "\t the loss for timestep 37 is: 0.7053544522538335\n",
            "\t the loss for timestep 38 is: 0.3912596606400136\n",
            "\t the loss for timestep 39 is: 0.8693354483930577\n",
            "\t the loss for timestep 40 is: 0.33259840323286316\n",
            "\t the loss for timestep 41 is: 0.9700978960232188\n",
            "\t the loss for timestep 42 is: 0.25797729615441156\n",
            "\t the loss for timestep 43 is: 1.2480649945431552\n",
            "\t the loss for timestep 44 is: 0.19342409514849962\n",
            "\t the loss for timestep 45 is: 1.5675759167852785\n",
            "\t the loss for timestep 46 is: 0.16190794195696698\n",
            "\t the loss for timestep 47 is: 1.6005219404112965\n",
            "\t the loss for timestep 48 is: 0.16776482851186683\n",
            "\t the loss for timestep 49 is: 1.7596890245250099\n",
            "\t the loss for timestep 50 is: 0.14935053637033854\n",
            "\t the loss for timestep 51 is: 1.9102370890247216\n",
            "\t the loss for timestep 52 is: 0.14362764833189906\n",
            "\t the loss for timestep 53 is: 1.9639946399390822\n",
            "\t the loss for timestep 54 is: 0.1414062826658257\n",
            "\t the loss for timestep 55 is: 1.9851416076127475\n",
            "\t the loss for timestep 56 is: 0.14011597942334778\n",
            "\t the loss for timestep 57 is: 1.997363364467434\n",
            "\t the loss for timestep 58 is: 0.13912765172505903\n",
            "\t the loss for timestep 59 is: 2.0067887046323896\n",
            "\t the loss for timestep 60 is: 0.13828932971260927\n",
            "\t the loss for timestep 61 is: 2.014893201102337\n",
            "\t the loss for timestep 62 is: 0.14808228485717093\n",
            "\t the loss for timestep 63 is: 2.178353819060494\n",
            "\t the loss for timestep 64 is: 0.4375963088281708\n",
            "\t the loss for timestep 65 is: 2.561439312780484\n",
            "\t the loss for timestep 66 is: 0.14352806191679285\n",
            "\t the loss for timestep 67 is: 1.961188025295564\n",
            "\t the loss for timestep 68 is: 0.1368143560238098\n",
            "\t the loss for timestep 69 is: 2.028324498046855\n",
            "\t the loss for timestep 70 is: 0.13553112151958563\n",
            "\t the loss for timestep 71 is: 2.062354482069133\n",
            "\t the loss for timestep 72 is: 0.13474008168306179\n",
            "\t the loss for timestep 73 is: 2.0509926385108868\n",
            "\t the loss for timestep 74 is: 0.13459075867916956\n",
            "\t the loss for timestep 75 is: 2.0523874188028994\n",
            "\t the loss for timestep 76 is: 0.13430576958322754\n",
            "\t the loss for timestep 77 is: 2.055395311074537\n",
            "\t the loss for timestep 78 is: 0.13403193876175534\n",
            "\t the loss for timestep 79 is: 3.0600683329586587\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.13313861578377686\n",
            "\t the loss for timestep 2 is: 2.068714100623057\n",
            "\t the loss for timestep 3 is: 0.13368348061836227\n",
            "\t the loss for timestep 4 is: 2.0623030285854\n",
            "\t the loss for timestep 5 is: 0.15816500190400817\n",
            "\t the loss for timestep 6 is: 3.2750644496765036\n",
            "\t the loss for timestep 7 is: 0.12936555321886636\n",
            "\t the loss for timestep 8 is: 2.1138164399249635\n",
            "\t the loss for timestep 9 is: 0.13333435424950557\n",
            "\t the loss for timestep 10 is: 2.066608813845739\n",
            "\t the loss for timestep 11 is: 0.13382503021579964\n",
            "\t the loss for timestep 12 is: 2.0609677847644154\n",
            "\t the loss for timestep 13 is: 0.13393469397369803\n",
            "\t the loss for timestep 14 is: 2.0598117147299417\n",
            "\t the loss for timestep 15 is: 0.1340069844437082\n",
            "\t the loss for timestep 16 is: 2.05911470364212\n",
            "\t the loss for timestep 17 is: 0.13408232700877776\n",
            "\t the loss for timestep 18 is: 2.0584017135352215\n",
            "\t the loss for timestep 19 is: 0.13416590755386473\n",
            "\t the loss for timestep 20 is: 2.0576138547833414\n",
            "\t the loss for timestep 21 is: 0.13425875632801137\n",
            "\t the loss for timestep 22 is: 2.0567412509583334\n",
            "\t the loss for timestep 23 is: 0.1343614620932718\n",
            "\t the loss for timestep 24 is: 2.055778340952859\n",
            "\t the loss for timestep 25 is: 0.13447463381577127\n",
            "\t the loss for timestep 26 is: 2.0547215821656133\n",
            "\t the loss for timestep 27 is: 0.13459893609515855\n",
            "\t the loss for timestep 28 is: 2.0535648467328627\n",
            "\t the loss for timestep 29 is: 0.13473513176004376\n",
            "\t the loss for timestep 30 is: 2.0523033268911792\n",
            "\t the loss for timestep 31 is: 0.1348840754775118\n",
            "\t the loss for timestep 32 is: 2.0509304079607014\n",
            "\t the loss for timestep 33 is: 0.13504673471035428\n",
            "\t the loss for timestep 34 is: 162.43690256522908\n",
            "\t the loss for timestep 35 is: 192.9724368815735\n",
            "\t the loss for timestep 36 is: 1.5916178307568234\n",
            "\t the loss for timestep 37 is: 0.1458421091068654\n",
            "\t the loss for timestep 38 is: 1.9366881720178124\n",
            "\t the loss for timestep 39 is: 0.1396961168132901\n",
            "\t the loss for timestep 40 is: 2.104494517835354\n",
            "\t the loss for timestep 41 is: 0.136837695085092\n",
            "\t the loss for timestep 42 is: 2.067601572110676\n",
            "\t the loss for timestep 43 is: 0.1384283579147922\n",
            "\t the loss for timestep 44 is: 2.0198661333601473\n",
            "\t the loss for timestep 45 is: 0.1397797297541487\n",
            "\t the loss for timestep 46 is: 2.0076476250896844\n",
            "\t the loss for timestep 47 is: 0.13970252209258843\n",
            "\t the loss for timestep 48 is: 1.7545161848181625\n",
            "\t the loss for timestep 49 is: 0.159021425192096\n",
            "\t the loss for timestep 50 is: 1.8446134226084958\n",
            "\t the loss for timestep 51 is: 0.14881478751527635\n",
            "\t the loss for timestep 52 is: 1.9311617162563928\n",
            "\t the loss for timestep 53 is: 0.14824089227594373\n",
            "\t the loss for timestep 54 is: 1.940174565298967\n",
            "\t the loss for timestep 55 is: 0.15028491661874605\n",
            "\t the loss for timestep 56 is: 1.9267805183989175\n",
            "\t the loss for timestep 57 is: 0.1534283383464994\n",
            "\t the loss for timestep 58 is: 1.9055726959793222\n",
            "\t the loss for timestep 59 is: 0.15741870906687938\n",
            "\t the loss for timestep 60 is: 1.8796658316100583\n",
            "\t the loss for timestep 61 is: 0.1623494999565372\n",
            "\t the loss for timestep 62 is: 1.8461834350582624\n",
            "\t the loss for timestep 63 is: 0.46728390912290807\n",
            "\t the loss for timestep 64 is: 2.528601503280876\n",
            "\t the loss for timestep 65 is: 0.6940643919138236\n",
            "\t the loss for timestep 66 is: 0.9279491607439292\n",
            "\t the loss for timestep 67 is: 0.36176987294563495\n",
            "\t the loss for timestep 68 is: 1.0109371860658505\n",
            "\t the loss for timestep 69 is: 0.32206347400660246\n",
            "\t the loss for timestep 70 is: 1.1508039765209277\n",
            "\t the loss for timestep 71 is: 0.2946571039689834\n",
            "\t the loss for timestep 72 is: 1.2523718562354653\n",
            "\t the loss for timestep 73 is: 0.28524906972452463\n",
            "\t the loss for timestep 74 is: 1.31398440236108\n",
            "\t the loss for timestep 75 is: 0.29013502698993493\n",
            "\t the loss for timestep 76 is: 1.3259053467994806\n",
            "\t the loss for timestep 77 is: 0.3100069629603882\n",
            "\t the loss for timestep 78 is: 1.2950593510056148\n",
            "\t the loss for timestep 79 is: 1.5785398200082859\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.22956699899014726\n",
            "\t the loss for timestep 2 is: 1.606545174964586\n",
            "\t the loss for timestep 3 is: 0.2926853714849486\n",
            "\t the loss for timestep 4 is: 1.382159333482098\n",
            "\t the loss for timestep 5 is: 1.0991643917688332\n",
            "\t the loss for timestep 6 is: 1.4436193198187806\n",
            "\t the loss for timestep 7 is: 0.36305468006154185\n",
            "\t the loss for timestep 8 is: 1.2027160971493354\n",
            "\t the loss for timestep 9 is: 0.38701728912979555\n",
            "\t the loss for timestep 10 is: 1.1290881169809193\n",
            "\t the loss for timestep 11 is: 0.4111026503313318\n",
            "\t the loss for timestep 12 is: 1.0769543846255147\n",
            "\t the loss for timestep 13 is: 0.431423780861049\n",
            "\t the loss for timestep 14 is: 1.0366529755540559\n",
            "\t the loss for timestep 15 is: 0.4490820446084145\n",
            "\t the loss for timestep 16 is: 1.004419992392832\n",
            "\t the loss for timestep 17 is: 0.46485664000130755\n",
            "\t the loss for timestep 18 is: 0.9778929827743127\n",
            "\t the loss for timestep 19 is: 0.4793043517881239\n",
            "\t the loss for timestep 20 is: 0.9555292958726753\n",
            "\t the loss for timestep 21 is: 0.4928320844316561\n",
            "\t the loss for timestep 22 is: 0.9362762802573767\n",
            "\t the loss for timestep 23 is: 0.5057414772952294\n",
            "\t the loss for timestep 24 is: 0.9193926081360226\n",
            "\t the loss for timestep 25 is: 0.5182557123461848\n",
            "\t the loss for timestep 26 is: 0.9043459199253926\n",
            "\t the loss for timestep 27 is: 0.5305358154647484\n",
            "\t the loss for timestep 28 is: 0.8907485696965294\n",
            "\t the loss for timestep 29 is: 0.5426909024798497\n",
            "\t the loss for timestep 30 is: 0.8783192656348426\n",
            "\t the loss for timestep 31 is: 0.5547850671062821\n",
            "\t the loss for timestep 32 is: 0.866854578609203\n",
            "\t the loss for timestep 33 is: 0.5668418932070937\n",
            "\t the loss for timestep 34 is: 169.64228973257246\n",
            "\t the loss for timestep 35 is: 180.36762441125063\n",
            "\t the loss for timestep 36 is: 0.6410751619615824\n",
            "\t the loss for timestep 37 is: 0.7987769807181375\n",
            "\t the loss for timestep 38 is: 0.6340471794389944\n",
            "\t the loss for timestep 39 is: 0.8649824936672991\n",
            "\t the loss for timestep 40 is: 0.6752094675531387\n",
            "\t the loss for timestep 41 is: 0.8025061823930348\n",
            "\t the loss for timestep 42 is: 0.693740909118302\n",
            "\t the loss for timestep 43 is: 0.8081714764775253\n",
            "\t the loss for timestep 44 is: 0.6994906542157144\n",
            "\t the loss for timestep 45 is: 0.7992113296165698\n",
            "\t the loss for timestep 46 is: 0.719783275805657\n",
            "\t the loss for timestep 47 is: 0.783054867193165\n",
            "\t the loss for timestep 48 is: 0.8341020191384121\n",
            "\t the loss for timestep 49 is: 0.8324989594745494\n",
            "\t the loss for timestep 50 is: 0.7556819554257469\n",
            "\t the loss for timestep 51 is: 0.8064946872780586\n",
            "\t the loss for timestep 52 is: 0.7620119043455433\n",
            "\t the loss for timestep 53 is: 0.8037798735121386\n",
            "\t the loss for timestep 54 is: 0.7738258015766275\n",
            "\t the loss for timestep 55 is: 0.8023848019008776\n",
            "\t the loss for timestep 56 is: 0.7820075711611807\n",
            "\t the loss for timestep 57 is: 0.8008962259248685\n",
            "\t the loss for timestep 58 is: 0.7868269665804702\n",
            "\t the loss for timestep 59 is: 0.7987209958176669\n",
            "\t the loss for timestep 60 is: 0.7885527309601393\n",
            "\t the loss for timestep 61 is: 0.7953992179698753\n",
            "\t the loss for timestep 62 is: 1.2668543746938816\n",
            "\t the loss for timestep 63 is: 1.3329509132867998\n",
            "\t the loss for timestep 64 is: 2.1723544864122664\n",
            "\t the loss for timestep 65 is: 1.6605373581884177\n",
            "\t the loss for timestep 66 is: 0.7644083706272895\n",
            "\t the loss for timestep 67 is: 0.8686365181863804\n",
            "\t the loss for timestep 68 is: 0.7107965817991122\n",
            "\t the loss for timestep 69 is: 0.8172065382790195\n",
            "\t the loss for timestep 70 is: 0.7169745560953951\n",
            "\t the loss for timestep 71 is: 0.7885264355628723\n",
            "\t the loss for timestep 72 is: 0.7082724211271992\n",
            "\t the loss for timestep 73 is: 0.7677832687858388\n",
            "\t the loss for timestep 74 is: 0.7015257257405472\n",
            "\t the loss for timestep 75 is: 0.746832735461229\n",
            "\t the loss for timestep 76 is: 0.6914926768828192\n",
            "\t the loss for timestep 77 is: 0.7275472415809953\n",
            "\t the loss for timestep 78 is: 0.6792022383870276\n",
            "\t the loss for timestep 79 is: 2.10130999842535\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.24462076843441113\n",
            "\t the loss for timestep 2 is: 1.569558053372893\n",
            "\t the loss for timestep 3 is: 0.3131684159320805\n",
            "\t the loss for timestep 4 is: 1.3397720784929628\n",
            "\t the loss for timestep 5 is: 1.0666983781453514\n",
            "\t the loss for timestep 6 is: 1.4286239567414536\n",
            "\t the loss for timestep 7 is: 0.3823311731770735\n",
            "\t the loss for timestep 8 is: 1.1708013751884223\n",
            "\t the loss for timestep 9 is: 0.40572840643728386\n",
            "\t the loss for timestep 10 is: 1.0974387314334784\n",
            "\t the loss for timestep 11 is: 0.4286030201918901\n",
            "\t the loss for timestep 12 is: 1.0467937302215278\n",
            "\t the loss for timestep 13 is: 0.4465137432276407\n",
            "\t the loss for timestep 14 is: 1.0089196104466396\n",
            "\t the loss for timestep 15 is: 0.46062948189378117\n",
            "\t the loss for timestep 16 is: 0.9799201017368772\n",
            "\t the loss for timestep 17 is: 0.4717607974276576\n",
            "\t the loss for timestep 18 is: 0.9574079677341301\n",
            "\t the loss for timestep 19 is: 0.4805060940446514\n",
            "\t the loss for timestep 20 is: 0.9398489644613592\n",
            "\t the loss for timestep 21 is: 0.48733832363203267\n",
            "\t the loss for timestep 22 is: 0.926199975213796\n",
            "\t the loss for timestep 23 is: 0.49266035153729637\n",
            "\t the loss for timestep 24 is: 0.9157109232254956\n",
            "\t the loss for timestep 25 is: 0.4968407832231517\n",
            "\t the loss for timestep 26 is: 0.9078067052080432\n",
            "\t the loss for timestep 27 is: 0.5002392376413112\n",
            "\t the loss for timestep 28 is: 0.9020084279511627\n",
            "\t the loss for timestep 29 is: 0.5032251922402863\n",
            "\t the loss for timestep 30 is: 0.8978816587094887\n",
            "\t the loss for timestep 31 is: 0.5061932388277084\n",
            "\t the loss for timestep 32 is: 0.8949959533956147\n",
            "\t the loss for timestep 33 is: 0.5095732560721383\n",
            "\t the loss for timestep 34 is: 169.37629120255488\n",
            "\t the loss for timestep 35 is: 181.03376130166743\n",
            "\t the loss for timestep 36 is: 0.6247739213157742\n",
            "\t the loss for timestep 37 is: 0.7555057733578409\n",
            "\t the loss for timestep 38 is: 0.6070880954462189\n",
            "\t the loss for timestep 39 is: 0.8297263207571015\n",
            "\t the loss for timestep 40 is: 0.6356999098112855\n",
            "\t the loss for timestep 41 is: 0.7662536983499623\n",
            "\t the loss for timestep 42 is: 0.6410499433748874\n",
            "\t the loss for timestep 43 is: 0.7733950940687155\n",
            "\t the loss for timestep 44 is: 0.6336019058258902\n",
            "\t the loss for timestep 45 is: 0.7645053602832573\n",
            "\t the loss for timestep 46 is: 0.6421058320212417\n",
            "\t the loss for timestep 47 is: 0.7263087597372376\n",
            "\t the loss for timestep 48 is: 0.7282514690832057\n",
            "\t the loss for timestep 49 is: 0.7732249449413542\n",
            "\t the loss for timestep 50 is: 0.6666374146093428\n",
            "\t the loss for timestep 51 is: 0.7510589266229164\n",
            "\t the loss for timestep 52 is: 0.6668286159310123\n",
            "\t the loss for timestep 53 is: 0.7453318752972635\n",
            "\t the loss for timestep 54 is: 0.6715838805263636\n",
            "\t the loss for timestep 55 is: 0.7394989277252717\n",
            "\t the loss for timestep 56 is: 0.674657132346729\n",
            "\t the loss for timestep 57 is: 0.7332249156745786\n",
            "\t the loss for timestep 58 is: 0.6760231712145655\n",
            "\t the loss for timestep 59 is: 0.7265337049186938\n",
            "\t the loss for timestep 60 is: 0.6756874700666391\n",
            "\t the loss for timestep 61 is: 0.7194263996255589\n",
            "\t the loss for timestep 62 is: 1.1256136997788089\n",
            "\t the loss for timestep 63 is: 1.1739482311850682\n",
            "\t the loss for timestep 64 is: 2.0364002320659873\n",
            "\t the loss for timestep 65 is: 1.421992133185261\n",
            "\t the loss for timestep 66 is: 0.6359586385246228\n",
            "\t the loss for timestep 67 is: 0.7815856684790117\n",
            "\t the loss for timestep 68 is: 0.5926873773528297\n",
            "\t the loss for timestep 69 is: 0.7583659153384466\n",
            "\t the loss for timestep 70 is: 0.5894271986835216\n",
            "\t the loss for timestep 71 is: 0.7456125997547411\n",
            "\t the loss for timestep 72 is: 0.575426490292258\n",
            "\t the loss for timestep 73 is: 0.738628935532442\n",
            "\t the loss for timestep 74 is: 0.563793083247554\n",
            "\t the loss for timestep 75 is: 0.7323890447793797\n",
            "\t the loss for timestep 76 is: 0.5493409182297768\n",
            "\t the loss for timestep 77 is: 0.729732595888813\n",
            "\t the loss for timestep 78 is: 0.5317156178254423\n",
            "\t the loss for timestep 79 is: 2.1842281400450845\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.1884935781284201\n",
            "\t the loss for timestep 2 is: 1.7246293533383217\n",
            "\t the loss for timestep 3 is: 0.21890836391277385\n",
            "\t the loss for timestep 4 is: 1.566717735497059\n",
            "\t the loss for timestep 5 is: 0.7221850293551622\n",
            "\t the loss for timestep 6 is: 1.7240564216549763\n",
            "\t the loss for timestep 7 is: 0.24491826160010355\n",
            "\t the loss for timestep 8 is: 1.461421997265516\n",
            "\t the loss for timestep 9 is: 0.2531849379594121\n",
            "\t the loss for timestep 10 is: 1.4191127815903062\n",
            "\t the loss for timestep 11 is: 0.26164151705400335\n",
            "\t the loss for timestep 12 is: 1.3897955475793293\n",
            "\t the loss for timestep 13 is: 0.2695230406335614\n",
            "\t the loss for timestep 14 is: 1.3656807810603402\n",
            "\t the loss for timestep 15 is: 0.27786069705777855\n",
            "\t the loss for timestep 16 is: 1.3428896837393813\n",
            "\t the loss for timestep 17 is: 0.2874728005970584\n",
            "\t the loss for timestep 18 is: 1.3189082923298172\n",
            "\t the loss for timestep 19 is: 0.2990902243629243\n",
            "\t the loss for timestep 20 is: 1.2920570567316976\n",
            "\t the loss for timestep 21 is: 0.3134364269151285\n",
            "\t the loss for timestep 22 is: 1.261237280484933\n",
            "\t the loss for timestep 23 is: 0.3312789640535446\n",
            "\t the loss for timestep 24 is: 1.225834450707306\n",
            "\t the loss for timestep 25 is: 0.3534511692374422\n",
            "\t the loss for timestep 26 is: 1.1857240945706014\n",
            "\t the loss for timestep 27 is: 0.38082923422266807\n",
            "\t the loss for timestep 28 is: 1.1413464493065553\n",
            "\t the loss for timestep 29 is: 0.4142375249886522\n",
            "\t the loss for timestep 30 is: 1.0938199094920502\n",
            "\t the loss for timestep 31 is: 0.4542488634915216\n",
            "\t the loss for timestep 32 is: 1.0450195722995173\n",
            "\t the loss for timestep 33 is: 0.500866404859784\n",
            "\t the loss for timestep 34 is: 168.3961209451518\n",
            "\t the loss for timestep 35 is: 179.23778819569\n",
            "\t the loss for timestep 36 is: 0.6658251547372088\n",
            "\t the loss for timestep 37 is: 0.8781781607871434\n",
            "\t the loss for timestep 38 is: 0.704628722968569\n",
            "\t the loss for timestep 39 is: 0.9528416451949855\n",
            "\t the loss for timestep 40 is: 0.8126265713039711\n",
            "\t the loss for timestep 41 is: 0.8846383414143325\n",
            "\t the loss for timestep 42 is: 0.8671714641316841\n",
            "\t the loss for timestep 43 is: 0.922451241151642\n",
            "\t the loss for timestep 44 is: 0.9023491001120801\n",
            "\t the loss for timestep 45 is: 0.9446046887504194\n",
            "\t the loss for timestep 46 is: 0.9548076662165021\n",
            "\t the loss for timestep 47 is: 0.8896096071998805\n",
            "\t the loss for timestep 48 is: 1.0193484992025375\n",
            "\t the loss for timestep 49 is: 1.1040316790817795\n",
            "\t the loss for timestep 50 is: 1.0469506917148788\n",
            "\t the loss for timestep 51 is: 1.0888693110534695\n",
            "\t the loss for timestep 52 is: 1.0897053475984309\n",
            "\t the loss for timestep 53 is: 1.1161317466140213\n",
            "\t the loss for timestep 54 is: 1.1307094692531667\n",
            "\t the loss for timestep 55 is: 1.1468982072762266\n",
            "\t the loss for timestep 56 is: 1.1593742933339226\n",
            "\t the loss for timestep 57 is: 1.1695961721726498\n",
            "\t the loss for timestep 58 is: 1.1768141630091795\n",
            "\t the loss for timestep 59 is: 1.1810103290367615\n",
            "\t the loss for timestep 60 is: 1.1820545648997516\n",
            "\t the loss for timestep 61 is: 1.1799257144403148\n",
            "\t the loss for timestep 62 is: 1.5119743185025372\n",
            "\t the loss for timestep 63 is: 1.6947617958745123\n",
            "\t the loss for timestep 64 is: 2.541858974663778\n",
            "\t the loss for timestep 65 is: 2.3214807878794153\n",
            "\t the loss for timestep 66 is: 1.1850079481013114\n",
            "\t the loss for timestep 67 is: 1.1420967754437616\n",
            "\t the loss for timestep 68 is: 1.1050668732019457\n",
            "\t the loss for timestep 69 is: 1.0753101933824918\n",
            "\t the loss for timestep 70 is: 1.0661672844107828\n",
            "\t the loss for timestep 71 is: 1.0346070071408273\n",
            "\t the loss for timestep 72 is: 1.006470439969942\n",
            "\t the loss for timestep 73 is: 0.9901810329598865\n",
            "\t the loss for timestep 74 is: 0.9642905158111432\n",
            "\t the loss for timestep 75 is: 0.9438548029584158\n",
            "\t the loss for timestep 76 is: 0.9209204427121038\n",
            "\t the loss for timestep 77 is: 0.9001770730963085\n",
            "\t the loss for timestep 78 is: 0.8789670496987897\n",
            "\t the loss for timestep 79 is: 2.373446424630551\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.413402723484812\n",
            "\t the loss for timestep 2 is: 1.3374352662362012\n",
            "\t the loss for timestep 3 is: 0.5985672325051115\n",
            "\t the loss for timestep 4 is: 1.070772849197708\n",
            "\t the loss for timestep 5 is: 2.01862613452533\n",
            "\t the loss for timestep 6 is: 1.4352857177033662\n",
            "\t the loss for timestep 7 is: 0.5699280599468196\n",
            "\t the loss for timestep 8 is: 1.0936881154291502\n",
            "\t the loss for timestep 9 is: 0.6713098286325518\n",
            "\t the loss for timestep 10 is: 0.9590815955655007\n",
            "\t the loss for timestep 11 is: 0.7244310132753754\n",
            "\t the loss for timestep 12 is: 0.8889627018802166\n",
            "\t the loss for timestep 13 is: 0.7487244483869295\n",
            "\t the loss for timestep 14 is: 0.8456417946812994\n",
            "\t the loss for timestep 15 is: 0.7560573411710433\n",
            "\t the loss for timestep 16 is: 0.814986954584815\n",
            "\t the loss for timestep 17 is: 0.7536289676870146\n",
            "\t the loss for timestep 18 is: 0.7905710076191765\n",
            "\t the loss for timestep 19 is: 0.7454866133064921\n",
            "\t the loss for timestep 20 is: 0.7693537546148288\n",
            "\t the loss for timestep 21 is: 0.7339354969168059\n",
            "\t the loss for timestep 22 is: 0.7498764849586351\n",
            "\t the loss for timestep 23 is: 0.7203277663106172\n",
            "\t the loss for timestep 24 is: 0.7314514456509846\n",
            "\t the loss for timestep 25 is: 0.7054855821228341\n",
            "\t the loss for timestep 26 is: 0.7137775154523855\n",
            "\t the loss for timestep 27 is: 0.6899239822127429\n",
            "\t the loss for timestep 28 is: 0.6967511471251775\n",
            "\t the loss for timestep 29 is: 0.673967761495877\n",
            "\t the loss for timestep 30 is: 0.6803761723294778\n",
            "\t the loss for timestep 31 is: 0.6578118307289278\n",
            "\t the loss for timestep 32 is: 0.6647212535204352\n",
            "\t the loss for timestep 33 is: 0.6415481513980208\n",
            "\t the loss for timestep 34 is: 171.958375383911\n",
            "\t the loss for timestep 35 is: 181.34106435088773\n",
            "\t the loss for timestep 36 is: 0.5696147868141648\n",
            "\t the loss for timestep 37 is: 0.7446811879120887\n",
            "\t the loss for timestep 38 is: 0.5341894529142306\n",
            "\t the loss for timestep 39 is: 0.8300134386851543\n",
            "\t the loss for timestep 40 is: 0.5269431463540553\n",
            "\t the loss for timestep 41 is: 0.7926637064241475\n",
            "\t the loss for timestep 42 is: 0.5050896130989498\n",
            "\t the loss for timestep 43 is: 0.8274528750302169\n",
            "\t the loss for timestep 44 is: 0.4690871852973929\n",
            "\t the loss for timestep 45 is: 0.8573149170321688\n",
            "\t the loss for timestep 46 is: 0.44299753404777575\n",
            "\t the loss for timestep 47 is: 0.8735616078981898\n",
            "\t the loss for timestep 48 is: 0.5109679129627146\n",
            "\t the loss for timestep 49 is: 0.8775026786572061\n",
            "\t the loss for timestep 50 is: 0.43744090736014984\n",
            "\t the loss for timestep 51 is: 0.9142797142893248\n",
            "\t the loss for timestep 52 is: 0.4059845327678994\n",
            "\t the loss for timestep 53 is: 0.9733612207193805\n",
            "\t the loss for timestep 54 is: 0.37865133045558524\n",
            "\t the loss for timestep 55 is: 1.0406343987488067\n",
            "\t the loss for timestep 56 is: 0.35431029381706647\n",
            "\t the loss for timestep 57 is: 1.1106980854053545\n",
            "\t the loss for timestep 58 is: 0.3354144421967522\n",
            "\t the loss for timestep 59 is: 1.175384728848534\n",
            "\t the loss for timestep 60 is: 0.32394649032885925\n",
            "\t the loss for timestep 61 is: 1.2255233803250307\n",
            "\t the loss for timestep 62 is: 0.5513233933339776\n",
            "\t the loss for timestep 63 is: 1.5094473952139873\n",
            "\t the loss for timestep 64 is: 1.7059038004935225\n",
            "\t the loss for timestep 65 is: 1.6534956381180996\n",
            "\t the loss for timestep 66 is: 0.532024857896378\n",
            "\t the loss for timestep 67 is: 0.9129377813157863\n",
            "\t the loss for timestep 68 is: 0.464392738356975\n",
            "\t the loss for timestep 69 is: 0.9280667023163846\n",
            "\t the loss for timestep 70 is: 0.45651078684988383\n",
            "\t the loss for timestep 71 is: 0.9541248706378743\n",
            "\t the loss for timestep 72 is: 0.45069451121706566\n",
            "\t the loss for timestep 73 is: 0.9754705747808016\n",
            "\t the loss for timestep 74 is: 0.4507216669499606\n",
            "\t the loss for timestep 75 is: 0.9878335167060331\n",
            "\t the loss for timestep 76 is: 0.45314146880101136\n",
            "\t the loss for timestep 77 is: 0.9946081270887654\n",
            "\t the loss for timestep 78 is: 0.45741380978039536\n",
            "\t the loss for timestep 79 is: 2.3494807117060197\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.2794619032828295\n",
            "\t the loss for timestep 2 is: 1.517491975230706\n",
            "\t the loss for timestep 3 is: 0.33900589126771413\n",
            "\t the loss for timestep 4 is: 1.3245896515524374\n",
            "\t the loss for timestep 5 is: 0.6402252593344178\n",
            "\t the loss for timestep 6 is: 1.6596263698101688\n",
            "\t the loss for timestep 7 is: 0.34632355736016657\n",
            "\t the loss for timestep 8 is: 1.3182849961281111\n",
            "\t the loss for timestep 9 is: 0.3636666076322385\n",
            "\t the loss for timestep 10 is: 1.235703141637885\n",
            "\t the loss for timestep 11 is: 0.3774306084771059\n",
            "\t the loss for timestep 12 is: 1.1900059264605534\n",
            "\t the loss for timestep 13 is: 0.3829533591154439\n",
            "\t the loss for timestep 14 is: 1.1655717936909311\n",
            "\t the loss for timestep 15 is: 0.3828582687878509\n",
            "\t the loss for timestep 16 is: 1.155694285029529\n",
            "\t the loss for timestep 17 is: 0.3784455617757278\n",
            "\t the loss for timestep 18 is: 1.1570377696739313\n",
            "\t the loss for timestep 19 is: 0.3707143337819815\n",
            "\t the loss for timestep 20 is: 1.1676418412824794\n",
            "\t the loss for timestep 21 is: 0.3606079392689017\n",
            "\t the loss for timestep 22 is: 1.1859415975426524\n",
            "\t the loss for timestep 23 is: 0.34916077421786323\n",
            "\t the loss for timestep 24 is: 1.2101497607173126\n",
            "\t the loss for timestep 25 is: 0.3375785162979953\n",
            "\t the loss for timestep 26 is: 1.2378142998531712\n",
            "\t the loss for timestep 27 is: 0.32726747590623095\n",
            "\t the loss for timestep 28 is: 1.2655516840367997\n",
            "\t the loss for timestep 29 is: 0.31982671829982146\n",
            "\t the loss for timestep 30 is: 1.2890533484351632\n",
            "\t the loss for timestep 31 is: 0.3170427745406864\n",
            "\t the loss for timestep 32 is: 1.3034202755275153\n",
            "\t the loss for timestep 33 is: 0.32094402043420206\n",
            "\t the loss for timestep 34 is: 166.57934359102697\n",
            "\t the loss for timestep 35 is: 183.1893661191728\n",
            "\t the loss for timestep 36 is: 0.798153649821087\n",
            "\t the loss for timestep 37 is: 0.6161592704577545\n",
            "\t the loss for timestep 38 is: 0.7790001810012082\n",
            "\t the loss for timestep 39 is: 0.6838294998337962\n",
            "\t the loss for timestep 40 is: 0.8150013135930015\n",
            "\t the loss for timestep 41 is: 0.6616756801512136\n",
            "\t the loss for timestep 42 is: 0.8185436082714037\n",
            "\t the loss for timestep 43 is: 0.6928116807051877\n",
            "\t the loss for timestep 44 is: 0.8112550409664401\n",
            "\t the loss for timestep 45 is: 0.7204826214658423\n",
            "\t the loss for timestep 46 is: 0.8166922445333367\n",
            "\t the loss for timestep 47 is: 0.7369484172593547\n",
            "\t the loss for timestep 48 is: 0.8996454869376981\n",
            "\t the loss for timestep 49 is: 0.8179017592560163\n",
            "\t the loss for timestep 50 is: 0.819821619208969\n",
            "\t the loss for timestep 51 is: 0.8369064886110845\n",
            "\t the loss for timestep 52 is: 0.8374595643107494\n",
            "\t the loss for timestep 53 is: 0.8552193726834008\n",
            "\t the loss for timestep 54 is: 0.8608954074973226\n",
            "\t the loss for timestep 55 is: 0.8749352754476998\n",
            "\t the loss for timestep 56 is: 0.8826570277817822\n",
            "\t the loss for timestep 57 is: 0.8941388499685583\n",
            "\t the loss for timestep 58 is: 0.9024685251238027\n",
            "\t the loss for timestep 59 is: 0.9120477480698437\n",
            "\t the loss for timestep 60 is: 0.9199473058813463\n",
            "\t the loss for timestep 61 is: 0.927856544896658\n",
            "\t the loss for timestep 62 is: 1.3320259615502326\n",
            "\t the loss for timestep 63 is: 1.268022889665164\n",
            "\t the loss for timestep 64 is: 2.3232342127418524\n",
            "\t the loss for timestep 65 is: 2.1671105617143214\n",
            "\t the loss for timestep 66 is: 0.8796120365038117\n",
            "\t the loss for timestep 67 is: 1.0025552184325044\n",
            "\t the loss for timestep 68 is: 0.9408454876818648\n",
            "\t the loss for timestep 69 is: 0.9739670974173796\n",
            "\t the loss for timestep 70 is: 0.97005171363502\n",
            "\t the loss for timestep 71 is: 0.9684975139636368\n",
            "\t the loss for timestep 72 is: 0.9523322762789149\n",
            "\t the loss for timestep 73 is: 0.9576074578569868\n",
            "\t the loss for timestep 74 is: 0.949397245511825\n",
            "\t the loss for timestep 75 is: 0.9457576896712373\n",
            "\t the loss for timestep 76 is: 0.9383917995368181\n",
            "\t the loss for timestep 77 is: 0.9314574241441147\n",
            "\t the loss for timestep 78 is: 0.9229602815697546\n",
            "\t the loss for timestep 79 is: 2.529136036839552\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.6645188167746342\n",
            "\t the loss for timestep 2 is: 1.1212377592382452\n",
            "\t the loss for timestep 3 is: 0.8152032277901299\n",
            "\t the loss for timestep 4 is: 0.9568914001505711\n",
            "\t the loss for timestep 5 is: 2.355623975391796\n",
            "\t the loss for timestep 6 is: 1.6428927809385414\n",
            "\t the loss for timestep 7 is: 0.5758248310573666\n",
            "\t the loss for timestep 8 is: 1.1053395566833648\n",
            "\t the loss for timestep 9 is: 0.7626926175351543\n",
            "\t the loss for timestep 10 is: 0.9365076804471333\n",
            "\t the loss for timestep 11 is: 0.8071705434271992\n",
            "\t the loss for timestep 12 is: 0.8714502926248346\n",
            "\t the loss for timestep 13 is: 0.8125007759605174\n",
            "\t the loss for timestep 14 is: 0.8347213658748803\n",
            "\t the loss for timestep 15 is: 0.8017826802573745\n",
            "\t the loss for timestep 16 is: 0.8068445429387893\n",
            "\t the loss for timestep 17 is: 0.7845604895952664\n",
            "\t the loss for timestep 18 is: 0.7821071001757619\n",
            "\t the loss for timestep 19 is: 0.7646451944772117\n",
            "\t the loss for timestep 20 is: 0.7587276177737324\n",
            "\t the loss for timestep 21 is: 0.7437180003298056\n",
            "\t the loss for timestep 22 is: 0.736198574968784\n",
            "\t the loss for timestep 23 is: 0.7226196696208438\n",
            "\t the loss for timestep 24 is: 0.7144362474736174\n",
            "\t the loss for timestep 25 is: 0.7018189931191355\n",
            "\t the loss for timestep 26 is: 0.6934866720651335\n",
            "\t the loss for timestep 27 is: 0.6815937520732003\n",
            "\t the loss for timestep 28 is: 0.6734204354783777\n",
            "\t the loss for timestep 29 is: 0.662108830587327\n",
            "\t the loss for timestep 30 is: 0.6542974977023561\n",
            "\t the loss for timestep 31 is: 0.6434540149942432\n",
            "\t the loss for timestep 32 is: 0.6361583934624018\n",
            "\t the loss for timestep 33 is: 0.625664171406842\n",
            "\t the loss for timestep 34 is: 172.1884642917124\n",
            "\t the loss for timestep 35 is: 184.1369605033514\n",
            "\t the loss for timestep 36 is: 0.6716024661153733\n",
            "\t the loss for timestep 37 is: 0.5639303508537911\n",
            "\t the loss for timestep 38 is: 0.6650280157467197\n",
            "\t the loss for timestep 39 is: 0.5792431136738566\n",
            "\t the loss for timestep 40 is: 0.6889902419813709\n",
            "\t the loss for timestep 41 is: 0.5341900187195202\n",
            "\t the loss for timestep 42 is: 0.7038443723652561\n",
            "\t the loss for timestep 43 is: 0.5112601365059297\n",
            "\t the loss for timestep 44 is: 0.7212448763986856\n",
            "\t the loss for timestep 45 is: 0.48182090054059223\n",
            "\t the loss for timestep 46 is: 0.7602109626460517\n",
            "\t the loss for timestep 47 is: 0.45970202029278406\n",
            "\t the loss for timestep 48 is: 0.8810301441761293\n",
            "\t the loss for timestep 49 is: 0.45822515953574305\n",
            "\t the loss for timestep 50 is: 0.8237307968718452\n",
            "\t the loss for timestep 51 is: 0.4183234010465375\n",
            "\t the loss for timestep 52 is: 0.8933498212407279\n",
            "\t the loss for timestep 53 is: 0.3883935050791907\n",
            "\t the loss for timestep 54 is: 0.9782987520324438\n",
            "\t the loss for timestep 55 is: 0.3675605958659186\n",
            "\t the loss for timestep 56 is: 1.0595113978529287\n",
            "\t the loss for timestep 57 is: 0.3640289150138759\n",
            "\t the loss for timestep 58 is: 1.1134590942566827\n",
            "\t the loss for timestep 59 is: 0.3869564741893049\n",
            "\t the loss for timestep 60 is: 1.12043380148823\n",
            "\t the loss for timestep 61 is: 0.44524376911948255\n",
            "\t the loss for timestep 62 is: 1.5072043964528739\n",
            "\t the loss for timestep 63 is: 1.211314489861411\n",
            "\t the loss for timestep 64 is: 2.1802588215030214\n",
            "\t the loss for timestep 65 is: 1.3546292339571095\n",
            "\t the loss for timestep 66 is: 0.9724971022004105\n",
            "\t the loss for timestep 67 is: 0.887501861556222\n",
            "\t the loss for timestep 68 is: 0.9221394499010758\n",
            "\t the loss for timestep 69 is: 0.9332096933633534\n",
            "\t the loss for timestep 70 is: 0.9836430054707028\n",
            "\t the loss for timestep 71 is: 1.0094540859973464\n",
            "\t the loss for timestep 72 is: 1.0481804444101372\n",
            "\t the loss for timestep 73 is: 1.083998782222021\n",
            "\t the loss for timestep 74 is: 1.1184747105013613\n",
            "\t the loss for timestep 75 is: 1.1512476426471951\n",
            "\t the loss for timestep 76 is: 1.181949484984353\n",
            "\t the loss for timestep 77 is: 1.210249957626549\n",
            "\t the loss for timestep 78 is: 1.235915315256253\n",
            "\t the loss for timestep 79 is: 1.935615475955484\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 1.2489138745011341\n",
            "\t the loss for timestep 2 is: 1.3441413886249398\n",
            "\t the loss for timestep 3 is: 1.2604292007014521\n",
            "\t the loss for timestep 4 is: 1.2758117010539414\n",
            "\t the loss for timestep 5 is: 1.9120592726096557\n",
            "\t the loss for timestep 6 is: 1.5916349496087188\n",
            "\t the loss for timestep 7 is: 1.1557901807565176\n",
            "\t the loss for timestep 8 is: 1.258074318355575\n",
            "\t the loss for timestep 9 is: 1.169332753392312\n",
            "\t the loss for timestep 10 is: 1.1716604744460433\n",
            "\t the loss for timestep 11 is: 1.1305661595065073\n",
            "\t the loss for timestep 12 is: 1.1088575243762322\n",
            "\t the loss for timestep 13 is: 1.0743265144138463\n",
            "\t the loss for timestep 14 is: 1.0442503566169141\n",
            "\t the loss for timestep 15 is: 1.0097239961358118\n",
            "\t the loss for timestep 16 is: 0.9764960747820259\n",
            "\t the loss for timestep 17 is: 0.9418592672305317\n",
            "\t the loss for timestep 18 is: 0.9082399706351001\n",
            "\t the loss for timestep 19 is: 0.8747707016501638\n",
            "\t the loss for timestep 20 is: 0.8426953249079168\n",
            "\t the loss for timestep 21 is: 0.8116829058657421\n",
            "\t the loss for timestep 22 is: 0.7824216142541307\n",
            "\t the loss for timestep 23 is: 0.7546900641972368\n",
            "\t the loss for timestep 24 is: 0.728861675981687\n",
            "\t the loss for timestep 25 is: 0.7047003110970389\n",
            "\t the loss for timestep 26 is: 0.6824015747115325\n",
            "\t the loss for timestep 27 is: 0.6616953562268865\n",
            "\t the loss for timestep 28 is: 0.6426929041986188\n",
            "\t the loss for timestep 29 is: 0.6250983359280334\n",
            "\t the loss for timestep 30 is: 0.6090032772697404\n",
            "\t the loss for timestep 31 is: 0.5940866837381067\n",
            "\t the loss for timestep 32 is: 0.5804698426028908\n",
            "\t the loss for timestep 33 is: 0.5677919680885182\n",
            "\t the loss for timestep 34 is: 173.1842143729062\n",
            "\t the loss for timestep 35 is: 183.07159717030888\n",
            "\t the loss for timestep 36 is: 0.46868855310793833\n",
            "\t the loss for timestep 37 is: 0.6639459004412399\n",
            "\t the loss for timestep 38 is: 0.4071137205612204\n",
            "\t the loss for timestep 39 is: 0.8014651636578198\n",
            "\t the loss for timestep 40 is: 0.33817558993455704\n",
            "\t the loss for timestep 41 is: 0.9159616377147473\n",
            "\t the loss for timestep 42 is: 0.2552665295705669\n",
            "\t the loss for timestep 43 is: 1.2242970334227798\n",
            "\t the loss for timestep 44 is: 0.18459217765076802\n",
            "\t the loss for timestep 45 is: 1.6084373641492795\n",
            "\t the loss for timestep 46 is: 0.1517086312912646\n",
            "\t the loss for timestep 47 is: 1.6575599101261518\n",
            "\t the loss for timestep 48 is: 0.1553633183801707\n",
            "\t the loss for timestep 49 is: 1.8456060709670137\n",
            "\t the loss for timestep 50 is: 0.140152498610545\n",
            "\t the loss for timestep 51 is: 1.9913525830587535\n",
            "\t the loss for timestep 52 is: 0.13637598031190726\n",
            "\t the loss for timestep 53 is: 2.0314029217648724\n",
            "\t the loss for timestep 54 is: 0.13493989699902698\n",
            "\t the loss for timestep 55 is: 2.0466239663879704\n",
            "\t the loss for timestep 56 is: 0.1340275871451489\n",
            "\t the loss for timestep 57 is: 2.056313264197052\n",
            "\t the loss for timestep 58 is: 0.13331364077791308\n",
            "\t the loss for timestep 59 is: 2.064010792586501\n",
            "\t the loss for timestep 60 is: 0.1327262269513474\n",
            "\t the loss for timestep 61 is: 2.0704540892627734\n",
            "\t the loss for timestep 62 is: 0.14376986486474022\n",
            "\t the loss for timestep 63 is: 2.1994716093444207\n",
            "\t the loss for timestep 64 is: 0.2251185655945897\n",
            "\t the loss for timestep 65 is: 2.865875606608003\n",
            "\t the loss for timestep 66 is: 0.13210737967248765\n",
            "\t the loss for timestep 67 is: 2.077235558105478\n",
            "\t the loss for timestep 68 is: 0.13123905847814926\n",
            "\t the loss for timestep 69 is: 2.087235725851314\n",
            "\t the loss for timestep 70 is: 0.13098960763406522\n",
            "\t the loss for timestep 71 is: 2.1106114752591996\n",
            "\t the loss for timestep 72 is: 0.13063306479628983\n",
            "\t the loss for timestep 73 is: 2.09459772700425\n",
            "\t the loss for timestep 74 is: 0.13055796630505037\n",
            "\t the loss for timestep 75 is: 2.0953010476115606\n",
            "\t the loss for timestep 76 is: 0.1304094969456208\n",
            "\t the loss for timestep 77 is: 2.097043995083376\n",
            "\t the loss for timestep 78 is: 0.13027528898110238\n",
            "\t the loss for timestep 79 is: 3.0779270389786446\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.1300430242344622\n",
            "\t the loss for timestep 2 is: 2.1018144199191413\n",
            "\t the loss for timestep 3 is: 0.1301455509507528\n",
            "\t the loss for timestep 4 is: 2.100365747509253\n",
            "\t the loss for timestep 5 is: 0.1408440907447015\n",
            "\t the loss for timestep 6 is: 3.4226043442579632\n",
            "\t the loss for timestep 7 is: 0.12844086451762235\n",
            "\t the loss for timestep 8 is: 2.124604684705438\n",
            "\t the loss for timestep 9 is: 0.13006880704409374\n",
            "\t the loss for timestep 10 is: 2.101485954291462\n",
            "\t the loss for timestep 11 is: 0.13016769904129707\n",
            "\t the loss for timestep 12 is: 2.1001113937068774\n",
            "\t the loss for timestep 13 is: 0.13018220535155975\n",
            "\t the loss for timestep 14 is: 2.099924558396798\n",
            "\t the loss for timestep 15 is: 0.13019294868926928\n",
            "\t the loss for timestep 16 is: 2.0997968100733635\n",
            "\t the loss for timestep 17 is: 0.13020453958370748\n",
            "\t the loss for timestep 18 is: 2.0996596962257628\n",
            "\t the loss for timestep 19 is: 0.1302172791264478\n",
            "\t the loss for timestep 20 is: 2.099509077339253\n",
            "\t the loss for timestep 21 is: 0.1302312108978573\n",
            "\t the loss for timestep 22 is: 2.0993447320209135\n",
            "\t the loss for timestep 23 is: 0.1302463657113795\n",
            "\t the loss for timestep 24 is: 2.0991655062317265\n",
            "\t the loss for timestep 25 is: 0.13026277915168066\n",
            "\t the loss for timestep 26 is: 2.0989721792576828\n",
            "\t the loss for timestep 27 is: 0.13028048491751884\n",
            "\t the loss for timestep 28 is: 2.098763242534059\n",
            "\t the loss for timestep 29 is: 0.13029952764186706\n",
            "\t the loss for timestep 30 is: 2.098539138095683\n",
            "\t the loss for timestep 31 is: 0.1303199475083039\n",
            "\t the loss for timestep 32 is: 2.098299169622588\n",
            "\t the loss for timestep 33 is: 0.1303417933734587\n",
            "\t the loss for timestep 34 is: 162.20312280064257\n",
            "\t the loss for timestep 35 is: 194.91027492796974\n",
            "\t the loss for timestep 36 is: 2.0964043377864945\n",
            "\t the loss for timestep 37 is: 0.13039103899848928\n",
            "\t the loss for timestep 38 is: 2.097448737372971\n",
            "\t the loss for timestep 39 is: 0.13037026244683134\n",
            "\t the loss for timestep 40 is: 2.1976553672805075\n",
            "\t the loss for timestep 41 is: 0.1301699817903707\n",
            "\t the loss for timestep 42 is: 2.1341805281183905\n",
            "\t the loss for timestep 43 is: 0.13031192581061923\n",
            "\t the loss for timestep 44 is: 2.0987647955444055\n",
            "\t the loss for timestep 45 is: 0.13047880361377506\n",
            "\t the loss for timestep 46 is: 2.0964610304853553\n",
            "\t the loss for timestep 47 is: 0.1307595999163748\n",
            "\t the loss for timestep 48 is: 1.8164202733061217\n",
            "\t the loss for timestep 49 is: 0.13378912333565843\n",
            "\t the loss for timestep 50 is: 2.051856981732688\n",
            "\t the loss for timestep 51 is: 0.1308065064094887\n",
            "\t the loss for timestep 52 is: 2.0921911332929803\n",
            "\t the loss for timestep 53 is: 0.1306371629566049\n",
            "\t the loss for timestep 54 is: 2.094580925901914\n",
            "\t the loss for timestep 55 is: 0.13066304507293613\n",
            "\t the loss for timestep 56 is: 2.0943130586790213\n",
            "\t the loss for timestep 57 is: 0.13070408241700918\n",
            "\t the loss for timestep 58 is: 2.0938451909542173\n",
            "\t the loss for timestep 59 is: 0.13074841199629836\n",
            "\t the loss for timestep 60 is: 2.0933402691260294\n",
            "\t the loss for timestep 61 is: 0.13079535859220537\n",
            "\t the loss for timestep 62 is: 1.9417794257300371\n",
            "\t the loss for timestep 63 is: 0.14853100454018464\n",
            "\t the loss for timestep 64 is: 3.152450722075403\n",
            "\t the loss for timestep 65 is: 0.15134539631745633\n",
            "\t the loss for timestep 66 is: 1.9983241766360318\n",
            "\t the loss for timestep 67 is: 0.1316573271341543\n",
            "\t the loss for timestep 68 is: 2.081754687887656\n",
            "\t the loss for timestep 69 is: 0.13108441865534903\n",
            "\t the loss for timestep 70 is: 2.1099703497222846\n",
            "\t the loss for timestep 71 is: 0.13101970143634456\n",
            "\t the loss for timestep 72 is: 2.090441775937904\n",
            "\t the loss for timestep 73 is: 0.13118867284111768\n",
            "\t the loss for timestep 74 is: 2.0884304726776977\n",
            "\t the loss for timestep 75 is: 0.13128382805197483\n",
            "\t the loss for timestep 76 is: 2.0873692423887027\n",
            "\t the loss for timestep 77 is: 0.13137843505430996\n",
            "\t the loss for timestep 78 is: 2.0863325616415027\n",
            "\t the loss for timestep 79 is: 0.20843792983685128\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.13126775813666092\n",
            "\t the loss for timestep 2 is: 2.087955549149432\n",
            "\t the loss for timestep 3 is: 0.13151366816136312\n",
            "\t the loss for timestep 4 is: 2.084784837343059\n",
            "\t the loss for timestep 5 is: 0.15020069887778198\n",
            "\t the loss for timestep 6 is: 3.34246325151256\n",
            "\t the loss for timestep 7 is: 0.12871248702334598\n",
            "\t the loss for timestep 8 is: 2.1212401870149944\n",
            "\t the loss for timestep 9 is: 0.13134034649521356\n",
            "\t the loss for timestep 10 is: 2.0871099651042595\n",
            "\t the loss for timestep 11 is: 0.131573219983792\n",
            "\t the loss for timestep 12 is: 2.084163961232753\n",
            "\t the loss for timestep 13 is: 0.13161590383028327\n",
            "\t the loss for timestep 14 is: 2.083668002380978\n",
            "\t the loss for timestep 15 is: 0.13164562711556577\n",
            "\t the loss for timestep 16 is: 2.083349234855253\n",
            "\t the loss for timestep 17 is: 0.13167725454728832\n",
            "\t the loss for timestep 18 is: 2.0830134852569318\n",
            "\t the loss for timestep 19 is: 0.13171216124002078\n",
            "\t the loss for timestep 20 is: 2.0826435563069907\n",
            "\t the loss for timestep 21 is: 0.1317505790200981\n",
            "\t the loss for timestep 22 is: 2.082237255042402\n",
            "\t the loss for timestep 23 is: 0.13179265541989477\n",
            "\t the loss for timestep 24 is: 2.081792414851386\n",
            "\t the loss for timestep 25 is: 0.13183854964911818\n",
            "\t the loss for timestep 26 is: 2.0813087622059387\n",
            "\t the loss for timestep 27 is: 0.1318884294341469\n",
            "\t the loss for timestep 28 is: 2.080783675806799\n",
            "\t the loss for timestep 29 is: 0.13194249287908227\n",
            "\t the loss for timestep 30 is: 2.0802163071504354\n",
            "\t the loss for timestep 31 is: 0.1320009458503599\n",
            "\t the loss for timestep 32 is: 2.07960459038709\n",
            "\t the loss for timestep 33 is: 0.13206402370133752\n",
            "\t the loss for timestep 34 is: 162.28692366961513\n",
            "\t the loss for timestep 35 is: 194.7996648201002\n",
            "\t the loss for timestep 36 is: 2.064490127407047\n",
            "\t the loss for timestep 37 is: 0.13230227668507089\n",
            "\t the loss for timestep 38 is: 2.0762448756329546\n",
            "\t the loss for timestep 39 is: 0.13223545957723368\n",
            "\t the loss for timestep 40 is: 2.177118242680015\n",
            "\t the loss for timestep 41 is: 0.13191056797525336\n",
            "\t the loss for timestep 42 is: 2.114929694460451\n",
            "\t the loss for timestep 43 is: 0.1321806952162779\n",
            "\t the loss for timestep 44 is: 2.0783603472587155\n",
            "\t the loss for timestep 45 is: 0.13251022365951234\n",
            "\t the loss for timestep 46 is: 2.0743862105190956\n",
            "\t the loss for timestep 47 is: 0.13307824595266873\n",
            "\t the loss for timestep 48 is: 1.7978875936652645\n",
            "\t the loss for timestep 49 is: 0.13814225842853617\n",
            "\t the loss for timestep 50 is: 2.0077852476154816\n",
            "\t the loss for timestep 51 is: 0.13345971383909225\n",
            "\t the loss for timestep 52 is: 2.0635726984190006\n",
            "\t the loss for timestep 53 is: 0.13305951340839534\n",
            "\t the loss for timestep 54 is: 2.068656906209989\n",
            "\t the loss for timestep 55 is: 0.13314288377289676\n",
            "\t the loss for timestep 56 is: 2.067939913415948\n",
            "\t the loss for timestep 57 is: 0.1332872828578097\n",
            "\t the loss for timestep 58 is: 2.066520231749787\n",
            "\t the loss for timestep 59 is: 0.13344849229639522\n",
            "\t the loss for timestep 60 is: 2.064934411401919\n",
            "\t the loss for timestep 61 is: 0.13362262819686496\n",
            "\t the loss for timestep 62 is: 1.9290248221192232\n",
            "\t the loss for timestep 63 is: 0.16639620722177656\n",
            "\t the loss for timestep 64 is: 3.069853303533915\n",
            "\t the loss for timestep 65 is: 0.19169890137686513\n",
            "\t the loss for timestep 66 is: 1.7547314176458477\n",
            "\t the loss for timestep 67 is: 0.13926988907242666\n",
            "\t the loss for timestep 68 is: 2.00094610122014\n",
            "\t the loss for timestep 69 is: 0.13519948534499648\n",
            "\t the loss for timestep 70 is: 2.0673222223948633\n",
            "\t the loss for timestep 71 is: 0.13475382474171133\n",
            "\t the loss for timestep 72 is: 2.05261668060193\n",
            "\t the loss for timestep 73 is: 0.13520463752205356\n",
            "\t the loss for timestep 74 is: 2.0483725597915816\n",
            "\t the loss for timestep 75 is: 0.13560999662901185\n",
            "\t the loss for timestep 76 is: 2.044655158366058\n",
            "\t the loss for timestep 77 is: 0.1360430104869213\n",
            "\t the loss for timestep 78 is: 2.0407581217283512\n",
            "\t the loss for timestep 79 is: 0.32655221243231813\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.13555603525428567\n",
            "\t the loss for timestep 2 is: 2.046799585512268\n",
            "\t the loss for timestep 3 is: 0.13663468850181565\n",
            "\t the loss for timestep 4 is: 2.0352628537286357\n",
            "\t the loss for timestep 5 is: 0.1885298752687338\n",
            "\t the loss for timestep 6 is: 3.0934989000565447\n",
            "\t the loss for timestep 7 is: 0.13033544691746884\n",
            "\t the loss for timestep 8 is: 2.103721341528371\n",
            "\t the loss for timestep 9 is: 0.13601564891203516\n",
            "\t the loss for timestep 10 is: 2.0423024885086134\n",
            "\t the loss for timestep 11 is: 0.13697116347632854\n",
            "\t the loss for timestep 12 is: 2.0323984085736706\n",
            "\t the loss for timestep 13 is: 0.1372434490164736\n",
            "\t the loss for timestep 14 is: 2.0298120006792613\n",
            "\t the loss for timestep 15 is: 0.13742550868916145\n",
            "\t the loss for timestep 16 is: 2.0282309688673203\n",
            "\t the loss for timestep 17 is: 0.13761211911815802\n",
            "\t the loss for timestep 18 is: 2.026653776308077\n",
            "\t the loss for timestep 19 is: 0.1378199663662606\n",
            "\t the loss for timestep 20 is: 2.0249108652329784\n",
            "\t the loss for timestep 21 is: 0.13805336987546438\n",
            "\t the loss for timestep 22 is: 2.0229645505347364\n",
            "\t the loss for timestep 23 is: 0.13831489379199147\n",
            "\t the loss for timestep 24 is: 2.020795851709395\n",
            "\t the loss for timestep 25 is: 0.13860712169828612\n",
            "\t the loss for timestep 26 is: 2.0183890953653343\n",
            "\t the loss for timestep 27 is: 0.13893296645779143\n",
            "\t the loss for timestep 28 is: 2.0157247854630183\n",
            "\t the loss for timestep 29 is: 0.13929582710200228\n",
            "\t the loss for timestep 30 is: 2.01278264205168\n",
            "\t the loss for timestep 31 is: 0.13969962541111264\n",
            "\t the loss for timestep 32 is: 2.009538456231414\n",
            "\t the loss for timestep 33 is: 0.14014894664080213\n",
            "\t the loss for timestep 34 is: 162.61229971836073\n",
            "\t the loss for timestep 35 is: 194.1089465435514\n",
            "\t the loss for timestep 36 is: 1.9048837567962937\n",
            "\t the loss for timestep 37 is: 0.14357107453184262\n",
            "\t the loss for timestep 38 is: 1.9753975438457683\n",
            "\t the loss for timestep 39 is: 0.14259157649512116\n",
            "\t the loss for timestep 40 is: 2.085763199966231\n",
            "\t the loss for timestep 41 is: 0.14177796565148054\n",
            "\t the loss for timestep 42 is: 2.0284713597151427\n",
            "\t the loss for timestep 43 is: 0.14309556763057796\n",
            "\t the loss for timestep 44 is: 1.984997702202343\n",
            "\t the loss for timestep 45 is: 0.1448918822586091\n",
            "\t the loss for timestep 46 is: 1.9703446703213476\n",
            "\t the loss for timestep 47 is: 0.14753810717894655\n",
            "\t the loss for timestep 48 is: 1.711956647632578\n",
            "\t the loss for timestep 49 is: 0.164090579189777\n",
            "\t the loss for timestep 50 is: 1.8172339105261266\n",
            "\t the loss for timestep 51 is: 0.15449420897904545\n",
            "\t the loss for timestep 52 is: 1.896932409560825\n",
            "\t the loss for timestep 53 is: 0.15311033448646943\n",
            "\t the loss for timestep 54 is: 1.911650183980252\n",
            "\t the loss for timestep 55 is: 0.15449124519679727\n",
            "\t the loss for timestep 56 is: 1.9045126925692233\n",
            "\t the loss for timestep 57 is: 0.15699532567547536\n",
            "\t the loss for timestep 58 is: 1.8895189024143106\n",
            "\t the loss for timestep 59 is: 0.1602303981764707\n",
            "\t the loss for timestep 60 is: 1.8704105008844578\n",
            "\t the loss for timestep 61 is: 0.16418390056685708\n",
            "\t the loss for timestep 62 is: 1.8360707054074499\n",
            "\t the loss for timestep 63 is: 0.3317593949213804\n",
            "\t the loss for timestep 64 is: 2.710263971334645\n",
            "\t the loss for timestep 65 is: 0.7423276299775262\n",
            "\t the loss for timestep 66 is: 0.845070017851247\n",
            "\t the loss for timestep 67 is: 0.40118759119817504\n",
            "\t the loss for timestep 68 is: 0.9250687699884456\n",
            "\t the loss for timestep 69 is: 0.35996606963368266\n",
            "\t the loss for timestep 70 is: 1.0586388562024003\n",
            "\t the loss for timestep 71 is: 0.32228355794552016\n",
            "\t the loss for timestep 72 is: 1.1765402203320374\n",
            "\t the loss for timestep 73 is: 0.2994620492510322\n",
            "\t the loss for timestep 74 is: 1.2773988133811707\n",
            "\t the loss for timestep 75 is: 0.29122414049897005\n",
            "\t the loss for timestep 76 is: 1.3343725087385379\n",
            "\t the loss for timestep 77 is: 0.2994986770729014\n",
            "\t the loss for timestep 78 is: 1.3418690669380726\n",
            "\t the loss for timestep 79 is: 1.681495544371525\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.2173920308231773\n",
            "\t the loss for timestep 2 is: 1.6694771073874968\n",
            "\t the loss for timestep 3 is: 0.2716770867970543\n",
            "\t the loss for timestep 4 is: 1.4673092696596934\n",
            "\t the loss for timestep 5 is: 1.156663105146033\n",
            "\t the loss for timestep 6 is: 1.5210179947714266\n",
            "\t the loss for timestep 7 is: 0.32262795342038575\n",
            "\t the loss for timestep 8 is: 1.3045485071022285\n",
            "\t the loss for timestep 9 is: 0.35014404018460893\n",
            "\t the loss for timestep 10 is: 1.23770856171777\n",
            "\t the loss for timestep 11 is: 0.370370615380262\n",
            "\t the loss for timestep 12 is: 1.1894263193062424\n",
            "\t the loss for timestep 13 is: 0.3884074630420985\n",
            "\t the loss for timestep 14 is: 1.1511198874036885\n",
            "\t the loss for timestep 15 is: 0.40546442674093336\n",
            "\t the loss for timestep 16 is: 1.1188984843445873\n",
            "\t the loss for timestep 17 is: 0.42256306011888684\n",
            "\t the loss for timestep 18 is: 1.0902744779960458\n",
            "\t the loss for timestep 19 is: 0.44049235214250937\n",
            "\t the loss for timestep 20 is: 1.063632434470554\n",
            "\t the loss for timestep 21 is: 0.4598517951814015\n",
            "\t the loss for timestep 22 is: 1.0379611726507103\n",
            "\t the loss for timestep 23 is: 0.48105477094202387\n",
            "\t the loss for timestep 24 is: 1.012718006090009\n",
            "\t the loss for timestep 25 is: 0.5043069539397039\n",
            "\t the loss for timestep 26 is: 0.9877466117453384\n",
            "\t the loss for timestep 27 is: 0.5295729886234921\n",
            "\t the loss for timestep 28 is: 0.9632015566261936\n",
            "\t the loss for timestep 29 is: 0.5565488018486633\n",
            "\t the loss for timestep 30 is: 0.9394636523918379\n",
            "\t the loss for timestep 31 is: 0.584659229255579\n",
            "\t the loss for timestep 32 is: 0.9170325063276679\n",
            "\t the loss for timestep 33 is: 0.6130983583777322\n",
            "\t the loss for timestep 34 is: 169.53308473781019\n",
            "\t the loss for timestep 35 is: 180.0769314919997\n",
            "\t the loss for timestep 36 is: 0.7331604345624687\n",
            "\t the loss for timestep 37 is: 0.8302279730793849\n",
            "\t the loss for timestep 38 is: 0.7246897311115333\n",
            "\t the loss for timestep 39 is: 0.9052756426623747\n",
            "\t the loss for timestep 40 is: 0.7869018872698186\n",
            "\t the loss for timestep 41 is: 0.8451396152133572\n",
            "\t the loss for timestep 42 is: 0.8143801941049542\n",
            "\t the loss for timestep 43 is: 0.8658316284565089\n",
            "\t the loss for timestep 44 is: 0.8256529433486677\n",
            "\t the loss for timestep 45 is: 0.8706341594324682\n",
            "\t the loss for timestep 46 is: 0.855133775470132\n",
            "\t the loss for timestep 47 is: 0.8532554435318798\n",
            "\t the loss for timestep 48 is: 0.9721174591435233\n",
            "\t the loss for timestep 49 is: 0.9662954300565569\n",
            "\t the loss for timestep 50 is: 0.9038172692777182\n",
            "\t the loss for timestep 51 is: 0.9430179249525888\n",
            "\t the loss for timestep 52 is: 0.9216686007414931\n",
            "\t the loss for timestep 53 is: 0.9511022488356693\n",
            "\t the loss for timestep 54 is: 0.9466885285646288\n",
            "\t the loss for timestep 55 is: 0.96332108336156\n",
            "\t the loss for timestep 56 is: 0.9648380883767536\n",
            "\t the loss for timestep 57 is: 0.974365255070938\n",
            "\t the loss for timestep 58 is: 0.9770106654177264\n",
            "\t the loss for timestep 59 is: 0.9819746273809136\n",
            "\t the loss for timestep 60 is: 0.9834028210723369\n",
            "\t the loss for timestep 61 is: 0.9847998125707033\n",
            "\t the loss for timestep 62 is: 1.400747513318301\n",
            "\t the loss for timestep 63 is: 1.5853453391944108\n",
            "\t the loss for timestep 64 is: 2.373060445163044\n",
            "\t the loss for timestep 65 is: 1.9453553957212144\n",
            "\t the loss for timestep 66 is: 1.0280304600322074\n",
            "\t the loss for timestep 67 is: 1.0224891225655548\n",
            "\t the loss for timestep 68 is: 0.9416395306140153\n",
            "\t the loss for timestep 69 is: 0.9546139129997508\n",
            "\t the loss for timestep 70 is: 0.9299589259615317\n",
            "\t the loss for timestep 71 is: 0.923201505993527\n",
            "\t the loss for timestep 72 is: 0.9001402187106227\n",
            "\t the loss for timestep 73 is: 0.8956976373997186\n",
            "\t the loss for timestep 74 is: 0.8750024769348947\n",
            "\t the loss for timestep 75 is: 0.8647874539474822\n",
            "\t the loss for timestep 76 is: 0.8465372909053872\n",
            "\t the loss for timestep 77 is: 0.8337168371531151\n",
            "\t the loss for timestep 78 is: 0.8166158517106462\n",
            "\t the loss for timestep 79 is: 2.125020737333755\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.3838221824023331\n",
            "\t the loss for timestep 2 is: 1.3638109298544396\n",
            "\t the loss for timestep 3 is: 0.516925152610648\n",
            "\t the loss for timestep 4 is: 1.1042380791860766\n",
            "\t the loss for timestep 5 is: 1.5423256556826033\n",
            "\t the loss for timestep 6 is: 1.271837015651511\n",
            "\t the loss for timestep 7 is: 0.5823644091160741\n",
            "\t the loss for timestep 8 is: 1.012958220141616\n",
            "\t the loss for timestep 9 is: 0.6260350639688317\n",
            "\t the loss for timestep 10 is: 0.9208685617167818\n",
            "\t the loss for timestep 11 is: 0.6595068541358374\n",
            "\t the loss for timestep 12 is: 0.865166273357687\n",
            "\t the loss for timestep 13 is: 0.6774027338557801\n",
            "\t the loss for timestep 14 is: 0.8258986820335888\n",
            "\t the loss for timestep 15 is: 0.6845942738161515\n",
            "\t the loss for timestep 16 is: 0.795912076064401\n",
            "\t the loss for timestep 17 is: 0.6844265697598072\n",
            "\t the loss for timestep 18 is: 0.7714220433780861\n",
            "\t the loss for timestep 19 is: 0.6791729693907168\n",
            "\t the loss for timestep 20 is: 0.7504009774891152\n",
            "\t the loss for timestep 21 is: 0.6703649622692438\n",
            "\t the loss for timestep 22 is: 0.7317765481850487\n",
            "\t the loss for timestep 23 is: 0.6590205273702388\n",
            "\t the loss for timestep 24 is: 0.7150300929092746\n",
            "\t the loss for timestep 25 is: 0.6457889029133339\n",
            "\t the loss for timestep 26 is: 0.6999912919690324\n",
            "\t the loss for timestep 27 is: 0.6310340465981276\n",
            "\t the loss for timestep 28 is: 0.6867428924866201\n",
            "\t the loss for timestep 29 is: 0.6148702987112168\n",
            "\t the loss for timestep 30 is: 0.6756058421962756\n",
            "\t the loss for timestep 31 is: 0.5971578311906128\n",
            "\t the loss for timestep 32 is: 0.6671925636932383\n",
            "\t the loss for timestep 33 is: 0.5774542428940986\n",
            "\t the loss for timestep 34 is: 171.93836734321488\n",
            "\t the loss for timestep 35 is: 181.814776987269\n",
            "\t the loss for timestep 36 is: 0.5303568816267213\n",
            "\t the loss for timestep 37 is: 0.7241980572814162\n",
            "\t the loss for timestep 38 is: 0.4840667579395694\n",
            "\t the loss for timestep 39 is: 0.833878604426524\n",
            "\t the loss for timestep 40 is: 0.46306225350076013\n",
            "\t the loss for timestep 41 is: 0.8159987821632374\n",
            "\t the loss for timestep 42 is: 0.4208261137208991\n",
            "\t the loss for timestep 43 is: 0.8945852361839094\n",
            "\t the loss for timestep 44 is: 0.3628405408456109\n",
            "\t the loss for timestep 45 is: 0.9900108908817338\n",
            "\t the loss for timestep 46 is: 0.31440045601412886\n",
            "\t the loss for timestep 47 is: 1.0640096471112588\n",
            "\t the loss for timestep 48 is: 0.33049621732568935\n",
            "\t the loss for timestep 49 is: 1.131717356867225\n",
            "\t the loss for timestep 50 is: 0.26730005051655786\n",
            "\t the loss for timestep 51 is: 1.2928377260775243\n",
            "\t the loss for timestep 52 is: 0.230105309770776\n",
            "\t the loss for timestep 53 is: 1.4561351809360414\n",
            "\t the loss for timestep 54 is: 0.20774308046320092\n",
            "\t the loss for timestep 55 is: 1.575203312331673\n",
            "\t the loss for timestep 56 is: 0.19676813274049693\n",
            "\t the loss for timestep 57 is: 1.64022122825628\n",
            "\t the loss for timestep 58 is: 0.19321047337531544\n",
            "\t the loss for timestep 59 is: 1.6642121393993201\n",
            "\t the loss for timestep 60 is: 0.19399106604186714\n",
            "\t the loss for timestep 61 is: 1.6632389605366136\n",
            "\t the loss for timestep 62 is: 0.22246111422733836\n",
            "\t the loss for timestep 63 is: 1.9221657932935536\n",
            "\t the loss for timestep 64 is: 1.1435714709584717\n",
            "\t the loss for timestep 65 is: 1.885368532795264\n",
            "\t the loss for timestep 66 is: 0.3276945394164\n",
            "\t the loss for timestep 67 is: 1.175625852443914\n",
            "\t the loss for timestep 68 is: 0.2691484621434847\n",
            "\t the loss for timestep 69 is: 1.3070219950865927\n",
            "\t the loss for timestep 70 is: 0.24830830400890497\n",
            "\t the loss for timestep 71 is: 1.4148828017039636\n",
            "\t the loss for timestep 72 is: 0.238262183262023\n",
            "\t the loss for timestep 73 is: 1.457003021459491\n",
            "\t the loss for timestep 74 is: 0.2373895788121818\n",
            "\t the loss for timestep 75 is: 1.4666743844055037\n",
            "\t the loss for timestep 76 is: 0.2397980484711113\n",
            "\t the loss for timestep 77 is: 1.4609179857000172\n",
            "\t the loss for timestep 78 is: 0.24370861036968933\n",
            "\t the loss for timestep 79 is: 2.7260403025192157\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.19964637292547968\n",
            "\t the loss for timestep 2 is: 1.6624235007737134\n",
            "\t the loss for timestep 3 is: 0.22739095924398672\n",
            "\t the loss for timestep 4 is: 1.5278428206260417\n",
            "\t the loss for timestep 5 is: 0.26591453327362957\n",
            "\t the loss for timestep 6 is: 2.5717697122790923\n",
            "\t the loss for timestep 7 is: 0.1911220423954297\n",
            "\t the loss for timestep 8 is: 1.711861006508774\n",
            "\t the loss for timestep 9 is: 0.22211242965899064\n",
            "\t the loss for timestep 10 is: 1.5560160618187688\n",
            "\t the loss for timestep 11 is: 0.2353095188390089\n",
            "\t the loss for timestep 12 is: 1.4970148947785122\n",
            "\t the loss for timestep 13 is: 0.2405608959284546\n",
            "\t the loss for timestep 14 is: 1.4749677950842117\n",
            "\t the loss for timestep 15 is: 0.24193351775337718\n",
            "\t the loss for timestep 16 is: 1.470432808126691\n",
            "\t the loss for timestep 17 is: 0.24117805218132288\n",
            "\t the loss for timestep 18 is: 1.475432852013968\n",
            "\t the loss for timestep 19 is: 0.23919341888556317\n",
            "\t the loss for timestep 20 is: 1.4860606976708066\n",
            "\t the loss for timestep 21 is: 0.2365176021474375\n",
            "\t the loss for timestep 22 is: 1.5000542807035397\n",
            "\t the loss for timestep 23 is: 0.23353005829748902\n",
            "\t the loss for timestep 24 is: 1.5158344664314605\n",
            "\t the loss for timestep 25 is: 0.23054258075957273\n",
            "\t the loss for timestep 26 is: 1.532083484579319\n",
            "\t the loss for timestep 27 is: 0.22784377989033958\n",
            "\t the loss for timestep 28 is: 1.5475442635722765\n",
            "\t the loss for timestep 29 is: 0.2257240588665741\n",
            "\t the loss for timestep 30 is: 1.560931648308471\n",
            "\t the loss for timestep 31 is: 0.224496830038749\n",
            "\t the loss for timestep 32 is: 1.570881868992387\n",
            "\t the loss for timestep 33 is: 0.2245234966267467\n",
            "\t the loss for timestep 34 is: 165.0821953205579\n",
            "\t the loss for timestep 35 is: 184.6831037372894\n",
            "\t the loss for timestep 36 is: 0.748804808399439\n",
            "\t the loss for timestep 37 is: 0.527526418309322\n",
            "\t the loss for timestep 38 is: 0.7549407504483054\n",
            "\t the loss for timestep 39 is: 0.5720772411242853\n",
            "\t the loss for timestep 40 is: 0.8144933608462109\n",
            "\t the loss for timestep 41 is: 0.5159827075873148\n",
            "\t the loss for timestep 42 is: 0.8462723117309142\n",
            "\t the loss for timestep 43 is: 0.5169307465560068\n",
            "\t the loss for timestep 44 is: 0.8568652137253585\n",
            "\t the loss for timestep 45 is: 0.5136645992843174\n",
            "\t the loss for timestep 46 is: 0.8797678781750322\n",
            "\t the loss for timestep 47 is: 0.5151773204294385\n",
            "\t the loss for timestep 48 is: 0.9664895469785302\n",
            "\t the loss for timestep 49 is: 0.5988241495555477\n",
            "\t the loss for timestep 50 is: 0.8449050061185954\n",
            "\t the loss for timestep 51 is: 0.6035289220948808\n",
            "\t the loss for timestep 52 is: 0.8382700621250271\n",
            "\t the loss for timestep 53 is: 0.6317217375709284\n",
            "\t the loss for timestep 54 is: 0.83430810926956\n",
            "\t the loss for timestep 55 is: 0.6653581272457131\n",
            "\t the loss for timestep 56 is: 0.8287678266624706\n",
            "\t the loss for timestep 57 is: 0.7015606025587756\n",
            "\t the loss for timestep 58 is: 0.8246436158820796\n",
            "\t the loss for timestep 59 is: 0.7376890621284591\n",
            "\t the loss for timestep 60 is: 0.8242387016452254\n",
            "\t the loss for timestep 61 is: 0.7714768223761836\n",
            "\t the loss for timestep 62 is: 1.2828756253113762\n",
            "\t the loss for timestep 63 is: 1.194107574966132\n",
            "\t the loss for timestep 64 is: 2.2043538372590348\n",
            "\t the loss for timestep 65 is: 1.969794934902914\n",
            "\t the loss for timestep 66 is: 0.761363867115133\n",
            "\t the loss for timestep 67 is: 0.9428028603568723\n",
            "\t the loss for timestep 68 is: 0.8131985076071508\n",
            "\t the loss for timestep 69 is: 0.9058545484702047\n",
            "\t the loss for timestep 70 is: 0.8706568114451615\n",
            "\t the loss for timestep 71 is: 0.9034743120273381\n",
            "\t the loss for timestep 72 is: 0.8837507370559713\n",
            "\t the loss for timestep 73 is: 0.9081771544950821\n",
            "\t the loss for timestep 74 is: 0.9052170426618893\n",
            "\t the loss for timestep 75 is: 0.9163365008347124\n",
            "\t the loss for timestep 76 is: 0.9188095461746251\n",
            "\t the loss for timestep 77 is: 0.9247728297768898\n",
            "\t the loss for timestep 78 is: 0.9277559353818667\n",
            "\t the loss for timestep 79 is: 2.5108059081130696\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.7450331909772695\n",
            "\t the loss for timestep 2 is: 1.0905846147656777\n",
            "\t the loss for timestep 3 is: 0.8677280365216145\n",
            "\t the loss for timestep 4 is: 0.9567474205117392\n",
            "\t the loss for timestep 5 is: 2.3952747440081814\n",
            "\t the loss for timestep 6 is: 1.7190649961749043\n",
            "\t the loss for timestep 7 is: 0.6023471688389406\n",
            "\t the loss for timestep 8 is: 1.1078045541844936\n",
            "\t the loss for timestep 9 is: 0.7983912491437433\n",
            "\t the loss for timestep 10 is: 0.9377414397779269\n",
            "\t the loss for timestep 11 is: 0.8355097698868436\n",
            "\t the loss for timestep 12 is: 0.8777900098630415\n",
            "\t the loss for timestep 13 is: 0.8338509724020703\n",
            "\t the loss for timestep 14 is: 0.8432494603457694\n",
            "\t the loss for timestep 15 is: 0.8181571924492534\n",
            "\t the loss for timestep 16 is: 0.8155543987305244\n",
            "\t the loss for timestep 17 is: 0.7973993173303416\n",
            "\t the loss for timestep 18 is: 0.7900377489979024\n",
            "\t the loss for timestep 19 is: 0.7748148877846706\n",
            "\t the loss for timestep 20 is: 0.7654979716153859\n",
            "\t the loss for timestep 21 is: 0.7517667147276746\n",
            "\t the loss for timestep 22 is: 0.7417169479508134\n",
            "\t the loss for timestep 23 is: 0.7289351472504495\n",
            "\t the loss for timestep 24 is: 0.7187492288450057\n",
            "\t the loss for timestep 25 is: 0.7067047511727571\n",
            "\t the loss for timestep 26 is: 0.6967020048447111\n",
            "\t the loss for timestep 27 is: 0.68530344286998\n",
            "\t the loss for timestep 28 is: 0.6756663440431515\n",
            "\t the loss for timestep 29 is: 0.6648619633368188\n",
            "\t the loss for timestep 30 is: 0.6557002795405122\n",
            "\t the loss for timestep 31 is: 0.6454445658824668\n",
            "\t the loss for timestep 32 is: 0.6368292090152692\n",
            "\t the loss for timestep 33 is: 0.6270675644824608\n",
            "\t the loss for timestep 34 is: 172.1145410556773\n",
            "\t the loss for timestep 35 is: 183.91152316588122\n",
            "\t the loss for timestep 36 is: 0.6619993054973266\n",
            "\t the loss for timestep 37 is: 0.5743747444553657\n",
            "\t the loss for timestep 38 is: 0.6523091296551742\n",
            "\t the loss for timestep 39 is: 0.5914482722763797\n",
            "\t the loss for timestep 40 is: 0.6705880008701812\n",
            "\t the loss for timestep 41 is: 0.5500566645998114\n",
            "\t the loss for timestep 42 is: 0.680440493730221\n",
            "\t the loss for timestep 43 is: 0.5308941986116785\n",
            "\t the loss for timestep 44 is: 0.6909066040764482\n",
            "\t the loss for timestep 45 is: 0.5058131598288714\n",
            "\t the loss for timestep 46 is: 0.7193291385866877\n",
            "\t the loss for timestep 47 is: 0.49532395086343756\n",
            "\t the loss for timestep 48 is: 0.8383284545142635\n",
            "\t the loss for timestep 49 is: 0.48659514807543863\n",
            "\t the loss for timestep 50 is: 0.7694370135212539\n",
            "\t the loss for timestep 51 is: 0.44702106006123055\n",
            "\t the loss for timestep 52 is: 0.825755050296362\n",
            "\t the loss for timestep 53 is: 0.41544810654300707\n",
            "\t the loss for timestep 54 is: 0.9023086916708125\n",
            "\t the loss for timestep 55 is: 0.38801358593459057\n",
            "\t the loss for timestep 56 is: 0.9878883336382295\n",
            "\t the loss for timestep 57 is: 0.3722575930075368\n",
            "\t the loss for timestep 58 is: 1.0640697895342885\n",
            "\t the loss for timestep 59 is: 0.37776455088758415\n",
            "\t the loss for timestep 60 is: 1.1054062179233577\n",
            "\t the loss for timestep 61 is: 0.414918422391865\n",
            "\t the loss for timestep 62 is: 1.515385830942054\n",
            "\t the loss for timestep 63 is: 1.1584338689870641\n",
            "\t the loss for timestep 64 is: 2.178002298760111\n",
            "\t the loss for timestep 65 is: 1.3022849054133605\n",
            "\t the loss for timestep 66 is: 0.9388826671631652\n",
            "\t the loss for timestep 67 is: 0.8372443372749508\n",
            "\t the loss for timestep 68 is: 0.8830093381174816\n",
            "\t the loss for timestep 69 is: 0.8802861876384915\n",
            "\t the loss for timestep 70 is: 0.9357172406914369\n",
            "\t the loss for timestep 71 is: 0.9524716241621475\n",
            "\t the loss for timestep 72 is: 0.9930018900718846\n",
            "\t the loss for timestep 73 is: 1.0241170390876795\n",
            "\t the loss for timestep 74 is: 1.0581695955090205\n",
            "\t the loss for timestep 75 is: 1.0888560104356757\n",
            "\t the loss for timestep 76 is: 1.1189797878948606\n",
            "\t the loss for timestep 77 is: 1.1465623394287863\n",
            "\t the loss for timestep 78 is: 1.172137387102899\n",
            "\t the loss for timestep 79 is: 1.9093824078071175\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 1.1526790150514332\n",
            "\t the loss for timestep 2 is: 1.3012094100953226\n",
            "\t the loss for timestep 3 is: 1.188247766915341\n",
            "\t the loss for timestep 4 is: 1.2189944201578125\n",
            "\t the loss for timestep 5 is: 1.8407351066882043\n",
            "\t the loss for timestep 6 is: 1.5138372424821551\n",
            "\t the loss for timestep 7 is: 1.0901732015973313\n",
            "\t the loss for timestep 8 is: 1.2102594271512985\n",
            "\t the loss for timestep 9 is: 1.1130067695623844\n",
            "\t the loss for timestep 10 is: 1.1266988211625595\n",
            "\t the loss for timestep 11 is: 1.0843754063812405\n",
            "\t the loss for timestep 12 is: 1.0697761979160618\n",
            "\t the loss for timestep 13 is: 1.0376719600966704\n",
            "\t the loss for timestep 14 is: 1.0132570713391111\n",
            "\t the loss for timestep 15 is: 0.9825299486087387\n",
            "\t the loss for timestep 16 is: 0.9542975901896551\n",
            "\t the loss for timestep 17 is: 0.923677456993096\n",
            "\t the loss for timestep 18 is: 0.8943665021527603\n",
            "\t the loss for timestep 19 is: 0.8644606247161528\n",
            "\t the loss for timestep 20 is: 0.8358152510592454\n",
            "\t the loss for timestep 21 is: 0.8075676188604083\n",
            "\t the loss for timestep 22 is: 0.780777547643102\n",
            "\t the loss for timestep 23 is: 0.7549404954483203\n",
            "\t the loss for timestep 24 is: 0.7307090080556945\n",
            "\t the loss for timestep 25 is: 0.7076839292088971\n",
            "\t the loss for timestep 26 is: 0.6862940032204943\n",
            "\t the loss for timestep 27 is: 0.666153856522295\n",
            "\t the loss for timestep 28 is: 0.6475790723320374\n",
            "\t the loss for timestep 29 is: 0.6301658565712088\n",
            "\t the loss for timestep 30 is: 0.6141952618686428\n",
            "\t the loss for timestep 31 is: 0.599222023371419\n",
            "\t the loss for timestep 32 is: 0.5855595285891428\n",
            "\t the loss for timestep 33 is: 0.5726878691048614\n",
            "\t the loss for timestep 34 is: 173.22541759394085\n",
            "\t the loss for timestep 35 is: 182.80592548797915\n",
            "\t the loss for timestep 36 is: 0.4626978669495376\n",
            "\t the loss for timestep 37 is: 0.6869313034577422\n",
            "\t the loss for timestep 38 is: 0.39869705383335957\n",
            "\t the loss for timestep 39 is: 0.8363880322018241\n",
            "\t the loss for timestep 40 is: 0.33188298681235223\n",
            "\t the loss for timestep 41 is: 0.9502197948699616\n",
            "\t the loss for timestep 42 is: 0.2515992665065075\n",
            "\t the loss for timestep 43 is: 1.2543635771730812\n",
            "\t the loss for timestep 44 is: 0.18462079465034886\n",
            "\t the loss for timestep 45 is: 1.6145244461334094\n",
            "\t the loss for timestep 46 is: 0.15351588052439874\n",
            "\t the loss for timestep 47 is: 1.64817658098474\n",
            "\t the loss for timestep 48 is: 0.15898161291333007\n",
            "\t the loss for timestep 49 is: 1.818354308383928\n",
            "\t the loss for timestep 50 is: 0.1423068632502143\n",
            "\t the loss for timestep 51 is: 1.9710879739303355\n",
            "\t the loss for timestep 52 is: 0.1379100051973014\n",
            "\t the loss for timestep 53 is: 2.0163781919474015\n",
            "\t the loss for timestep 54 is: 0.1362567493474453\n",
            "\t the loss for timestep 55 is: 2.0334777982691223\n",
            "\t the loss for timestep 56 is: 0.13524060670477903\n",
            "\t the loss for timestep 57 is: 2.0439822197543696\n",
            "\t the loss for timestep 58 is: 0.13445009809234063\n",
            "\t the loss for timestep 59 is: 2.052257331744199\n",
            "\t the loss for timestep 60 is: 0.13379468209758527\n",
            "\t the loss for timestep 61 is: 2.059228043634483\n",
            "\t the loss for timestep 62 is: 0.14634612183364543\n",
            "\t the loss for timestep 63 is: 2.18317344684322\n",
            "\t the loss for timestep 64 is: 0.2772172734278024\n",
            "\t the loss for timestep 65 is: 2.783548331653968\n",
            "\t the loss for timestep 66 is: 0.1339887565668189\n",
            "\t the loss for timestep 67 is: 2.0563201056528873\n",
            "\t the loss for timestep 68 is: 0.13217687937269323\n",
            "\t the loss for timestep 69 is: 2.076761065986804\n",
            "\t the loss for timestep 70 is: 0.13180670349473297\n",
            "\t the loss for timestep 71 is: 2.1014353614184507\n",
            "\t the loss for timestep 72 is: 0.13136841782184877\n",
            "\t the loss for timestep 73 is: 2.086329894050969\n",
            "\t the loss for timestep 74 is: 0.13128137078153992\n",
            "\t the loss for timestep 75 is: 2.087139474844844\n",
            "\t the loss for timestep 76 is: 0.13110455035542543\n",
            "\t the loss for timestep 77 is: 2.0891559199214633\n",
            "\t the loss for timestep 78 is: 0.1309423099622047\n",
            "\t the loss for timestep 79 is: 3.0748576325651773\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.1306145036887178\n",
            "\t the loss for timestep 2 is: 2.095323688651279\n",
            "\t the loss for timestep 3 is: 0.130777843810338\n",
            "\t the loss for timestep 4 is: 2.093133999649043\n",
            "\t the loss for timestep 5 is: 0.1467699443942879\n",
            "\t the loss for timestep 6 is: 3.3671956028424885\n",
            "\t the loss for timestep 7 is: 0.12856783422509283\n",
            "\t the loss for timestep 8 is: 2.122984442999992\n",
            "\t the loss for timestep 9 is: 0.13066085534061173\n",
            "\t the loss for timestep 10 is: 2.094765231144608\n",
            "\t the loss for timestep 11 is: 0.13081710737852695\n",
            "\t the loss for timestep 12 is: 2.092709894229824\n",
            "\t the loss for timestep 13 is: 0.13084357315268533\n",
            "\t the loss for timestep 14 is: 2.0923907427679316\n",
            "\t the loss for timestep 15 is: 0.13086280710299822\n",
            "\t the loss for timestep 16 is: 2.0921761985365213\n",
            "\t the loss for timestep 17 is: 0.13088341187945074\n",
            "\t the loss for timestep 18 is: 2.09194792084698\n",
            "\t the loss for timestep 19 is: 0.1309060647831725\n",
            "\t the loss for timestep 20 is: 2.0916971046466837\n",
            "\t the loss for timestep 21 is: 0.13093087456863817\n",
            "\t the loss for timestep 22 is: 2.0914228395249648\n",
            "\t the loss for timestep 23 is: 0.1309579154047528\n",
            "\t the loss for timestep 24 is: 2.0911235854162173\n",
            "\t the loss for timestep 25 is: 0.1309872699706586\n",
            "\t the loss for timestep 26 is: 2.0907997016150093\n",
            "\t the loss for timestep 27 is: 0.1310190216333686\n",
            "\t the loss for timestep 28 is: 2.0904492537124986\n",
            "\t the loss for timestep 29 is: 0.13105327261316976\n",
            "\t the loss for timestep 30 is: 2.090072176783014\n",
            "\t the loss for timestep 31 is: 0.13109012396916592\n",
            "\t the loss for timestep 32 is: 2.089667250392123\n",
            "\t the loss for timestep 33 is: 0.13112969300883243\n",
            "\t the loss for timestep 34 is: 162.2432171873263\n",
            "\t the loss for timestep 35 is: 194.7730783384217\n",
            "\t the loss for timestep 36 is: 2.0557141554675513\n",
            "\t the loss for timestep 37 is: 0.13142490605926377\n",
            "\t the loss for timestep 38 is: 2.0855747168948704\n",
            "\t the loss for timestep 39 is: 0.13123397315796717\n",
            "\t the loss for timestep 40 is: 2.1880625027973037\n",
            "\t the loss for timestep 41 is: 0.1309834910367254\n",
            "\t the loss for timestep 42 is: 2.1250781144197237\n",
            "\t the loss for timestep 43 is: 0.131191944354388\n",
            "\t the loss for timestep 44 is: 2.089049677665232\n",
            "\t the loss for timestep 45 is: 0.13144921081528507\n",
            "\t the loss for timestep 46 is: 2.085772019359398\n",
            "\t the loss for timestep 47 is: 0.13189570249836388\n",
            "\t the loss for timestep 48 is: 1.8072634105263201\n",
            "\t the loss for timestep 49 is: 0.13613193038322935\n",
            "\t the loss for timestep 50 is: 2.027613295464586\n",
            "\t the loss for timestep 51 is: 0.1321034951494286\n",
            "\t the loss for timestep 52 is: 2.077916343163122\n",
            "\t the loss for timestep 53 is: 0.13182382450452257\n",
            "\t the loss for timestep 54 is: 2.0816392302098494\n",
            "\t the loss for timestep 55 is: 0.13188748438509929\n",
            "\t the loss for timestep 56 is: 2.081026498452038\n",
            "\t the loss for timestep 57 is: 0.13198696028408596\n",
            "\t the loss for timestep 58 is: 2.0799795299677717\n",
            "\t the loss for timestep 59 is: 0.1320958104553668\n",
            "\t the loss for timestep 60 is: 2.0788356278911415\n",
            "\t the loss for timestep 61 is: 0.13221216785592244\n",
            "\t the loss for timestep 62 is: 1.9360225369180608\n",
            "\t the loss for timestep 63 is: 0.16319292876098018\n",
            "\t the loss for timestep 64 is: 3.075571536861805\n",
            "\t the loss for timestep 65 is: 0.16798287966291653\n",
            "\t the loss for timestep 66 is: 1.8861187512374111\n",
            "\t the loss for timestep 67 is: 0.1348146774100528\n",
            "\t the loss for timestep 68 is: 2.047132352735426\n",
            "\t the loss for timestep 69 is: 0.1330404530457175\n",
            "\t the loss for timestep 70 is: 2.0891305088660497\n",
            "\t the loss for timestep 71 is: 0.13289205329282858\n",
            "\t the loss for timestep 72 is: 2.0708355298748624\n",
            "\t the loss for timestep 73 is: 0.1332260180780444\n",
            "\t the loss for timestep 74 is: 2.067370798638901\n",
            "\t the loss for timestep 75 is: 0.13347813215316667\n",
            "\t the loss for timestep 76 is: 2.064859405578018\n",
            "\t the loss for timestep 77 is: 0.13373946898592243\n",
            "\t the loss for timestep 78 is: 2.0623042561279434\n",
            "\t the loss for timestep 79 is: 0.25896389712002377\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.13349127374756836\n",
            "\t the loss for timestep 2 is: 2.0656684564657937\n",
            "\t the loss for timestep 3 is: 0.13411184843346993\n",
            "\t the loss for timestep 4 is: 2.0585240233846642\n",
            "\t the loss for timestep 5 is: 0.17251357645220428\n",
            "\t the loss for timestep 6 is: 3.183007741985558\n",
            "\t the loss for timestep 7 is: 0.1294776370549643\n",
            "\t the loss for timestep 8 is: 2.1125549771383\n",
            "\t the loss for timestep 9 is: 0.1337266207762766\n",
            "\t the loss for timestep 10 is: 2.063209194176543\n",
            "\t the loss for timestep 11 is: 0.13429081108998936\n",
            "\t the loss for timestep 12 is: 2.0568863650302105\n",
            "\t the loss for timestep 13 is: 0.13442808763326627\n",
            "\t the loss for timestep 14 is: 2.0554810056277137\n",
            "\t the loss for timestep 15 is: 0.1345212347936452\n",
            "\t the loss for timestep 16 is: 2.054606673560302\n",
            "\t the loss for timestep 17 is: 0.13461836396085483\n",
            "\t the loss for timestep 18 is: 2.0537118454804997\n",
            "\t the loss for timestep 19 is: 0.13472612219683805\n",
            "\t the loss for timestep 20 is: 2.0527231452213845\n",
            "\t the loss for timestep 21 is: 0.13484596471874932\n",
            "\t the loss for timestep 22 is: 2.0516270358389397\n",
            "\t the loss for timestep 23 is: 0.13497876861905628\n",
            "\t the loss for timestep 24 is: 2.0504158748587735\n",
            "\t the loss for timestep 25 is: 0.13512544010390287\n",
            "\t the loss for timestep 26 is: 2.0490841184741857\n",
            "\t the loss for timestep 27 is: 0.13528698159569988\n",
            "\t the loss for timestep 28 is: 2.0476234030036746\n",
            "\t the loss for timestep 29 is: 0.13546455125862317\n",
            "\t the loss for timestep 30 is: 2.0460262947207326\n",
            "\t the loss for timestep 31 is: 0.13565944227019489\n",
            "\t the loss for timestep 32 is: 2.0442833778321883\n",
            "\t the loss for timestep 33 is: 0.13587313678666535\n",
            "\t the loss for timestep 34 is: 162.45265113916764\n",
            "\t the loss for timestep 35 is: 194.22706497516296\n",
            "\t the loss for timestep 36 is: 1.9243602073753237\n",
            "\t the loss for timestep 37 is: 0.13831846090732935\n",
            "\t the loss for timestep 38 is: 2.0175106710656316\n",
            "\t the loss for timestep 39 is: 0.13709172344429021\n",
            "\t the loss for timestep 40 is: 2.131093329898972\n",
            "\t the loss for timestep 41 is: 0.13649415224106484\n",
            "\t the loss for timestep 42 is: 2.071702793923983\n",
            "\t the loss for timestep 43 is: 0.13726235985026172\n",
            "\t the loss for timestep 44 is: 2.0313943053915193\n",
            "\t the loss for timestep 45 is: 0.1382845755858258\n",
            "\t the loss for timestep 46 is: 2.021650280925427\n",
            "\t the loss for timestep 47 is: 0.1397872711477351\n",
            "\t the loss for timestep 48 is: 1.7541902879833118\n",
            "\t the loss for timestep 49 is: 0.15116270511779273\n",
            "\t the loss for timestep 50 is: 1.901623105813325\n",
            "\t the loss for timestep 51 is: 0.14289734318785557\n",
            "\t the loss for timestep 52 is: 1.9800850226268927\n",
            "\t the loss for timestep 53 is: 0.14188200676761742\n",
            "\t the loss for timestep 54 is: 1.991438296164315\n",
            "\t the loss for timestep 55 is: 0.14249610701666732\n",
            "\t the loss for timestep 56 is: 1.987355471595577\n",
            "\t the loss for timestep 57 is: 0.14355401057192807\n",
            "\t the loss for timestep 58 is: 1.9794339852890537\n",
            "\t the loss for timestep 59 is: 0.14483341998431987\n",
            "\t the loss for timestep 60 is: 1.969932240480252\n",
            "\t the loss for timestep 61 is: 0.14631163896874097\n",
            "\t the loss for timestep 62 is: 1.887390618997926\n",
            "\t the loss for timestep 63 is: 0.2596241045885827\n",
            "\t the loss for timestep 64 is: 2.8074788894491123\n",
            "\t the loss for timestep 65 is: 0.4443611571850493\n",
            "\t the loss for timestep 66 is: 1.1241701768068129\n",
            "\t the loss for timestep 67 is: 0.23142168269521263\n",
            "\t the loss for timestep 68 is: 1.403368189389238\n",
            "\t the loss for timestep 69 is: 0.1886908043446657\n",
            "\t the loss for timestep 70 is: 1.6788844828230751\n",
            "\t the loss for timestep 71 is: 0.17035448040555828\n",
            "\t the loss for timestep 72 is: 1.793000569107012\n",
            "\t the loss for timestep 73 is: 0.16755435876412292\n",
            "\t the loss for timestep 74 is: 1.8219047379788886\n",
            "\t the loss for timestep 75 is: 0.17085236097517068\n",
            "\t the loss for timestep 76 is: 1.808959239539836\n",
            "\t the loss for timestep 77 is: 0.17763132423568576\n",
            "\t the loss for timestep 78 is: 1.776529997820571\n",
            "\t the loss for timestep 79 is: 1.0147858070448126\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.16891492268926928\n",
            "\t the loss for timestep 2 is: 1.8410962681806708\n",
            "\t the loss for timestep 3 is: 0.18610750287443234\n",
            "\t the loss for timestep 4 is: 1.738255781906478\n",
            "\t the loss for timestep 5 is: 0.6145308651091124\n",
            "\t the loss for timestep 6 is: 1.9803116482316763\n",
            "\t the loss for timestep 7 is: 0.18640488838054986\n",
            "\t the loss for timestep 8 is: 1.7337143807159336\n",
            "\t the loss for timestep 9 is: 0.19663486004025305\n",
            "\t the loss for timestep 10 is: 1.6845065164130162\n",
            "\t the loss for timestep 11 is: 0.20303642577355335\n",
            "\t the loss for timestep 12 is: 1.6546626323369966\n",
            "\t the loss for timestep 13 is: 0.20867366377774088\n",
            "\t the loss for timestep 14 is: 1.6313517861642723\n",
            "\t the loss for timestep 15 is: 0.2146432108373959\n",
            "\t the loss for timestep 16 is: 1.6089131855782521\n",
            "\t the loss for timestep 17 is: 0.22166033379600222\n",
            "\t the loss for timestep 18 is: 1.5843731059686115\n",
            "\t the loss for timestep 19 is: 0.2303106160647296\n",
            "\t the loss for timestep 20 is: 1.5559662755360895\n",
            "\t the loss for timestep 21 is: 0.24119260093701306\n",
            "\t the loss for timestep 22 is: 1.5225000132258963\n",
            "\t the loss for timestep 23 is: 0.25501262325581286\n",
            "\t the loss for timestep 24 is: 1.4830887871914378\n",
            "\t the loss for timestep 25 is: 0.2726599400277499\n",
            "\t the loss for timestep 26 is: 1.437093337720781\n",
            "\t the loss for timestep 27 is: 0.2952666716455457\n",
            "\t the loss for timestep 28 is: 1.3842006964207718\n",
            "\t the loss for timestep 29 is: 0.32423386692664585\n",
            "\t the loss for timestep 30 is: 1.3246403746425028\n",
            "\t the loss for timestep 31 is: 0.3611692154128694\n",
            "\t the loss for timestep 32 is: 1.259507211520345\n",
            "\t the loss for timestep 33 is: 0.40763801834537394\n",
            "\t the loss for timestep 34 is: 167.12646672735724\n",
            "\t the loss for timestep 35 is: 181.7061076808268\n",
            "\t the loss for timestep 36 is: 0.8420155954649937\n",
            "\t the loss for timestep 37 is: 0.7457005625147823\n",
            "\t the loss for timestep 38 is: 0.8270677631306483\n",
            "\t the loss for timestep 39 is: 0.8520423496388132\n",
            "\t the loss for timestep 40 is: 0.8916624134922243\n",
            "\t the loss for timestep 41 is: 0.8460750016867558\n",
            "\t the loss for timestep 42 is: 0.9197523298967359\n",
            "\t the loss for timestep 43 is: 0.912032057689597\n",
            "\t the loss for timestep 44 is: 0.9428062783930178\n",
            "\t the loss for timestep 45 is: 0.9595458120209386\n",
            "\t the loss for timestep 46 is: 0.992616853608604\n",
            "\t the loss for timestep 47 is: 0.9537575270096751\n",
            "\t the loss for timestep 48 is: 1.1033950946376627\n",
            "\t the loss for timestep 49 is: 1.1600672697859276\n",
            "\t the loss for timestep 50 is: 1.1076079418970217\n",
            "\t the loss for timestep 51 is: 1.159040167944328\n",
            "\t the loss for timestep 52 is: 1.1641406494201838\n",
            "\t the loss for timestep 53 is: 1.200939697773781\n",
            "\t the loss for timestep 54 is: 1.2242715612289663\n",
            "\t the loss for timestep 55 is: 1.2498462600515272\n",
            "\t the loss for timestep 56 is: 1.271040970866637\n",
            "\t the loss for timestep 57 is: 1.2893320572321991\n",
            "\t the loss for timestep 58 is: 1.3036043601508323\n",
            "\t the loss for timestep 59 is: 1.3135999555215752\n",
            "\t the loss for timestep 60 is: 1.3189710038294\n",
            "\t the loss for timestep 61 is: 1.3195332114309257\n",
            "\t the loss for timestep 62 is: 1.59731353915324\n",
            "\t the loss for timestep 63 is: 1.8573804219650012\n",
            "\t the loss for timestep 64 is: 2.6873942643895834\n",
            "\t the loss for timestep 65 is: 2.3962080589386945\n",
            "\t the loss for timestep 66 is: 1.4026377314988998\n",
            "\t the loss for timestep 67 is: 1.2750252117294438\n",
            "\t the loss for timestep 68 is: 1.2383239613241426\n",
            "\t the loss for timestep 69 is: 1.1915344374191998\n",
            "\t the loss for timestep 70 is: 1.1741362791798915\n",
            "\t the loss for timestep 71 is: 1.13416423575331\n",
            "\t the loss for timestep 72 is: 1.0962067004376843\n",
            "\t the loss for timestep 73 is: 1.070034125005289\n",
            "\t the loss for timestep 74 is: 1.0351218735552676\n",
            "\t the loss for timestep 75 is: 1.0049695385682935\n",
            "\t the loss for timestep 76 is: 0.9734386817699416\n",
            "\t the loss for timestep 77 is: 0.9439955149758553\n",
            "\t the loss for timestep 78 is: 0.9149903310692867\n",
            "\t the loss for timestep 79 is: 2.318342105411566\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.4693843113395208\n",
            "\t the loss for timestep 2 is: 1.2945161149711146\n",
            "\t the loss for timestep 3 is: 0.6568486150203278\n",
            "\t the loss for timestep 4 is: 1.0461239010244954\n",
            "\t the loss for timestep 5 is: 1.9791209206103482\n",
            "\t the loss for timestep 6 is: 1.4221996748784782\n",
            "\t the loss for timestep 7 is: 0.6259788228423745\n",
            "\t the loss for timestep 8 is: 1.072767549273348\n",
            "\t the loss for timestep 9 is: 0.7144157140690096\n",
            "\t the loss for timestep 10 is: 0.9464900864903789\n",
            "\t the loss for timestep 11 is: 0.7593071895504753\n",
            "\t the loss for timestep 12 is: 0.8831425401649714\n",
            "\t the loss for timestep 13 is: 0.7754126439145855\n",
            "\t the loss for timestep 14 is: 0.843293330527608\n",
            "\t the loss for timestep 15 is: 0.7758368712730979\n",
            "\t the loss for timestep 16 is: 0.8138728165984777\n",
            "\t the loss for timestep 17 is: 0.7677696422715099\n",
            "\t the loss for timestep 18 is: 0.7893046190705391\n",
            "\t the loss for timestep 19 is: 0.755023050224626\n",
            "\t the loss for timestep 20 is: 0.7671472498483192\n",
            "\t the loss for timestep 21 is: 0.7396797936425126\n",
            "\t the loss for timestep 22 is: 0.7463357704425528\n",
            "\t the loss for timestep 23 is: 0.7229311648625552\n",
            "\t the loss for timestep 24 is: 0.7264313493354709\n",
            "\t the loss for timestep 25 is: 0.7054911344780909\n",
            "\t the loss for timestep 26 is: 0.7072834560305428\n",
            "\t the loss for timestep 27 is: 0.6878012683297552\n",
            "\t the loss for timestep 28 is: 0.6888733259035569\n",
            "\t the loss for timestep 29 is: 0.6701337412680722\n",
            "\t the loss for timestep 30 is: 0.6712454748890735\n",
            "\t the loss for timestep 31 is: 0.6526436198557152\n",
            "\t the loss for timestep 32 is: 0.6544787637093504\n",
            "\t the loss for timestep 33 is: 0.6353916211282182\n",
            "\t the loss for timestep 34 is: 172.1584546084427\n",
            "\t the loss for timestep 35 is: 181.29307939493808\n",
            "\t the loss for timestep 36 is: 0.5469680077428856\n",
            "\t the loss for timestep 37 is: 0.7545022743611848\n",
            "\t the loss for timestep 38 is: 0.5069355984521842\n",
            "\t the loss for timestep 39 is: 0.8535311000768024\n",
            "\t the loss for timestep 40 is: 0.49378464691563\n",
            "\t the loss for timestep 41 is: 0.8214094016223445\n",
            "\t the loss for timestep 42 is: 0.4635007317836702\n",
            "\t the loss for timestep 43 is: 0.8732018388106338\n",
            "\t the loss for timestep 44 is: 0.4183351186288878\n",
            "\t the loss for timestep 45 is: 0.9263009849324103\n",
            "\t the loss for timestep 46 is: 0.3825749394320647\n",
            "\t the loss for timestep 47 is: 0.9610836549973722\n",
            "\t the loss for timestep 48 is: 0.43358178294100025\n",
            "\t the loss for timestep 49 is: 0.9745061758018355\n",
            "\t the loss for timestep 50 is: 0.3617581177480219\n",
            "\t the loss for timestep 51 is: 1.055610558048266\n",
            "\t the loss for timestep 52 is: 0.3232886892922099\n",
            "\t the loss for timestep 53 is: 1.1614800283201911\n",
            "\t the loss for timestep 54 is: 0.2927649119758343\n",
            "\t the loss for timestep 55 is: 1.2690247765151976\n",
            "\t the loss for timestep 56 is: 0.2708985733594885\n",
            "\t the loss for timestep 57 is: 1.3603515345469064\n",
            "\t the loss for timestep 58 is: 0.2589269604284111\n",
            "\t the loss for timestep 59 is: 1.4217866288829595\n",
            "\t the loss for timestep 60 is: 0.25628896657337275\n",
            "\t the loss for timestep 61 is: 1.4497043063917687\n",
            "\t the loss for timestep 62 is: 0.4233920413101983\n",
            "\t the loss for timestep 63 is: 1.6456705994925698\n",
            "\t the loss for timestep 64 is: 1.5988348288491174\n",
            "\t the loss for timestep 65 is: 1.7796984752321698\n",
            "\t the loss for timestep 66 is: 0.48387058266404337\n",
            "\t the loss for timestep 67 is: 0.9907722063412313\n",
            "\t the loss for timestep 68 is: 0.4185160385443144\n",
            "\t the loss for timestep 69 is: 1.0226706781548822\n",
            "\t the loss for timestep 70 is: 0.409970548835321\n",
            "\t the loss for timestep 71 is: 1.0612719200111211\n",
            "\t the loss for timestep 72 is: 0.405342541686147\n",
            "\t the loss for timestep 73 is: 1.0869333727226838\n",
            "\t the loss for timestep 74 is: 0.4087600255390121\n",
            "\t the loss for timestep 75 is: 1.0980009959413113\n",
            "\t the loss for timestep 76 is: 0.4160989858015832\n",
            "\t the loss for timestep 77 is: 1.099406727553079\n",
            "\t the loss for timestep 78 is: 0.4265152035763283\n",
            "\t the loss for timestep 79 is: 2.459146136144038\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.269023513032736\n",
            "\t the loss for timestep 2 is: 1.5680601091341042\n",
            "\t the loss for timestep 3 is: 0.32934706306729367\n",
            "\t the loss for timestep 4 is: 1.37266011000798\n",
            "\t the loss for timestep 5 is: 0.7016347887547612\n",
            "\t the loss for timestep 6 is: 1.6516537873178692\n",
            "\t the loss for timestep 7 is: 0.3434712788735995\n",
            "\t the loss for timestep 8 is: 1.3435495641102673\n",
            "\t the loss for timestep 9 is: 0.36227486016611266\n",
            "\t the loss for timestep 10 is: 1.262343025849906\n",
            "\t the loss for timestep 11 is: 0.37781698312886536\n",
            "\t the loss for timestep 12 is: 1.2142417525006004\n",
            "\t the loss for timestep 13 is: 0.38600037744647203\n",
            "\t the loss for timestep 14 is: 1.1852961256462353\n",
            "\t the loss for timestep 15 is: 0.3892044214158873\n",
            "\t the loss for timestep 16 is: 1.1692411127964646\n",
            "\t the loss for timestep 17 is: 0.38871534343650277\n",
            "\t the loss for timestep 18 is: 1.1626564243304827\n",
            "\t the loss for timestep 19 is: 0.3855620373572236\n",
            "\t the loss for timestep 20 is: 1.1633221279318007\n",
            "\t the loss for timestep 21 is: 0.3807194994553052\n",
            "\t the loss for timestep 22 is: 1.1694089898032594\n",
            "\t the loss for timestep 23 is: 0.37523562541913275\n",
            "\t the loss for timestep 24 is: 1.1790068827742406\n",
            "\t the loss for timestep 25 is: 0.3703109459937205\n",
            "\t the loss for timestep 26 is: 1.1898319731956826\n",
            "\t the loss for timestep 27 is: 0.36735208816148524\n",
            "\t the loss for timestep 28 is: 1.1990855896470092\n",
            "\t the loss for timestep 29 is: 0.3680112462752635\n",
            "\t the loss for timestep 30 is: 1.2035149200480937\n",
            "\t the loss for timestep 31 is: 0.37422821659701266\n",
            "\t the loss for timestep 32 is: 1.1997153395043563\n",
            "\t the loss for timestep 33 is: 0.3882770867831219\n",
            "\t the loss for timestep 34 is: 167.4082045019881\n",
            "\t the loss for timestep 35 is: 182.41671989777532\n",
            "\t the loss for timestep 36 is: 0.8025978245473405\n",
            "\t the loss for timestep 37 is: 0.6703359269222666\n",
            "\t the loss for timestep 38 is: 0.775882103064814\n",
            "\t the loss for timestep 39 is: 0.7449286211424035\n",
            "\t the loss for timestep 40 is: 0.8104977575562075\n",
            "\t the loss for timestep 41 is: 0.7192424819216467\n",
            "\t the loss for timestep 42 is: 0.8150650762333103\n",
            "\t the loss for timestep 43 is: 0.7486729214741522\n",
            "\t the loss for timestep 44 is: 0.8103458112293931\n",
            "\t the loss for timestep 45 is: 0.770256766966982\n",
            "\t the loss for timestep 46 is: 0.8197096957502484\n",
            "\t the loss for timestep 47 is: 0.7741666288736295\n",
            "\t the loss for timestep 48 is: 0.9074331263988352\n",
            "\t the loss for timestep 49 is: 0.8509668991075248\n",
            "\t the loss for timestep 50 is: 0.8297692216048771\n",
            "\t the loss for timestep 51 is: 0.8611071707175139\n",
            "\t the loss for timestep 52 is: 0.8467571898970199\n",
            "\t the loss for timestep 53 is: 0.8710083371881442\n",
            "\t the loss for timestep 54 is: 0.8675030147598504\n",
            "\t the loss for timestep 55 is: 0.883131254383394\n",
            "\t the loss for timestep 56 is: 0.8846221020060611\n",
            "\t the loss for timestep 57 is: 0.8949516149814029\n",
            "\t the loss for timestep 58 is: 0.8984343138948392\n",
            "\t the loss for timestep 59 is: 0.9054146848721534\n",
            "\t the loss for timestep 60 is: 0.9090592965281559\n",
            "\t the loss for timestep 61 is: 0.9136671646375646\n",
            "\t the loss for timestep 62 is: 1.313018107962804\n",
            "\t the loss for timestep 63 is: 1.3004953594367414\n",
            "\t the loss for timestep 64 is: 2.3445658291760383\n",
            "\t the loss for timestep 65 is: 2.1107855766603296\n",
            "\t the loss for timestep 66 is: 0.8288404092947795\n",
            "\t the loss for timestep 67 is: 0.9866283674399959\n",
            "\t the loss for timestep 68 is: 0.8865777409021147\n",
            "\t the loss for timestep 69 is: 0.9405321100833046\n",
            "\t the loss for timestep 70 is: 0.9156874642605534\n",
            "\t the loss for timestep 71 is: 0.92213984407998\n",
            "\t the loss for timestep 72 is: 0.8985422268446467\n",
            "\t the loss for timestep 73 is: 0.905779694152179\n",
            "\t the loss for timestep 74 is: 0.8925383267507119\n",
            "\t the loss for timestep 75 is: 0.8898269842111277\n",
            "\t the loss for timestep 76 is: 0.8797990693241307\n",
            "\t the loss for timestep 77 is: 0.8731878319103817\n",
            "\t the loss for timestep 78 is: 0.8635756420355142\n",
            "\t the loss for timestep 79 is: 2.468979240860734\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.5340582837896417\n",
            "\t the loss for timestep 2 is: 1.1857769487665817\n",
            "\t the loss for timestep 3 is: 0.6923354131972796\n",
            "\t the loss for timestep 4 is: 0.9695791660260881\n",
            "\t the loss for timestep 5 is: 2.2019668546489\n",
            "\t the loss for timestep 6 is: 1.5376449320860122\n",
            "\t the loss for timestep 7 is: 0.5382216277768663\n",
            "\t the loss for timestep 8 is: 1.0860251947682706\n",
            "\t the loss for timestep 9 is: 0.6862902655965897\n",
            "\t the loss for timestep 10 is: 0.9296668319203274\n",
            "\t the loss for timestep 11 is: 0.7368342706352539\n",
            "\t the loss for timestep 12 is: 0.8586296227846699\n",
            "\t the loss for timestep 13 is: 0.7548997152061654\n",
            "\t the loss for timestep 14 is: 0.8177759720428315\n",
            "\t the loss for timestep 15 is: 0.7558360873965888\n",
            "\t the loss for timestep 16 is: 0.7890686407589567\n",
            "\t the loss for timestep 17 is: 0.7480532135343825\n",
            "\t the loss for timestep 18 is: 0.7656866937822939\n",
            "\t the loss for timestep 19 is: 0.7357448602086996\n",
            "\t the loss for timestep 20 is: 0.7448418964913271\n",
            "\t the loss for timestep 21 is: 0.7210652442213635\n",
            "\t the loss for timestep 22 is: 0.7253725537048529\n",
            "\t the loss for timestep 23 is: 0.7051807125145967\n",
            "\t the loss for timestep 24 is: 0.7068111768319338\n",
            "\t the loss for timestep 25 is: 0.6887599425336651\n",
            "\t the loss for timestep 26 is: 0.6889947128188212\n",
            "\t the loss for timestep 27 is: 0.6722023572982175\n",
            "\t the loss for timestep 28 is: 0.6718945050653429\n",
            "\t the loss for timestep 29 is: 0.6557475536948686\n",
            "\t the loss for timestep 30 is: 0.6555430743981688\n",
            "\t the loss for timestep 31 is: 0.6395277245281024\n",
            "\t the loss for timestep 32 is: 0.6400053768725285\n",
            "\t the loss for timestep 33 is: 0.6235902873872781\n",
            "\t the loss for timestep 34 is: 171.9986092136027\n",
            "\t the loss for timestep 35 is: 183.41412465660363\n",
            "\t the loss for timestep 36 is: 0.6318102763482449\n",
            "\t the loss for timestep 37 is: 0.6149636065463474\n",
            "\t the loss for timestep 38 is: 0.6167824723041537\n",
            "\t the loss for timestep 39 is: 0.6537439316895239\n",
            "\t the loss for timestep 40 is: 0.6255342419314726\n",
            "\t the loss for timestep 41 is: 0.617888813871782\n",
            "\t the loss for timestep 42 is: 0.6208720543007765\n",
            "\t the loss for timestep 43 is: 0.618900594613194\n",
            "\t the loss for timestep 44 is: 0.6083383074997505\n",
            "\t the loss for timestep 45 is: 0.6156634353367008\n",
            "\t the loss for timestep 46 is: 0.6052772289791626\n",
            "\t the loss for timestep 47 is: 0.6121018463042178\n",
            "\t the loss for timestep 48 is: 0.6928574648814994\n",
            "\t the loss for timestep 49 is: 0.6229503740339802\n",
            "\t the loss for timestep 50 is: 0.6114286534758921\n",
            "\t the loss for timestep 51 is: 0.6153936623011917\n",
            "\t the loss for timestep 52 is: 0.6066192275949005\n",
            "\t the loss for timestep 53 is: 0.6183698180497064\n",
            "\t the loss for timestep 54 is: 0.6049860493088985\n",
            "\t the loss for timestep 55 is: 0.6227468028242484\n",
            "\t the loss for timestep 56 is: 0.6027206981160222\n",
            "\t the loss for timestep 57 is: 0.6284013248413959\n",
            "\t the loss for timestep 58 is: 0.5995563199859512\n",
            "\t the loss for timestep 59 is: 0.6353956072603201\n",
            "\t the loss for timestep 60 is: 0.5951501245975147\n",
            "\t the loss for timestep 61 is: 0.643731679125457\n",
            "\t the loss for timestep 62 is: 1.0645927173300263\n",
            "\t the loss for timestep 63 is: 1.1206936089691326\n",
            "\t the loss for timestep 64 is: 1.943658222783578\n",
            "\t the loss for timestep 65 is: 1.2490603685378705\n",
            "\t the loss for timestep 66 is: 0.653843685996923\n",
            "\t the loss for timestep 67 is: 0.6899015367630502\n",
            "\t the loss for timestep 68 is: 0.5836785088714778\n",
            "\t the loss for timestep 69 is: 0.6853729920517492\n",
            "\t the loss for timestep 70 is: 0.5785687744111893\n",
            "\t the loss for timestep 71 is: 0.6923963459469789\n",
            "\t the loss for timestep 72 is: 0.5697266738388718\n",
            "\t the loss for timestep 73 is: 0.7029913929517313\n",
            "\t the loss for timestep 74 is: 0.5622173386384505\n",
            "\t the loss for timestep 75 is: 0.7105286256599952\n",
            "\t the loss for timestep 76 is: 0.5527388385735065\n",
            "\t the loss for timestep 77 is: 0.7174906272608572\n",
            "\t the loss for timestep 78 is: 0.5407034500986649\n",
            "\t the loss for timestep 79 is: 1.9775689682762412\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.23934731393771513\n",
            "\t the loss for timestep 2 is: 1.5348015244356605\n",
            "\t the loss for timestep 3 is: 0.288517394190997\n",
            "\t the loss for timestep 4 is: 1.3499251839454853\n",
            "\t the loss for timestep 5 is: 0.4858420522341505\n",
            "\t the loss for timestep 6 is: 1.8437232184004935\n",
            "\t the loss for timestep 7 is: 0.27909904863564977\n",
            "\t the loss for timestep 8 is: 1.393735837238258\n",
            "\t the loss for timestep 9 is: 0.3027495156013854\n",
            "\t the loss for timestep 10 is: 1.2967237636535285\n",
            "\t the loss for timestep 11 is: 0.31681064914545887\n",
            "\t the loss for timestep 12 is: 1.2476199613020809\n",
            "\t the loss for timestep 13 is: 0.32313146409407645\n",
            "\t the loss for timestep 14 is: 1.223788997472823\n",
            "\t the loss for timestep 15 is: 0.3245958017081555\n",
            "\t the loss for timestep 16 is: 1.2155196043343823\n",
            "\t the loss for timestep 17 is: 0.3226322787682357\n",
            "\t the loss for timestep 18 is: 1.2180806239997763\n",
            "\t the loss for timestep 19 is: 0.3182030454554491\n",
            "\t the loss for timestep 20 is: 1.2286910795919834\n",
            "\t the loss for timestep 21 is: 0.3120956784000253\n",
            "\t the loss for timestep 22 is: 1.2452850107739286\n",
            "\t the loss for timestep 23 is: 0.30506420007828144\n",
            "\t the loss for timestep 24 is: 1.2659004358012698\n",
            "\t the loss for timestep 25 is: 0.29789822127456117\n",
            "\t the loss for timestep 26 is: 1.2883450848408562\n",
            "\t the loss for timestep 27 is: 0.29145698325792\n",
            "\t the loss for timestep 28 is: 1.3100258121026367\n",
            "\t the loss for timestep 29 is: 0.28668869962737387\n",
            "\t the loss for timestep 30 is: 1.3279239459262544\n",
            "\t the loss for timestep 31 is: 0.28465927171475314\n",
            "\t the loss for timestep 32 is: 1.3386913880161952\n",
            "\t the loss for timestep 33 is: 0.2866113897839281\n",
            "\t the loss for timestep 34 is: 166.32940500193084\n",
            "\t the loss for timestep 35 is: 183.21051396380625\n",
            "\t the loss for timestep 36 is: 0.7007057204050053\n",
            "\t the loss for timestep 37 is: 0.6258125601365094\n",
            "\t the loss for timestep 38 is: 0.6891548902997993\n",
            "\t the loss for timestep 39 is: 0.7042504261892878\n",
            "\t the loss for timestep 40 is: 0.7317315012804861\n",
            "\t the loss for timestep 41 is: 0.6620873374051854\n",
            "\t the loss for timestep 42 is: 0.7383334562239195\n",
            "\t the loss for timestep 43 is: 0.689073750324323\n",
            "\t the loss for timestep 44 is: 0.7334989053692589\n",
            "\t the loss for timestep 45 is: 0.7033442402121803\n",
            "\t the loss for timestep 46 is: 0.7462376295435666\n",
            "\t the loss for timestep 47 is: 0.6826645787920532\n",
            "\t the loss for timestep 48 is: 0.8233170852304343\n",
            "\t the loss for timestep 49 is: 0.7852559506250701\n",
            "\t the loss for timestep 50 is: 0.7630378030859755\n",
            "\t the loss for timestep 51 is: 0.787272528362476\n",
            "\t the loss for timestep 52 is: 0.7802040121445686\n",
            "\t the loss for timestep 53 is: 0.8019552577821457\n",
            "\t the loss for timestep 54 is: 0.802153028499714\n",
            "\t the loss for timestep 55 is: 0.8180938198714032\n",
            "\t the loss for timestep 56 is: 0.8223801458575363\n",
            "\t the loss for timestep 57 is: 0.8345416626630808\n",
            "\t the loss for timestep 58 is: 0.84087279690794\n",
            "\t the loss for timestep 59 is: 0.8506124698960127\n",
            "\t the loss for timestep 60 is: 0.8575443869732335\n",
            "\t the loss for timestep 61 is: 0.8656056751008924\n",
            "\t the loss for timestep 62 is: 1.267211812118799\n",
            "\t the loss for timestep 63 is: 1.2700162067094458\n",
            "\t the loss for timestep 64 is: 2.203250341434884\n",
            "\t the loss for timestep 65 is: 1.8307761305851702\n",
            "\t the loss for timestep 66 is: 0.8472786431707867\n",
            "\t the loss for timestep 67 is: 0.9364698709888147\n",
            "\t the loss for timestep 68 is: 0.887615336811092\n",
            "\t the loss for timestep 69 is: 0.9161813180546385\n",
            "\t the loss for timestep 70 is: 0.9160677496707758\n",
            "\t the loss for timestep 71 is: 0.9170005974695211\n",
            "\t the loss for timestep 72 is: 0.905111931725604\n",
            "\t the loss for timestep 73 is: 0.9125045400521768\n",
            "\t the loss for timestep 74 is: 0.9077174251328225\n",
            "\t the loss for timestep 75 is: 0.9075343684869086\n",
            "\t the loss for timestep 76 is: 0.9037750674646989\n",
            "\t the loss for timestep 77 is: 0.9006311570953762\n",
            "\t the loss for timestep 78 is: 0.8959711981178536\n",
            "\t the loss for timestep 79 is: 2.4620307848794694\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.6966142459843732\n",
            "\t the loss for timestep 2 is: 1.075661936520638\n",
            "\t the loss for timestep 3 is: 0.8076779343336398\n",
            "\t the loss for timestep 4 is: 0.9291661741192364\n",
            "\t the loss for timestep 5 is: 2.241771201076861\n",
            "\t the loss for timestep 6 is: 1.606406063163585\n",
            "\t the loss for timestep 7 is: 0.5905577135645609\n",
            "\t the loss for timestep 8 is: 1.0621246557004533\n",
            "\t the loss for timestep 9 is: 0.7605483944556951\n",
            "\t the loss for timestep 10 is: 0.9092673771140468\n",
            "\t the loss for timestep 11 is: 0.797221963228403\n",
            "\t the loss for timestep 12 is: 0.8516596023351258\n",
            "\t the loss for timestep 13 is: 0.8005715892403256\n",
            "\t the loss for timestep 14 is: 0.8186423839217758\n",
            "\t the loss for timestep 15 is: 0.7898755930273686\n",
            "\t the loss for timestep 16 is: 0.7931547392860017\n",
            "\t the loss for timestep 17 is: 0.7734281452957498\n",
            "\t the loss for timestep 18 is: 0.7702412256495922\n",
            "\t the loss for timestep 19 is: 0.7545560726379545\n",
            "\t the loss for timestep 20 is: 0.7483917482900113\n",
            "\t the loss for timestep 21 is: 0.7347417754974528\n",
            "\t the loss for timestep 22 is: 0.7272034733420948\n",
            "\t the loss for timestep 23 is: 0.7147403197150816\n",
            "\t the loss for timestep 24 is: 0.7066379325633134\n",
            "\t the loss for timestep 25 is: 0.6949838985684322\n",
            "\t the loss for timestep 26 is: 0.6867642681559627\n",
            "\t the loss for timestep 27 is: 0.6757368093842476\n",
            "\t the loss for timestep 28 is: 0.6676675805907706\n",
            "\t the loss for timestep 29 is: 0.6571621014075021\n",
            "\t the loss for timestep 30 is: 0.6494181602998915\n",
            "\t the loss for timestep 31 is: 0.6393539483731332\n",
            "\t the loss for timestep 32 is: 0.6320637806265571\n",
            "\t the loss for timestep 33 is: 0.6223554785567853\n",
            "\t the loss for timestep 34 is: 171.89140029992356\n",
            "\t the loss for timestep 35 is: 183.33573046648172\n",
            "\t the loss for timestep 36 is: 0.6103717077759784\n",
            "\t the loss for timestep 37 is: 0.6236657242991195\n",
            "\t the loss for timestep 38 is: 0.5947631052987872\n",
            "\t the loss for timestep 39 is: 0.6647433620000538\n",
            "\t the loss for timestep 40 is: 0.5987937743232332\n",
            "\t the loss for timestep 41 is: 0.6334980301049618\n",
            "\t the loss for timestep 42 is: 0.5887540127135968\n",
            "\t the loss for timestep 43 is: 0.6401839957552592\n",
            "\t the loss for timestep 44 is: 0.57057382917662\n",
            "\t the loss for timestep 45 is: 0.643802658379234\n",
            "\t the loss for timestep 46 is: 0.5592256189828915\n",
            "\t the loss for timestep 47 is: 0.6467575895969603\n",
            "\t the loss for timestep 48 is: 0.6360532891864198\n",
            "\t the loss for timestep 49 is: 0.6583400224783519\n",
            "\t the loss for timestep 50 is: 0.5541813339893522\n",
            "\t the loss for timestep 51 is: 0.6625218538719548\n",
            "\t the loss for timestep 52 is: 0.5363858748326613\n",
            "\t the loss for timestep 53 is: 0.6812012193507053\n",
            "\t the loss for timestep 54 is: 0.5180526037852314\n",
            "\t the loss for timestep 55 is: 0.7063750330950025\n",
            "\t the loss for timestep 56 is: 0.4951150867517412\n",
            "\t the loss for timestep 57 is: 0.7397840982322885\n",
            "\t the loss for timestep 58 is: 0.4664991807634828\n",
            "\t the loss for timestep 59 is: 0.7844684107425287\n",
            "\t the loss for timestep 60 is: 0.4309404923179342\n",
            "\t the loss for timestep 61 is: 0.8455014911591651\n",
            "\t the loss for timestep 62 is: 0.752179948759091\n",
            "\t the loss for timestep 63 is: 1.235774454811293\n",
            "\t the loss for timestep 64 is: 1.7041006382327417\n",
            "\t the loss for timestep 65 is: 1.3589731492624935\n",
            "\t the loss for timestep 66 is: 0.5054159673696372\n",
            "\t the loss for timestep 67 is: 0.7770331975782592\n",
            "\t the loss for timestep 68 is: 0.4048463810139264\n",
            "\t the loss for timestep 69 is: 0.8503307360070528\n",
            "\t the loss for timestep 70 is: 0.34561330161263754\n",
            "\t the loss for timestep 71 is: 0.9899885097549266\n",
            "\t the loss for timestep 72 is: 0.2782738035726007\n",
            "\t the loss for timestep 73 is: 1.2020098700688138\n",
            "\t the loss for timestep 74 is: 0.2173552564606386\n",
            "\t the loss for timestep 75 is: 1.470381377631874\n",
            "\t the loss for timestep 76 is: 0.1737862858686255\n",
            "\t the loss for timestep 77 is: 1.7246611987060472\n",
            "\t the loss for timestep 78 is: 0.15066195779224553\n",
            "\t the loss for timestep 79 is: 2.985115746672978\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.13687405940018074\n",
            "\t the loss for timestep 2 is: 2.028669608840105\n",
            "\t the loss for timestep 3 is: 0.13816246736893695\n",
            "\t the loss for timestep 4 is: 2.014726533781009\n",
            "\t the loss for timestep 5 is: 0.14004235268947643\n",
            "\t the loss for timestep 6 is: 3.43959064902806\n",
            "\t the loss for timestep 7 is: 0.130520826828667\n",
            "\t the loss for timestep 8 is: 2.1002274186176333\n",
            "\t the loss for timestep 9 is: 0.13727262502310827\n",
            "\t the loss for timestep 10 is: 2.0246248828578848\n",
            "\t the loss for timestep 11 is: 0.138323919781017\n",
            "\t the loss for timestep 12 is: 2.013443288362051\n",
            "\t the loss for timestep 13 is: 0.13853108643747505\n",
            "\t the loss for timestep 14 is: 2.0114126557850023\n",
            "\t the loss for timestep 15 is: 0.13861411297562687\n",
            "\t the loss for timestep 16 is: 2.0107553445602826\n",
            "\t the loss for timestep 17 is: 0.13868544813371003\n",
            "\t the loss for timestep 18 is: 2.0102629289763465\n",
            "\t the loss for timestep 19 is: 0.13876324604277235\n",
            "\t the loss for timestep 20 is: 2.0097428104665287\n",
            "\t the loss for timestep 21 is: 0.1388507650814914\n",
            "\t the loss for timestep 22 is: 2.009162335930094\n",
            "\t the loss for timestep 23 is: 0.13894896903861367\n",
            "\t the loss for timestep 24 is: 2.008512574043655\n",
            "\t the loss for timestep 25 is: 0.13905851830407592\n",
            "\t the loss for timestep 26 is: 2.0077900666582886\n",
            "\t the loss for timestep 27 is: 0.1391801234897149\n",
            "\t the loss for timestep 28 is: 2.006988967445057\n",
            "\t the loss for timestep 29 is: 0.13931456974756765\n",
            "\t the loss for timestep 30 is: 2.006105102773189\n",
            "\t the loss for timestep 31 is: 0.13946277761218479\n",
            "\t the loss for timestep 32 is: 2.0051321598659304\n",
            "\t the loss for timestep 33 is: 0.13962579176987927\n",
            "\t the loss for timestep 34 is: 162.70326777514805\n",
            "\t the loss for timestep 35 is: 190.04847604581374\n",
            "\t the loss for timestep 36 is: 0.9879684607091903\n",
            "\t the loss for timestep 37 is: 0.21198367046191002\n",
            "\t the loss for timestep 38 is: 1.426401398820478\n",
            "\t the loss for timestep 39 is: 0.17405475249333358\n",
            "\t the loss for timestep 40 is: 1.827725655403139\n",
            "\t the loss for timestep 41 is: 0.15087039696816607\n",
            "\t the loss for timestep 42 is: 1.947341669396834\n",
            "\t the loss for timestep 43 is: 0.15229716455342307\n",
            "\t the loss for timestep 44 is: 1.9100614486748\n",
            "\t the loss for timestep 45 is: 0.15537206092306993\n",
            "\t the loss for timestep 46 is: 1.8925183559873944\n",
            "\t the loss for timestep 47 is: 0.1591046078254384\n",
            "\t the loss for timestep 48 is: 1.663323568987267\n",
            "\t the loss for timestep 49 is: 0.2074747697677565\n",
            "\t the loss for timestep 50 is: 1.6091855764918765\n",
            "\t the loss for timestep 51 is: 0.19070522476007845\n",
            "\t the loss for timestep 52 is: 1.695117080656964\n",
            "\t the loss for timestep 53 is: 0.19354596176140645\n",
            "\t the loss for timestep 54 is: 1.6981341835608337\n",
            "\t the loss for timestep 55 is: 0.2040136014358651\n",
            "\t the loss for timestep 56 is: 1.6633542539064645\n",
            "\t the loss for timestep 57 is: 0.21972577499193285\n",
            "\t the loss for timestep 58 is: 1.6108333886814776\n",
            "\t the loss for timestep 59 is: 0.24030677554261048\n",
            "\t the loss for timestep 60 is: 1.5479015975714803\n",
            "\t the loss for timestep 61 is: 0.26624732140499396\n",
            "\t the loss for timestep 62 is: 1.6849002119719874\n",
            "\t the loss for timestep 63 is: 0.9435636669098397\n",
            "\t the loss for timestep 64 is: 2.3094185113737167\n",
            "\t the loss for timestep 65 is: 1.2407226005699727\n",
            "\t the loss for timestep 66 is: 0.8079633769657224\n",
            "\t the loss for timestep 67 is: 0.6915710491391214\n",
            "\t the loss for timestep 68 is: 0.742891080918785\n",
            "\t the loss for timestep 69 is: 0.6929693335007866\n",
            "\t the loss for timestep 70 is: 0.7612541510834719\n",
            "\t the loss for timestep 71 is: 0.713445711064369\n",
            "\t the loss for timestep 72 is: 0.7723986199340847\n",
            "\t the loss for timestep 73 is: 0.7407910704669647\n",
            "\t the loss for timestep 74 is: 0.7879200631874963\n",
            "\t the loss for timestep 75 is: 0.7658454518144409\n",
            "\t the loss for timestep 76 is: 0.8031768900266407\n",
            "\t the loss for timestep 77 is: 0.7904620598084803\n",
            "\t the loss for timestep 78 is: 0.8187519877514399\n",
            "\t the loss for timestep 79 is: 2.1711299409175675\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.408414094875312\n",
            "\t the loss for timestep 2 is: 1.34372004368861\n",
            "\t the loss for timestep 3 is: 0.5658414743525679\n",
            "\t the loss for timestep 4 is: 1.0826729273407323\n",
            "\t the loss for timestep 5 is: 1.6570732137750581\n",
            "\t the loss for timestep 6 is: 1.24531605744287\n",
            "\t the loss for timestep 7 is: 0.6130326229087988\n",
            "\t the loss for timestep 8 is: 1.023176462327998\n",
            "\t the loss for timestep 9 is: 0.6698662199926695\n",
            "\t the loss for timestep 10 is: 0.9235273471443908\n",
            "\t the loss for timestep 11 is: 0.7069346372173189\n",
            "\t the loss for timestep 12 is: 0.8666333527941477\n",
            "\t the loss for timestep 13 is: 0.7241271882571283\n",
            "\t the loss for timestep 14 is: 0.8279207096337595\n",
            "\t the loss for timestep 15 is: 0.7287315365487342\n",
            "\t the loss for timestep 16 is: 0.7986022789059095\n",
            "\t the loss for timestep 17 is: 0.7254220539238225\n",
            "\t the loss for timestep 18 is: 0.774334125258337\n",
            "\t the loss for timestep 19 is: 0.7171118672619692\n",
            "\t the loss for timestep 20 is: 0.7529342328101486\n",
            "\t the loss for timestep 21 is: 0.7056233183844951\n",
            "\t the loss for timestep 22 is: 0.7333124072153592\n",
            "\t the loss for timestep 23 is: 0.6921120010930377\n",
            "\t the loss for timestep 24 is: 0.7149515141141538\n",
            "\t the loss for timestep 25 is: 0.67731597851213\n",
            "\t the loss for timestep 26 is: 0.6976456777358466\n",
            "\t the loss for timestep 27 is: 0.6616973925623602\n",
            "\t the loss for timestep 28 is: 0.6813677683646834\n",
            "\t the loss for timestep 29 is: 0.6455179518160158\n",
            "\t the loss for timestep 30 is: 0.6662130587184041\n",
            "\t the loss for timestep 31 is: 0.6288726947682941\n",
            "\t the loss for timestep 32 is: 0.6523875671047019\n",
            "\t the loss for timestep 33 is: 0.6116893705666466\n",
            "\t the loss for timestep 34 is: 172.13768035825674\n",
            "\t the loss for timestep 35 is: 181.50476714469426\n",
            "\t the loss for timestep 36 is: 0.5362686076748688\n",
            "\t the loss for timestep 37 is: 0.7410614193719633\n",
            "\t the loss for timestep 38 is: 0.4946936903231272\n",
            "\t the loss for timestep 39 is: 0.841132587245529\n",
            "\t the loss for timestep 40 is: 0.47835367775617943\n",
            "\t the loss for timestep 41 is: 0.8198059085036732\n",
            "\t the loss for timestep 42 is: 0.44299182850682894\n",
            "\t the loss for timestep 43 is: 0.8823037258305833\n",
            "\t the loss for timestep 44 is: 0.39379094724687225\n",
            "\t the loss for timestep 45 is: 0.9510447190836379\n",
            "\t the loss for timestep 46 is: 0.3532108629625107\n",
            "\t the loss for timestep 47 is: 1.0050009301910885\n",
            "\t the loss for timestep 48 is: 0.3914973724800992\n",
            "\t the loss for timestep 49 is: 1.029759909861459\n",
            "\t the loss for timestep 50 is: 0.3218563796690921\n",
            "\t the loss for timestep 51 is: 1.1391043706038486\n",
            "\t the loss for timestep 52 is: 0.2821791426661787\n",
            "\t the loss for timestep 53 is: 1.27096950940604\n",
            "\t the loss for timestep 54 is: 0.25322770978379544\n",
            "\t the loss for timestep 55 is: 1.3922433276180468\n",
            "\t the loss for timestep 56 is: 0.23497098207610373\n",
            "\t the loss for timestep 57 is: 1.4814537249651596\n",
            "\t the loss for timestep 58 is: 0.22652410610462725\n",
            "\t the loss for timestep 59 is: 1.5312385054398174\n",
            "\t the loss for timestep 60 is: 0.2256950065360377\n",
            "\t the loss for timestep 61 is: 1.5471040627282462\n",
            "\t the loss for timestep 62 is: 0.3235439079445165\n",
            "\t the loss for timestep 63 is: 1.7484787608570205\n",
            "\t the loss for timestep 64 is: 1.3971088008684234\n",
            "\t the loss for timestep 65 is: 1.8122506409075085\n",
            "\t the loss for timestep 66 is: 0.41302179692660596\n",
            "\t the loss for timestep 67 is: 1.062750885331667\n",
            "\t the loss for timestep 68 is: 0.3516530348390344\n",
            "\t the loss for timestep 69 is: 1.129073982471802\n",
            "\t the loss for timestep 70 is: 0.3354909077458833\n",
            "\t the loss for timestep 71 is: 1.197563024067819\n",
            "\t the loss for timestep 72 is: 0.32578118130344313\n",
            "\t the loss for timestep 73 is: 1.239015682721217\n",
            "\t the loss for timestep 74 is: 0.3254393952984805\n",
            "\t the loss for timestep 75 is: 1.257644590766159\n",
            "\t the loss for timestep 76 is: 0.3298592498385625\n",
            "\t the loss for timestep 77 is: 1.2610312120664988\n",
            "\t the loss for timestep 78 is: 0.33761357223868516\n",
            "\t the loss for timestep 79 is: 2.595444759075204\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.24091859239324348\n",
            "\t the loss for timestep 2 is: 1.6081933846471397\n",
            "\t the loss for timestep 3 is: 0.287222467646826\n",
            "\t the loss for timestep 4 is: 1.4347899698495652\n",
            "\t the loss for timestep 5 is: 0.5513753906528442\n",
            "\t the loss for timestep 6 is: 1.8658453936400594\n",
            "\t the loss for timestep 7 is: 0.283327451458752\n",
            "\t the loss for timestep 8 is: 1.4663884799680413\n",
            "\t the loss for timestep 9 is: 0.3026425130970364\n",
            "\t the loss for timestep 10 is: 1.3756930267454663\n",
            "\t the loss for timestep 11 is: 0.3166178886297943\n",
            "\t the loss for timestep 12 is: 1.327393073489828\n",
            "\t the loss for timestep 13 is: 0.32362182001551726\n",
            "\t the loss for timestep 14 is: 1.3016534457922548\n",
            "\t the loss for timestep 15 is: 0.3263559278001032\n",
            "\t the loss for timestep 16 is: 1.2896867817878868\n",
            "\t the loss for timestep 17 is: 0.32624937495258455\n",
            "\t the loss for timestep 18 is: 1.2868295028915724\n",
            "\t the loss for timestep 19 is: 0.324357797138672\n",
            "\t the loss for timestep 20 is: 1.2900440270819957\n",
            "\t the loss for timestep 21 is: 0.32160736170968074\n",
            "\t the loss for timestep 22 is: 1.29687603601575\n",
            "\t the loss for timestep 23 is: 0.3189217788981817\n",
            "\t the loss for timestep 24 is: 1.3049584759938921\n",
            "\t the loss for timestep 25 is: 0.31729516493838295\n",
            "\t the loss for timestep 26 is: 1.3117800560463375\n",
            "\t the loss for timestep 27 is: 0.31784781544920787\n",
            "\t the loss for timestep 28 is: 1.314616877413194\n",
            "\t the loss for timestep 29 is: 0.32188813362923574\n",
            "\t the loss for timestep 30 is: 1.3106100133857137\n",
            "\t the loss for timestep 31 is: 0.3310001946555635\n",
            "\t the loss for timestep 32 is: 1.2969773158635511\n",
            "\t the loss for timestep 33 is: 0.3471575057088014\n",
            "\t the loss for timestep 34 is: 166.8267318453513\n",
            "\t the loss for timestep 35 is: 182.51321766540144\n",
            "\t the loss for timestep 36 is: 0.805765749284969\n",
            "\t the loss for timestep 37 is: 0.6667567383652859\n",
            "\t the loss for timestep 38 is: 0.782266559077968\n",
            "\t the loss for timestep 39 is: 0.7480797789445637\n",
            "\t the loss for timestep 40 is: 0.8222793854374787\n",
            "\t the loss for timestep 41 is: 0.7264332582925122\n",
            "\t the loss for timestep 42 is: 0.8293942424579498\n",
            "\t the loss for timestep 43 is: 0.7637277911033029\n",
            "\t the loss for timestep 44 is: 0.8278037284751371\n",
            "\t the loss for timestep 45 is: 0.7919552056719729\n",
            "\t the loss for timestep 46 is: 0.8422425242353642\n",
            "\t the loss for timestep 47 is: 0.7966544233144607\n",
            "\t the loss for timestep 48 is: 0.9357549392818711\n",
            "\t the loss for timestep 49 is: 0.8957677069472115\n",
            "\t the loss for timestep 50 is: 0.8666050581057847\n",
            "\t the loss for timestep 51 is: 0.9047233887676802\n",
            "\t the loss for timestep 52 is: 0.8917615037469334\n",
            "\t the loss for timestep 53 is: 0.9196728858470665\n",
            "\t the loss for timestep 54 is: 0.9209440614299325\n",
            "\t the loss for timestep 55 is: 0.938689957548424\n",
            "\t the loss for timestep 56 is: 0.9452429043624984\n",
            "\t the loss for timestep 57 is: 0.9575982272423025\n",
            "\t the loss for timestep 58 is: 0.9653987417201317\n",
            "\t the loss for timestep 59 is: 0.9745324637170635\n",
            "\t the loss for timestep 60 is: 0.9815261370524713\n",
            "\t the loss for timestep 61 is: 0.9881577793382362\n",
            "\t the loss for timestep 62 is: 1.3780548531218204\n",
            "\t the loss for timestep 63 is: 1.397382946860904\n",
            "\t the loss for timestep 64 is: 2.4082246904721827\n",
            "\t the loss for timestep 65 is: 2.310514783078498\n",
            "\t the loss for timestep 66 is: 0.9545236432440255\n",
            "\t the loss for timestep 67 is: 1.0407380824550956\n",
            "\t the loss for timestep 68 is: 0.9901122045154827\n",
            "\t the loss for timestep 69 is: 1.0090162992864988\n",
            "\t the loss for timestep 70 is: 1.0070023382866098\n",
            "\t the loss for timestep 71 is: 0.998318200178794\n",
            "\t the loss for timestep 72 is: 0.9798186697814524\n",
            "\t the loss for timestep 73 is: 0.9805798345077061\n",
            "\t the loss for timestep 74 is: 0.9686778958740294\n",
            "\t the loss for timestep 75 is: 0.9610421604238899\n",
            "\t the loss for timestep 76 is: 0.9499480206417525\n",
            "\t the loss for timestep 77 is: 0.9393633523364098\n",
            "\t the loss for timestep 78 is: 0.9273933808754029\n",
            "\t the loss for timestep 79 is: 2.52259664892734\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.6282648879992249\n",
            "\t the loss for timestep 2 is: 1.1564721574704209\n",
            "\t the loss for timestep 3 is: 0.7942630801787618\n",
            "\t the loss for timestep 4 is: 0.9738023323590873\n",
            "\t the loss for timestep 5 is: 2.3375719147376377\n",
            "\t the loss for timestep 6 is: 1.6276389830322717\n",
            "\t the loss for timestep 7 is: 0.5731667055179688\n",
            "\t the loss for timestep 8 is: 1.1188456413256398\n",
            "\t the loss for timestep 9 is: 0.7525609925128249\n",
            "\t the loss for timestep 10 is: 0.9492112814190993\n",
            "\t the loss for timestep 11 is: 0.8009651783750107\n",
            "\t the loss for timestep 12 is: 0.8805549695062455\n",
            "\t the loss for timestep 13 is: 0.8101342344978381\n",
            "\t the loss for timestep 14 is: 0.8417305758415863\n",
            "\t the loss for timestep 15 is: 0.8021340304478037\n",
            "\t the loss for timestep 16 is: 0.8129895700017382\n",
            "\t the loss for timestep 17 is: 0.7867578706874604\n",
            "\t the loss for timestep 18 is: 0.7880581471926773\n",
            "\t the loss for timestep 19 is: 0.7681374393463032\n",
            "\t the loss for timestep 20 is: 0.7648064535328813\n",
            "\t the loss for timestep 21 is: 0.7481569489517079\n",
            "\t the loss for timestep 22 is: 0.7425372097227761\n",
            "\t the loss for timestep 23 is: 0.7277680785226006\n",
            "\t the loss for timestep 24 is: 0.7210672049165607\n",
            "\t the loss for timestep 25 is: 0.7074989025093676\n",
            "\t the loss for timestep 26 is: 0.7003920408852996\n",
            "\t the loss for timestep 27 is: 0.6876601224248425\n",
            "\t the loss for timestep 28 is: 0.6805587549105391\n",
            "\t the loss for timestep 29 is: 0.6684360534479913\n",
            "\t the loss for timestep 30 is: 0.6616195580487261\n",
            "\t the loss for timestep 31 is: 0.6499284210209799\n",
            "\t the loss for timestep 32 is: 0.6436172006300431\n",
            "\t the loss for timestep 33 is: 0.6321786681390977\n",
            "\t the loss for timestep 34 is: 172.04767986642733\n",
            "\t the loss for timestep 35 is: 183.15624583164563\n",
            "\t the loss for timestep 36 is: 0.6324702394692608\n",
            "\t the loss for timestep 37 is: 0.6236439506895113\n",
            "\t the loss for timestep 38 is: 0.611227021951613\n",
            "\t the loss for timestep 39 is: 0.662631496651919\n",
            "\t the loss for timestep 40 is: 0.6157869065101744\n",
            "\t the loss for timestep 41 is: 0.6271343311834316\n",
            "\t the loss for timestep 42 is: 0.607440020138509\n",
            "\t the loss for timestep 43 is: 0.6296328245490448\n",
            "\t the loss for timestep 44 is: 0.5906633934249601\n",
            "\t the loss for timestep 45 is: 0.6288092268662849\n",
            "\t the loss for timestep 46 is: 0.5821322007741839\n",
            "\t the loss for timestep 47 is: 0.6408286083493545\n",
            "\t the loss for timestep 48 is: 0.6737280358623294\n",
            "\t the loss for timestep 49 is: 0.6383809992243628\n",
            "\t the loss for timestep 50 is: 0.5822902610372032\n",
            "\t the loss for timestep 51 is: 0.6337348988855794\n",
            "\t the loss for timestep 52 is: 0.569085178749974\n",
            "\t the loss for timestep 53 is: 0.6434789045604284\n",
            "\t the loss for timestep 54 is: 0.5572572111006479\n",
            "\t the loss for timestep 55 is: 0.6574769436755336\n",
            "\t the loss for timestep 56 is: 0.5420820276273439\n",
            "\t the loss for timestep 57 is: 0.6764879047713468\n",
            "\t the loss for timestep 58 is: 0.5224804298008026\n",
            "\t the loss for timestep 59 is: 0.7020348495709132\n",
            "\t the loss for timestep 60 is: 0.4970715966612843\n",
            "\t the loss for timestep 61 is: 0.7365082043839491\n",
            "\t the loss for timestep 62 is: 0.9085898264610799\n",
            "\t the loss for timestep 63 is: 1.1643023716153138\n",
            "\t the loss for timestep 64 is: 1.8272309241708844\n",
            "\t the loss for timestep 65 is: 1.3093867709502276\n",
            "\t the loss for timestep 66 is: 0.5688174502859856\n",
            "\t the loss for timestep 67 is: 0.7248910499573832\n",
            "\t the loss for timestep 68 is: 0.47179731469201275\n",
            "\t the loss for timestep 69 is: 0.7544340652712389\n",
            "\t the loss for timestep 70 is: 0.4316487934359031\n",
            "\t the loss for timestep 71 is: 0.8176470247517873\n",
            "\t the loss for timestep 72 is: 0.3818661288202624\n",
            "\t the loss for timestep 73 is: 0.9149617276536454\n",
            "\t the loss for timestep 74 is: 0.3261733260122432\n",
            "\t the loss for timestep 75 is: 1.0557518728021669\n",
            "\t the loss for timestep 76 is: 0.266532994033039\n",
            "\t the loss for timestep 77 is: 1.25197728660361\n",
            "\t the loss for timestep 78 is: 0.2122846024420774\n",
            "\t the loss for timestep 79 is: 2.7604049051947257\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.14973937260228193\n",
            "\t the loss for timestep 2 is: 1.9129882840210928\n",
            "\t the loss for timestep 3 is: 0.15534731737671312\n",
            "\t the loss for timestep 4 is: 1.8654287032150854\n",
            "\t the loss for timestep 5 is: 0.14966204822870838\n",
            "\t the loss for timestep 6 is: 3.3421920042143896\n",
            "\t the loss for timestep 7 is: 0.13637865600030663\n",
            "\t the loss for timestep 8 is: 2.0375514323808277\n",
            "\t the loss for timestep 9 is: 0.15190801587672792\n",
            "\t the loss for timestep 10 is: 1.8953184055090275\n",
            "\t the loss for timestep 11 is: 0.15596663495406568\n",
            "\t the loss for timestep 12 is: 1.8618925167408773\n",
            "\t the loss for timestep 13 is: 0.15706761897537602\n",
            "\t the loss for timestep 14 is: 1.8535409800992064\n",
            "\t the loss for timestep 15 is: 0.15736529957680032\n",
            "\t the loss for timestep 16 is: 1.8519225094357652\n",
            "\t the loss for timestep 17 is: 0.15743771816158417\n",
            "\t the loss for timestep 18 is: 1.8522695768850217\n",
            "\t the loss for timestep 19 is: 0.15744619943957536\n",
            "\t the loss for timestep 20 is: 1.8532675681568176\n",
            "\t the loss for timestep 21 is: 0.15743869897415663\n",
            "\t the loss for timestep 22 is: 1.8545301259221791\n",
            "\t the loss for timestep 23 is: 0.15743249301214537\n",
            "\t the loss for timestep 24 is: 1.8559205737916025\n",
            "\t the loss for timestep 25 is: 0.15743683196766944\n",
            "\t the loss for timestep 26 is: 1.8573700740439136\n",
            "\t the loss for timestep 27 is: 0.15745937400768587\n",
            "\t the loss for timestep 28 is: 1.858821886920533\n",
            "\t the loss for timestep 29 is: 0.15750776059515442\n",
            "\t the loss for timestep 30 is: 1.860222650295735\n",
            "\t the loss for timestep 31 is: 0.15759031670390633\n",
            "\t the loss for timestep 32 is: 1.8615140843653815\n",
            "\t the loss for timestep 33 is: 0.15771618822117472\n",
            "\t the loss for timestep 34 is: 163.47872390216452\n",
            "\t the loss for timestep 35 is: 187.17575449280406\n",
            "\t the loss for timestep 36 is: 0.6951507187720726\n",
            "\t the loss for timestep 37 is: 0.3792592965196441\n",
            "\t the loss for timestep 38 is: 0.8066554373450401\n",
            "\t the loss for timestep 39 is: 0.3591472090880695\n",
            "\t the loss for timestep 40 is: 1.0259063474063255\n",
            "\t the loss for timestep 41 is: 0.26393640145104474\n",
            "\t the loss for timestep 42 is: 1.2964726623342062\n",
            "\t the loss for timestep 43 is: 0.22665969969331887\n",
            "\t the loss for timestep 44 is: 1.4851087203645232\n",
            "\t the loss for timestep 45 is: 0.20384147766213165\n",
            "\t the loss for timestep 46 is: 1.616848086347709\n",
            "\t the loss for timestep 47 is: 0.19282546666304134\n",
            "\t the loss for timestep 48 is: 1.5360142510799237\n",
            "\t the loss for timestep 49 is: 0.25900106704805703\n",
            "\t the loss for timestep 50 is: 1.434024219500222\n",
            "\t the loss for timestep 51 is: 0.23459665316280925\n",
            "\t the loss for timestep 52 is: 1.5129002249274965\n",
            "\t the loss for timestep 53 is: 0.2349878904614701\n",
            "\t the loss for timestep 54 is: 1.53130816663751\n",
            "\t the loss for timestep 55 is: 0.24526194228024348\n",
            "\t the loss for timestep 56 is: 1.5078830977686766\n",
            "\t the loss for timestep 57 is: 0.2645536018505235\n",
            "\t the loss for timestep 58 is: 1.4551871114677817\n",
            "\t the loss for timestep 59 is: 0.2946450525135896\n",
            "\t the loss for timestep 60 is: 1.3787887157958634\n",
            "\t the loss for timestep 61 is: 0.33964716830996505\n",
            "\t the loss for timestep 62 is: 1.5894333923104615\n",
            "\t the loss for timestep 63 is: 1.0081217685676749\n",
            "\t the loss for timestep 64 is: 2.3273155350561465\n",
            "\t the loss for timestep 65 is: 1.4361782073815248\n",
            "\t the loss for timestep 66 is: 0.8028176709861929\n",
            "\t the loss for timestep 67 is: 0.8020818958753928\n",
            "\t the loss for timestep 68 is: 0.799625206033501\n",
            "\t the loss for timestep 69 is: 0.8269345688028572\n",
            "\t the loss for timestep 70 is: 0.8496618737436681\n",
            "\t the loss for timestep 71 is: 0.8695610538446179\n",
            "\t the loss for timestep 72 is: 0.8856864655684541\n",
            "\t the loss for timestep 73 is: 0.9173813562682195\n",
            "\t the loss for timestep 74 is: 0.9397303229572053\n",
            "\t the loss for timestep 75 is: 0.9690106537289476\n",
            "\t the loss for timestep 76 is: 0.996504746937385\n",
            "\t the loss for timestep 77 is: 1.0262191886820997\n",
            "\t the loss for timestep 78 is: 1.056179482171593\n",
            "\t the loss for timestep 79 is: 2.511950511548279\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 1.105016594922872\n",
            "\t the loss for timestep 2 is: 1.102839208370551\n",
            "\t the loss for timestep 3 is: 1.1022723453612417\n",
            "\t the loss for timestep 4 is: 1.086172795751526\n",
            "\t the loss for timestep 5 is: 2.4114017540038235\n",
            "\t the loss for timestep 6 is: 1.8664852623164847\n",
            "\t the loss for timestep 7 is: 0.7942071460274903\n",
            "\t the loss for timestep 8 is: 1.1506168251396065\n",
            "\t the loss for timestep 9 is: 0.9958992312384012\n",
            "\t the loss for timestep 10 is: 1.0162760092110257\n",
            "\t the loss for timestep 11 is: 0.9844090241846193\n",
            "\t the loss for timestep 12 is: 0.9710368487023013\n",
            "\t the loss for timestep 13 is: 0.9501956013905511\n",
            "\t the loss for timestep 14 is: 0.9319533244696718\n",
            "\t the loss for timestep 15 is: 0.9123254782944029\n",
            "\t the loss for timestep 16 is: 0.8933772704059774\n",
            "\t the loss for timestep 17 is: 0.8742537114904219\n",
            "\t the loss for timestep 18 is: 0.855591529415948\n",
            "\t the loss for timestep 19 is: 0.8371660524117616\n",
            "\t the loss for timestep 20 is: 0.8192376124561654\n",
            "\t the loss for timestep 21 is: 0.8017352728629945\n",
            "\t the loss for timestep 22 is: 0.7847837930584449\n",
            "\t the loss for timestep 23 is: 0.7683500351316667\n",
            "\t the loss for timestep 24 is: 0.7524966141972247\n",
            "\t the loss for timestep 25 is: 0.7371965753285392\n",
            "\t the loss for timestep 26 is: 0.7224795238837151\n",
            "\t the loss for timestep 27 is: 0.7083165259919543\n",
            "\t the loss for timestep 28 is: 0.6947186955464654\n",
            "\t the loss for timestep 29 is: 0.6816543140088633\n",
            "\t the loss for timestep 30 is: 0.669124224853967\n",
            "\t the loss for timestep 31 is: 0.6570943110283605\n",
            "\t the loss for timestep 32 is: 0.6455608007846878\n",
            "\t the loss for timestep 33 is: 0.6344878542499607\n",
            "\t the loss for timestep 34 is: 172.06070093765743\n",
            "\t the loss for timestep 35 is: 182.21235678654216\n",
            "\t the loss for timestep 36 is: 0.5725860812762015\n",
            "\t the loss for timestep 37 is: 0.6855423284265993\n",
            "\t the loss for timestep 38 is: 0.5347452324799044\n",
            "\t the loss for timestep 39 is: 0.755757375775824\n",
            "\t the loss for timestep 40 is: 0.5153727067434158\n",
            "\t the loss for timestep 41 is: 0.7354272129348655\n",
            "\t the loss for timestep 42 is: 0.4797355818817695\n",
            "\t the loss for timestep 43 is: 0.784174317072102\n",
            "\t the loss for timestep 44 is: 0.4268991358000833\n",
            "\t the loss for timestep 45 is: 0.8493560076847384\n",
            "\t the loss for timestep 46 is: 0.3754433291781688\n",
            "\t the loss for timestep 47 is: 0.9408606258116068\n",
            "\t the loss for timestep 48 is: 0.4251916476957424\n",
            "\t the loss for timestep 49 is: 0.9545136579494564\n",
            "\t the loss for timestep 50 is: 0.322287828226713\n",
            "\t the loss for timestep 51 is: 1.1053579614774673\n",
            "\t the loss for timestep 52 is: 0.26568211399469\n",
            "\t the loss for timestep 53 is: 1.3091347979926078\n",
            "\t the loss for timestep 54 is: 0.22524490103485265\n",
            "\t the loss for timestep 55 is: 1.5024177225498878\n",
            "\t the loss for timestep 56 is: 0.2030822756341087\n",
            "\t the loss for timestep 57 is: 1.6281719249764321\n",
            "\t the loss for timestep 58 is: 0.19546188582727317\n",
            "\t the loss for timestep 59 is: 1.679014496421552\n",
            "\t the loss for timestep 60 is: 0.19685716650823318\n",
            "\t the loss for timestep 61 is: 1.6794966330761287\n",
            "\t the loss for timestep 62 is: 0.30412573349910343\n",
            "\t the loss for timestep 63 is: 1.8132687816733952\n",
            "\t the loss for timestep 64 is: 1.3651563677449243\n",
            "\t the loss for timestep 65 is: 1.8422161879555425\n",
            "\t the loss for timestep 66 is: 0.41869197626485966\n",
            "\t the loss for timestep 67 is: 1.0362913959844988\n",
            "\t the loss for timestep 68 is: 0.3370259562319331\n",
            "\t the loss for timestep 69 is: 1.1346564110031052\n",
            "\t the loss for timestep 70 is: 0.3141536438440803\n",
            "\t the loss for timestep 71 is: 1.228061744498319\n",
            "\t the loss for timestep 72 is: 0.3040526896271755\n",
            "\t the loss for timestep 73 is: 1.269283652990771\n",
            "\t the loss for timestep 74 is: 0.3066299626479259\n",
            "\t the loss for timestep 75 is: 1.2720652333055351\n",
            "\t the loss for timestep 76 is: 0.31559939497099226\n",
            "\t the loss for timestep 77 is: 1.252673896667472\n",
            "\t the loss for timestep 78 is: 0.3283410216322175\n",
            "\t the loss for timestep 79 is: 2.537111587694266\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.24357873398892327\n",
            "\t the loss for timestep 2 is: 1.5143956010923652\n",
            "\t the loss for timestep 3 is: 0.29620396166266777\n",
            "\t the loss for timestep 4 is: 1.3339215644934748\n",
            "\t the loss for timestep 5 is: 0.3310208114619486\n",
            "\t the loss for timestep 6 is: 2.313702502082424\n",
            "\t the loss for timestep 7 is: 0.24349352193046675\n",
            "\t the loss for timestep 8 is: 1.5184704019548732\n",
            "\t the loss for timestep 9 is: 0.2905946923840722\n",
            "\t the loss for timestep 10 is: 1.3530905621508502\n",
            "\t the loss for timestep 11 is: 0.3125117196241164\n",
            "\t the loss for timestep 12 is: 1.2811897487796824\n",
            "\t the loss for timestep 13 is: 0.3219060811505475\n",
            "\t the loss for timestep 14 is: 1.2493294711077518\n",
            "\t the loss for timestep 15 is: 0.32409550929837405\n",
            "\t the loss for timestep 16 is: 1.2396579062884299\n",
            "\t the loss for timestep 17 is: 0.32143508196730786\n",
            "\t the loss for timestep 18 is: 1.2447933577489043\n",
            "\t the loss for timestep 19 is: 0.3152877235736238\n",
            "\t the loss for timestep 20 is: 1.261043884073429\n",
            "\t the loss for timestep 21 is: 0.3066459042246966\n",
            "\t the loss for timestep 22 is: 1.2860839671771236\n",
            "\t the loss for timestep 23 is: 0.29638812729936825\n",
            "\t the loss for timestep 24 is: 1.317934532472745\n",
            "\t the loss for timestep 25 is: 0.28538543775349035\n",
            "\t the loss for timestep 26 is: 1.3544442502439582\n",
            "\t the loss for timestep 27 is: 0.2745323863164247\n",
            "\t the loss for timestep 28 is: 1.3930344616010535\n",
            "\t the loss for timestep 29 is: 0.26473539071187135\n",
            "\t the loss for timestep 30 is: 1.4306672515581487\n",
            "\t the loss for timestep 31 is: 0.2568921149230944\n",
            "\t the loss for timestep 32 is: 1.4639826178566542\n",
            "\t the loss for timestep 33 is: 0.2518933735570451\n",
            "\t the loss for timestep 34 is: 166.01202821980033\n",
            "\t the loss for timestep 35 is: 185.19841816670544\n",
            "\t the loss for timestep 36 is: 0.8467836407769168\n",
            "\t the loss for timestep 37 is: 0.5016010978805248\n",
            "\t the loss for timestep 38 is: 0.8368769118001934\n",
            "\t the loss for timestep 39 is: 0.5319494682965484\n",
            "\t the loss for timestep 40 is: 0.9068732086819129\n",
            "\t the loss for timestep 41 is: 0.45472914860811936\n",
            "\t the loss for timestep 42 is: 0.9625623262767847\n",
            "\t the loss for timestep 43 is: 0.43037380183914725\n",
            "\t the loss for timestep 44 is: 1.0022460223028815\n",
            "\t the loss for timestep 45 is: 0.398329312322353\n",
            "\t the loss for timestep 46 is: 1.073428415873133\n",
            "\t the loss for timestep 47 is: 0.41520637648722125\n",
            "\t the loss for timestep 48 is: 1.1286903217035982\n",
            "\t the loss for timestep 49 is: 0.4264252339924936\n",
            "\t the loss for timestep 50 is: 1.0511052961087874\n",
            "\t the loss for timestep 51 is: 0.40692260383383533\n",
            "\t the loss for timestep 52 is: 1.0989044214319388\n",
            "\t the loss for timestep 53 is: 0.3987264086945858\n",
            "\t the loss for timestep 54 is: 1.1395243458772495\n",
            "\t the loss for timestep 55 is: 0.4027788060928267\n",
            "\t the loss for timestep 56 is: 1.1595995942622774\n",
            "\t the loss for timestep 57 is: 0.4217629325318235\n",
            "\t the loss for timestep 58 is: 1.1549593513333107\n",
            "\t the loss for timestep 59 is: 0.4587154464374083\n",
            "\t the loss for timestep 60 is: 1.1265056820067112\n",
            "\t the loss for timestep 61 is: 0.5160595673493444\n",
            "\t the loss for timestep 62 is: 1.3801235276796784\n",
            "\t the loss for timestep 63 is: 0.9239758004254413\n",
            "\t the loss for timestep 64 is: 2.3554075384806596\n",
            "\t the loss for timestep 65 is: 1.8471975406551084\n",
            "\t the loss for timestep 66 is: 0.7846913121214214\n",
            "\t the loss for timestep 67 is: 0.9564056768283944\n",
            "\t the loss for timestep 68 is: 0.8285483235654431\n",
            "\t the loss for timestep 69 is: 0.9612137918394987\n",
            "\t the loss for timestep 70 is: 0.9152685278693653\n",
            "\t the loss for timestep 71 is: 0.9800590246086867\n",
            "\t the loss for timestep 72 is: 0.9607361654023958\n",
            "\t the loss for timestep 73 is: 1.0094402226237889\n",
            "\t the loss for timestep 74 is: 1.0176525603156286\n",
            "\t the loss for timestep 75 is: 1.0472685293055854\n",
            "\t the loss for timestep 76 is: 1.0651227294336416\n",
            "\t the loss for timestep 77 is: 1.0876770523576922\n",
            "\t the loss for timestep 78 is: 1.1066412475025402\n",
            "\t the loss for timestep 79 is: 2.7328922724768216\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.9463900207557252\n",
            "\t the loss for timestep 2 is: 1.2361344423595526\n",
            "\t the loss for timestep 3 is: 1.0899772191736048\n",
            "\t the loss for timestep 4 is: 1.1249409203101335\n",
            "\t the loss for timestep 5 is: 2.763957242449108\n",
            "\t the loss for timestep 6 is: 2.0278239559664977\n",
            "\t the loss for timestep 7 is: 0.6746163138775025\n",
            "\t the loss for timestep 8 is: 1.2213819178191785\n",
            "\t the loss for timestep 9 is: 0.958218850978944\n",
            "\t the loss for timestep 10 is: 1.0434852548101994\n",
            "\t the loss for timestep 11 is: 0.9702656352234873\n",
            "\t the loss for timestep 12 is: 0.9737870545141094\n",
            "\t the loss for timestep 13 is: 0.938737333099503\n",
            "\t the loss for timestep 14 is: 0.9239961620067104\n",
            "\t the loss for timestep 15 is: 0.8981427786348453\n",
            "\t the loss for timestep 16 is: 0.8791239010509715\n",
            "\t the loss for timestep 17 is: 0.8564815509049541\n",
            "\t the loss for timestep 18 is: 0.8368837857347182\n",
            "\t the loss for timestep 19 is: 0.8161092525472136\n",
            "\t the loss for timestep 20 is: 0.7971342449807965\n",
            "\t the loss for timestep 21 is: 0.7779126522290378\n",
            "\t the loss for timestep 22 is: 0.7600117836388547\n",
            "\t the loss for timestep 23 is: 0.7422520740398743\n",
            "\t the loss for timestep 24 is: 0.7255922931308022\n",
            "\t the loss for timestep 25 is: 0.7092348772675294\n",
            "\t the loss for timestep 26 is: 0.6938537166299301\n",
            "\t the loss for timestep 27 is: 0.6788274195788133\n",
            "\t the loss for timestep 28 is: 0.6646972953902401\n",
            "\t the loss for timestep 29 is: 0.6509155336480006\n",
            "\t the loss for timestep 30 is: 0.6379764446438313\n",
            "\t the loss for timestep 31 is: 0.6253414029261413\n",
            "\t the loss for timestep 32 is: 0.613519528555221\n",
            "\t the loss for timestep 33 is: 0.6019262568595606\n",
            "\t the loss for timestep 34 is: 173.7090787019278\n",
            "\t the loss for timestep 35 is: 187.30464669044352\n",
            "\t the loss for timestep 36 is: 0.847921040469374\n",
            "\t the loss for timestep 37 is: 0.36409853568901507\n",
            "\t the loss for timestep 38 is: 0.9432259328840017\n",
            "\t the loss for timestep 39 is: 0.30518917413305335\n",
            "\t the loss for timestep 40 is: 1.1718101028159005\n",
            "\t the loss for timestep 41 is: 0.22967041916265343\n",
            "\t the loss for timestep 42 is: 1.4364772653113036\n",
            "\t the loss for timestep 43 is: 0.18282840594301406\n",
            "\t the loss for timestep 44 is: 1.6817810419277965\n",
            "\t the loss for timestep 45 is: 0.1607722822118475\n",
            "\t the loss for timestep 46 is: 1.8400727044246312\n",
            "\t the loss for timestep 47 is: 0.15744374263957558\n",
            "\t the loss for timestep 48 is: 1.6609439902378178\n",
            "\t the loss for timestep 49 is: 0.16950772794534555\n",
            "\t the loss for timestep 50 is: 1.7718326168266743\n",
            "\t the loss for timestep 51 is: 0.15423568194494083\n",
            "\t the loss for timestep 52 is: 1.8907068735969008\n",
            "\t the loss for timestep 53 is: 0.15078138621265708\n",
            "\t the loss for timestep 54 is: 1.9217313334554724\n",
            "\t the loss for timestep 55 is: 0.15184945219989845\n",
            "\t the loss for timestep 56 is: 1.9161633236998106\n",
            "\t the loss for timestep 57 is: 0.15559512256940933\n",
            "\t the loss for timestep 58 is: 1.891295293214745\n",
            "\t the loss for timestep 59 is: 0.1621973329519329\n",
            "\t the loss for timestep 60 is: 1.8494513025491532\n",
            "\t the loss for timestep 61 is: 0.17282060779670505\n",
            "\t the loss for timestep 62 is: 1.8272322347821237\n",
            "\t the loss for timestep 63 is: 0.6788181165831407\n",
            "\t the loss for timestep 64 is: 2.3306322831177333\n",
            "\t the loss for timestep 65 is: 0.9281419771475982\n",
            "\t the loss for timestep 66 is: 0.8157425903550297\n",
            "\t the loss for timestep 67 is: 0.4999369037176632\n",
            "\t the loss for timestep 68 is: 0.7808937802606604\n",
            "\t the loss for timestep 69 is: 0.4868607573122909\n",
            "\t the loss for timestep 70 is: 0.8209248216467426\n",
            "\t the loss for timestep 71 is: 0.4966846842637148\n",
            "\t the loss for timestep 72 is: 0.8412864209147258\n",
            "\t the loss for timestep 73 is: 0.5253047380603527\n",
            "\t the loss for timestep 74 is: 0.8445532608219761\n",
            "\t the loss for timestep 75 is: 0.5621203470246756\n",
            "\t the loss for timestep 76 is: 0.8344372526972093\n",
            "\t the loss for timestep 77 is: 0.6049443920701869\n",
            "\t the loss for timestep 78 is: 0.8192742887086224\n",
            "\t the loss for timestep 79 is: 1.3438027224743299\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.5232306479895936\n",
            "\t the loss for timestep 2 is: 1.0898866549243504\n",
            "\t the loss for timestep 3 is: 0.583147416525918\n",
            "\t the loss for timestep 4 is: 0.92961596382018\n",
            "\t the loss for timestep 5 is: 0.9500051014506278\n",
            "\t the loss for timestep 6 is: 0.9588977407655431\n",
            "\t the loss for timestep 7 is: 0.6164996594777664\n",
            "\t the loss for timestep 8 is: 0.855374733930369\n",
            "\t the loss for timestep 9 is: 0.624018693847572\n",
            "\t the loss for timestep 10 is: 0.8088257076372225\n",
            "\t the loss for timestep 11 is: 0.6313024815517048\n",
            "\t the loss for timestep 12 is: 0.7765834018084525\n",
            "\t the loss for timestep 13 is: 0.6309147889293664\n",
            "\t the loss for timestep 14 is: 0.7510476347716242\n",
            "\t the loss for timestep 15 is: 0.6250890702609138\n",
            "\t the loss for timestep 16 is: 0.7296075425050652\n",
            "\t the loss for timestep 17 is: 0.6149562742818224\n",
            "\t the loss for timestep 18 is: 0.7111079564337721\n",
            "\t the loss for timestep 19 is: 0.6012844444809489\n",
            "\t the loss for timestep 20 is: 0.6952555825064674\n",
            "\t the loss for timestep 21 is: 0.5845000838614135\n",
            "\t the loss for timestep 22 is: 0.6823771115015165\n",
            "\t the loss for timestep 23 is: 0.5646627102850144\n",
            "\t the loss for timestep 24 is: 0.6734140653779421\n",
            "\t the loss for timestep 25 is: 0.541382709110041\n",
            "\t the loss for timestep 26 is: 0.6701456805425241\n",
            "\t the loss for timestep 27 is: 0.5136828699796328\n",
            "\t the loss for timestep 28 is: 0.6757510710501435\n",
            "\t the loss for timestep 29 is: 0.4798272698456595\n",
            "\t the loss for timestep 30 is: 0.6960165955549618\n",
            "\t the loss for timestep 31 is: 0.4372760967464793\n",
            "\t the loss for timestep 32 is: 0.7417695591935355\n",
            "\t the loss for timestep 33 is: 0.3833091465004969\n",
            "\t the loss for timestep 34 is: 170.81004754106584\n",
            "\t the loss for timestep 35 is: 184.59463234750325\n",
            "\t the loss for timestep 36 is: 0.49222698085318806\n",
            "\t the loss for timestep 37 is: 0.5770606949814574\n",
            "\t the loss for timestep 38 is: 0.43635135234818945\n",
            "\t the loss for timestep 39 is: 0.684297283269718\n",
            "\t the loss for timestep 40 is: 0.4146100250952536\n",
            "\t the loss for timestep 41 is: 0.6816518688482393\n",
            "\t the loss for timestep 42 is: 0.3471295927973963\n",
            "\t the loss for timestep 43 is: 0.8230826409788371\n",
            "\t the loss for timestep 44 is: 0.2694326903478892\n",
            "\t the loss for timestep 45 is: 1.0492884657836132\n",
            "\t the loss for timestep 46 is: 0.2223108720414614\n",
            "\t the loss for timestep 47 is: 1.2091408106606578\n",
            "\t the loss for timestep 48 is: 0.21107198698874918\n",
            "\t the loss for timestep 49 is: 1.3159340965707085\n",
            "\t the loss for timestep 50 is: 0.2115812150616975\n",
            "\t the loss for timestep 51 is: 1.3236827420391997\n",
            "\t the loss for timestep 52 is: 0.22365990192848267\n",
            "\t the loss for timestep 53 is: 1.2349902200963014\n",
            "\t the loss for timestep 54 is: 0.24840886982129878\n",
            "\t the loss for timestep 55 is: 1.0932565522219666\n",
            "\t the loss for timestep 56 is: 0.2815469313042719\n",
            "\t the loss for timestep 57 is: 0.9425014303937053\n",
            "\t the loss for timestep 58 is: 0.3193377242479744\n",
            "\t the loss for timestep 59 is: 0.8102187230277564\n",
            "\t the loss for timestep 60 is: 0.3583817779859345\n",
            "\t the loss for timestep 61 is: 0.7079746560697385\n",
            "\t the loss for timestep 62 is: 0.3009128102782689\n",
            "\t the loss for timestep 63 is: 1.2953367272763547\n",
            "\t the loss for timestep 64 is: 1.2642056180975714\n",
            "\t the loss for timestep 65 is: 0.8333540079162726\n",
            "\t the loss for timestep 66 is: 0.5110222254182798\n",
            "\t the loss for timestep 67 is: 0.5319972407878405\n",
            "\t the loss for timestep 68 is: 0.5036388816909725\n",
            "\t the loss for timestep 69 is: 0.5271501333214035\n",
            "\t the loss for timestep 70 is: 0.5122468035100667\n",
            "\t the loss for timestep 71 is: 0.5253465712547996\n",
            "\t the loss for timestep 72 is: 0.5225753143755076\n",
            "\t the loss for timestep 73 is: 0.5295129198736477\n",
            "\t the loss for timestep 74 is: 0.5288124721126761\n",
            "\t the loss for timestep 75 is: 0.5323990226574746\n",
            "\t the loss for timestep 76 is: 0.5332126156186089\n",
            "\t the loss for timestep 77 is: 0.5353071178660794\n",
            "\t the loss for timestep 78 is: 0.5364261939230542\n",
            "\t the loss for timestep 79 is: 0.49834398306075817\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.6255123318727251\n",
            "\t the loss for timestep 2 is: 0.5629744743417625\n",
            "\t the loss for timestep 3 is: 0.5287728190291421\n",
            "\t the loss for timestep 4 is: 0.5431788523767411\n",
            "\t the loss for timestep 5 is: 0.4065486695042475\n",
            "\t the loss for timestep 6 is: 0.41565751209515067\n",
            "\t the loss for timestep 7 is: 0.5260146858352881\n",
            "\t the loss for timestep 8 is: 0.539515892864004\n",
            "\t the loss for timestep 9 is: 0.5312774070835683\n",
            "\t the loss for timestep 10 is: 0.533261418729807\n",
            "\t the loss for timestep 11 is: 0.5298313306582566\n",
            "\t the loss for timestep 12 is: 0.5288534314869293\n",
            "\t the loss for timestep 13 is: 0.5262875319043122\n",
            "\t the loss for timestep 14 is: 0.5242536016969774\n",
            "\t the loss for timestep 15 is: 0.5216399905809251\n",
            "\t the loss for timestep 16 is: 0.5190530213517742\n",
            "\t the loss for timestep 17 is: 0.5161752008934026\n",
            "\t the loss for timestep 18 is: 0.5131943989867633\n",
            "\t the loss for timestep 19 is: 0.5100184299655612\n",
            "\t the loss for timestep 20 is: 0.5067139526673072\n",
            "\t the loss for timestep 21 is: 0.5032567693577418\n",
            "\t the loss for timestep 22 is: 0.49967642503380977\n",
            "\t the loss for timestep 23 is: 0.49597059013093003\n",
            "\t the loss for timestep 24 is: 0.49215671333578415\n",
            "\t the loss for timestep 25 is: 0.4882401727693253\n",
            "\t the loss for timestep 26 is: 0.48423432968695296\n",
            "\t the loss for timestep 27 is: 0.4801465885805296\n",
            "\t the loss for timestep 28 is: 0.47598842602263\n",
            "\t the loss for timestep 29 is: 0.4717692414497795\n",
            "\t the loss for timestep 30 is: 0.4674989965574178\n",
            "\t the loss for timestep 31 is: 0.46318677063623265\n",
            "\t the loss for timestep 32 is: 0.45884199472930565\n",
            "\t the loss for timestep 33 is: 0.4544733407275163\n",
            "\t the loss for timestep 34 is: 182.55247879203858\n",
            "\t the loss for timestep 35 is: 184.3383411700308\n",
            "\t the loss for timestep 36 is: 0.36032408784378633\n",
            "\t the loss for timestep 37 is: 0.5279986283996817\n",
            "\t the loss for timestep 38 is: 0.3744273932531898\n",
            "\t the loss for timestep 39 is: 0.5815716663073335\n",
            "\t the loss for timestep 40 is: 0.43638830416503555\n",
            "\t the loss for timestep 41 is: 0.4551355806023706\n",
            "\t the loss for timestep 42 is: 0.42210012084212273\n",
            "\t the loss for timestep 43 is: 0.4588207202370113\n",
            "\t the loss for timestep 44 is: 0.390584371665632\n",
            "\t the loss for timestep 45 is: 0.43454318624628535\n",
            "\t the loss for timestep 46 is: 0.38201365364750295\n",
            "\t the loss for timestep 47 is: 0.3806573942720175\n",
            "\t the loss for timestep 48 is: 0.35540088761716604\n",
            "\t the loss for timestep 49 is: 0.42940453779673604\n",
            "\t the loss for timestep 50 is: 0.36198198642989443\n",
            "\t the loss for timestep 51 is: 0.42770434204199936\n",
            "\t the loss for timestep 52 is: 0.3461156380400302\n",
            "\t the loss for timestep 53 is: 0.43620047659707123\n",
            "\t the loss for timestep 54 is: 0.32568513044221603\n",
            "\t the loss for timestep 55 is: 0.457235295374944\n",
            "\t the loss for timestep 56 is: 0.2976158407249168\n",
            "\t the loss for timestep 57 is: 0.5035144139635575\n",
            "\t the loss for timestep 58 is: 0.259479187856743\n",
            "\t the loss for timestep 59 is: 0.6046055508178935\n",
            "\t the loss for timestep 60 is: 0.21259657396342782\n",
            "\t the loss for timestep 61 is: 0.8267496150123084\n",
            "\t the loss for timestep 62 is: 0.15109265504355532\n",
            "\t the loss for timestep 63 is: 1.927663534346332\n",
            "\t the loss for timestep 64 is: 0.3326966364475977\n",
            "\t the loss for timestep 65 is: 1.842740360540145\n",
            "\t the loss for timestep 66 is: 0.15110829546500637\n",
            "\t the loss for timestep 67 is: 1.5258778024650441\n",
            "\t the loss for timestep 68 is: 0.14069930903194922\n",
            "\t the loss for timestep 69 is: 1.7682769343618154\n",
            "\t the loss for timestep 70 is: 0.14111453887948244\n",
            "\t the loss for timestep 71 is: 1.7813573603261417\n",
            "\t the loss for timestep 72 is: 0.14958701364378277\n",
            "\t the loss for timestep 73 is: 1.5899323516593982\n",
            "\t the loss for timestep 74 is: 0.17581425946518756\n",
            "\t the loss for timestep 75 is: 1.2169022313289806\n",
            "\t the loss for timestep 76 is: 0.25372600428771575\n",
            "\t the loss for timestep 77 is: 0.7712583835408744\n",
            "\t the loss for timestep 78 is: 0.414906751678792\n",
            "\t the loss for timestep 79 is: 1.1320833547139326\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.4228179710178396\n",
            "\t the loss for timestep 2 is: 0.6196634549578508\n",
            "\t the loss for timestep 3 is: 0.5446419895563102\n",
            "\t the loss for timestep 4 is: 0.5773968679988564\n",
            "\t the loss for timestep 5 is: 0.46540252854923825\n",
            "\t the loss for timestep 6 is: 0.44025204858736944\n",
            "\t the loss for timestep 7 is: 0.5389848303609639\n",
            "\t the loss for timestep 8 is: 0.5649321603045503\n",
            "\t the loss for timestep 9 is: 0.5578603301119271\n",
            "\t the loss for timestep 10 is: 0.5595955805247989\n",
            "\t the loss for timestep 11 is: 0.5556688657829422\n",
            "\t the loss for timestep 12 is: 0.5541051049405815\n",
            "\t the loss for timestep 13 is: 0.550876125195731\n",
            "\t the loss for timestep 14 is: 0.5481277906024861\n",
            "\t the loss for timestep 15 is: 0.5447350349277016\n",
            "\t the loss for timestep 16 is: 0.5413272928790017\n",
            "\t the loss for timestep 17 is: 0.537578209729048\n",
            "\t the loss for timestep 18 is: 0.5336933978317273\n",
            "\t the loss for timestep 19 is: 0.5295776809974366\n",
            "\t the loss for timestep 20 is: 0.5253107582494734\n",
            "\t the loss for timestep 21 is: 0.5208693332723489\n",
            "\t the loss for timestep 22 is: 0.5162929645629882\n",
            "\t the loss for timestep 23 is: 0.5115820470156264\n",
            "\t the loss for timestep 24 is: 0.5067619100015228\n",
            "\t the loss for timestep 25 is: 0.5018418031494085\n",
            "\t the loss for timestep 26 is: 0.49684137309731663\n",
            "\t the loss for timestep 27 is: 0.49177182656333934\n",
            "\t the loss for timestep 28 is: 0.4866498650142025\n",
            "\t the loss for timestep 29 is: 0.48148813474561997\n",
            "\t the loss for timestep 30 is: 0.47630077702028206\n",
            "\t the loss for timestep 31 is: 0.4710996147859484\n",
            "\t the loss for timestep 32 is: 0.4658972219690677\n",
            "\t the loss for timestep 33 is: 0.460704307529131\n",
            "\t the loss for timestep 34 is: 182.24121509449577\n",
            "\t the loss for timestep 35 is: 184.09765074871984\n",
            "\t the loss for timestep 36 is: 0.36478281749174674\n",
            "\t the loss for timestep 37 is: 0.5524323728945615\n",
            "\t the loss for timestep 38 is: 0.3560143360622371\n",
            "\t the loss for timestep 39 is: 0.6113256012525099\n",
            "\t the loss for timestep 40 is: 0.39012282773654616\n",
            "\t the loss for timestep 41 is: 0.49297367961103544\n",
            "\t the loss for timestep 42 is: 0.382374518086365\n",
            "\t the loss for timestep 43 is: 0.4985577577341875\n",
            "\t the loss for timestep 44 is: 0.35056905926961124\n",
            "\t the loss for timestep 45 is: 0.4918636022269235\n",
            "\t the loss for timestep 46 is: 0.32900077901545477\n",
            "\t the loss for timestep 47 is: 0.5055236154923012\n",
            "\t the loss for timestep 48 is: 0.31525948051741776\n",
            "\t the loss for timestep 49 is: 0.5528117004160638\n",
            "\t the loss for timestep 50 is: 0.2690521342818266\n",
            "\t the loss for timestep 51 is: 0.6380223069469599\n",
            "\t the loss for timestep 52 is: 0.22411769528822661\n",
            "\t the loss for timestep 53 is: 0.8210171268943227\n",
            "\t the loss for timestep 54 is: 0.179196360468516\n",
            "\t the loss for timestep 55 is: 1.168681229395395\n",
            "\t the loss for timestep 56 is: 0.14888918150471608\n",
            "\t the loss for timestep 57 is: 1.6125580151069514\n",
            "\t the loss for timestep 58 is: 0.1373106227821598\n",
            "\t the loss for timestep 59 is: 1.8705446526012757\n",
            "\t the loss for timestep 60 is: 0.13494061776821414\n",
            "\t the loss for timestep 61 is: 1.9333633572766573\n",
            "\t the loss for timestep 62 is: 0.1346620096283337\n",
            "\t the loss for timestep 63 is: 2.209404502675264\n",
            "\t the loss for timestep 64 is: 0.5093524412743091\n",
            "\t the loss for timestep 65 is: 1.655229489501051\n",
            "\t the loss for timestep 66 is: 0.19958368737542106\n",
            "\t the loss for timestep 67 is: 1.0380870884695765\n",
            "\t the loss for timestep 68 is: 0.1765612073128187\n",
            "\t the loss for timestep 69 is: 1.2430861026695847\n",
            "\t the loss for timestep 70 is: 0.16610125101449413\n",
            "\t the loss for timestep 71 is: 1.3922819141486125\n",
            "\t the loss for timestep 72 is: 0.16468258822324736\n",
            "\t the loss for timestep 73 is: 1.4090911724961857\n",
            "\t the loss for timestep 74 is: 0.17247278060596255\n",
            "\t the loss for timestep 75 is: 1.3258023335356077\n",
            "\t the loss for timestep 76 is: 0.19008765390799348\n",
            "\t the loss for timestep 77 is: 1.1671610060794213\n",
            "\t the loss for timestep 78 is: 0.22249366340179236\n",
            "\t the loss for timestep 79 is: 2.284029538984081\n",
            "\t the loss for timestep 0 is: 2.128026557426312\n",
            "\t the loss for timestep 1 is: 0.18270686280091783\n",
            "\t the loss for timestep 2 is: 1.268757544133051\n",
            "\t the loss for timestep 3 is: 0.23530084734654286\n",
            "\t the loss for timestep 4 is: 0.9167959337072824\n",
            "\t the loss for timestep 5 is: 0.17385782786524576\n",
            "\t the loss for timestep 6 is: 2.729731524655085\n",
            "\t the loss for timestep 7 is: 0.1739980098353171\n",
            "\t the loss for timestep 8 is: 1.3670048323213684\n",
            "\t the loss for timestep 9 is: 0.23017602324172465\n",
            "\t the loss for timestep 10 is: 0.9486453748188961\n",
            "\t the loss for timestep 11 is: 0.2883614577957249\n",
            "\t the loss for timestep 12 is: 0.7484031573790568\n",
            "\t the loss for timestep 13 is: 0.33881902693066895\n",
            "\t the loss for timestep 14 is: 0.6516104013428339\n",
            "\t the loss for timestep 15 is: 0.37544030312290444\n",
            "\t the loss for timestep 16 is: 0.601480804459079\n",
            "\t the loss for timestep 17 is: 0.4006737833702914\n",
            "\t the loss for timestep 18 is: 0.5722038350162698\n",
            "\t the loss for timestep 19 is: 0.4185913210638243\n",
            "\t the loss for timestep 20 is: 0.5532690362112517\n",
            "\t the loss for timestep 21 is: 0.4317218108120944\n",
            "\t the loss for timestep 22 is: 0.5400899186810155\n",
            "\t the loss for timestep 23 is: 0.4414340851712117\n",
            "\t the loss for timestep 24 is: 0.5303984557121837\n",
            "\t the loss for timestep 25 is: 0.4485084910252679\n",
            "\t the loss for timestep 26 is: 0.5229402153494174\n",
            "\t the loss for timestep 27 is: 0.45343445119724385\n",
            "\t the loss for timestep 28 is: 0.5169580397917933\n",
            "\t the loss for timestep 29 is: 0.4565450108538859\n",
            "\t the loss for timestep 30 is: 0.5119738567865565\n",
            "\t the loss for timestep 31 is: 0.45808050407810147\n",
            "\t the loss for timestep 32 is: 0.507681902390713\n",
            "\t the loss for timestep 33 is: 0.45821483908788085\n",
            "\t the loss for timestep 34 is: 180.98390770376128\n",
            "\t the loss for timestep 35 is: 184.0247045324506\n",
            "\t the loss for timestep 36 is: 0.3951977094765492\n",
            "\t the loss for timestep 37 is: 0.5977959810244433\n",
            "\t the loss for timestep 38 is: 0.375310798314777\n",
            "\t the loss for timestep 39 is: 0.6763195263786956\n",
            "\t the loss for timestep 40 is: 0.4108444365905452\n",
            "\t the loss for timestep 41 is: 0.5582677651557827\n",
            "\t the loss for timestep 42 is: 0.39619318573952894\n",
            "\t the loss for timestep 43 is: 0.5733030262148647\n",
            "\t the loss for timestep 44 is: 0.3603871780701653\n",
            "\t the loss for timestep 45 is: 0.5790711846586077\n",
            "\t the loss for timestep 46 is: 0.33641541456868185\n",
            "\t the loss for timestep 47 is: 0.61966537906641\n",
            "\t the loss for timestep 48 is: 0.3235037317031556\n",
            "\t the loss for timestep 49 is: 0.6635107672293952\n",
            "\t the loss for timestep 50 is: 0.28096213623627797\n",
            "\t the loss for timestep 51 is: 0.7544834005110476\n",
            "\t the loss for timestep 52 is: 0.24218660200678022\n",
            "\t the loss for timestep 53 is: 0.9055019925359169\n",
            "\t the loss for timestep 54 is: 0.20584597436320523\n",
            "\t the loss for timestep 55 is: 1.1156478479188199\n",
            "\t the loss for timestep 56 is: 0.17786203429519784\n",
            "\t the loss for timestep 57 is: 1.3534658710435865\n",
            "\t the loss for timestep 58 is: 0.16098482650193124\n",
            "\t the loss for timestep 59 is: 1.5498429652820982\n",
            "\t the loss for timestep 60 is: 0.15310451169834388\n",
            "\t the loss for timestep 61 is: 1.6628638279458818\n",
            "\t the loss for timestep 62 is: 0.15133064838525684\n",
            "\t the loss for timestep 63 is: 2.0714177727883705\n",
            "\t the loss for timestep 64 is: 0.7351503949479488\n",
            "\t the loss for timestep 65 is: 1.6614122779203746\n",
            "\t the loss for timestep 66 is: 0.24845999967214155\n",
            "\t the loss for timestep 67 is: 0.9682342829039723\n",
            "\t the loss for timestep 68 is: 0.2064495603419231\n",
            "\t the loss for timestep 69 is: 1.1729751045778487\n",
            "\t the loss for timestep 70 is: 0.184918488012155\n",
            "\t the loss for timestep 71 is: 1.3638978738606893\n",
            "\t the loss for timestep 72 is: 0.17418806416688623\n",
            "\t the loss for timestep 73 is: 1.462389409998168\n",
            "\t the loss for timestep 74 is: 0.1722283386514965\n",
            "\t the loss for timestep 75 is: 1.4945561571294526\n",
            "\t the loss for timestep 76 is: 0.1749767528447569\n",
            "\t the loss for timestep 77 is: 1.4821405712094973\n",
            "\t the loss for timestep 78 is: 0.18135053948318824\n",
            "\t the loss for timestep 79 is: 2.7167562878677662\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x787183c0e510>]"
            ]
          },
          "metadata": {},
          "execution_count": 169
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(rtrl.cache['losses'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7ugT6XeAFJs",
        "outputId": "0816eeb1-6659-4d0d-8cdb-124638cbd0ff"
      },
      "id": "M7ugT6XeAFJs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_rtrl)"
      ],
      "metadata": {
        "id": "Y_Le1IE6-cWQ"
      },
      "id": "Y_Le1IE6-cWQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def exp_smooth_loss(losses, beta=0.9):\n",
        "    \"\"\"Exponentially weighted moving average.\"\"\"\n",
        "    smoothed = []\n",
        "    last = 0\n",
        "    for i, val in enumerate(losses):\n",
        "        last = last * beta + (1 - beta) * val\n",
        "        smoothed_val = last / (1 - beta**(i + 1))  # bias-corrected\n",
        "        smoothed.append(smoothed_val)\n",
        "    return np.array(smoothed)\n",
        "\n",
        "smoothed_losses_exp = exp_smooth_loss(loss_rtrl, beta=0.9)"
      ],
      "metadata": {
        "id": "v_3RagRWySpV"
      },
      "id": "v_3RagRWySpV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(smoothed_losses_exp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "8HNeEvieayRR",
        "outputId": "01d6cf16-1e58-4dde-dbde-ea579354066b"
      },
      "id": "8HNeEvieayRR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7871836ab210>]"
            ]
          },
          "metadata": {},
          "execution_count": 171
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00155f29-14c8-4a26-bc54-0a3a2689f35c",
      "metadata": {
        "id": "00155f29-14c8-4a26-bc54-0a3a2689f35c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "d9af71b3-2d3c-45c4-fa67-0ada5077d0a2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "timesteps = len(rtrl.cache['losses'][1:] )\n",
        "plt.plot( range(timesteps) , [np.mean(a) for a in rtrl.cache['losses'][1:] ])\n",
        "# rtrl.cache['activations'][1:]\n",
        "plt.xlabel('Timesteps')\n",
        "plt.ylabel('Loss')\n",
        "t = datetime.datetime.now()\n",
        "h = t.hour\n",
        "m = t.minute\n",
        "s = t.second\n",
        "plt.savefig(f\"RNN_RTRL_Loss_plot_{h}_{m}_{s}.pdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67815cba-1106-4a4d-b999-388e5f203d52",
      "metadata": {
        "id": "67815cba-1106-4a4d-b999-388e5f203d52"
      },
      "source": [
        "# Possible causes of fluctuating losses are:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5ebf17d-ab87-4797-b7dc-f3ebc8df1214",
      "metadata": {
        "id": "b5ebf17d-ab87-4797-b7dc-f3ebc8df1214"
      },
      "source": [
        ">1.batch size,\n",
        ">\n",
        ">2.learning rate ,\n",
        ">\n",
        ">3.Conflicting error signals problem.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2406d1de-0447-4f86-b9dc-81330f78dca4",
      "metadata": {
        "id": "2406d1de-0447-4f86-b9dc-81330f78dca4"
      },
      "source": [
        "# 4. LSTM CELLS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e7d23a8-73ff-49b9-8a3e-1f05b2b6dbae",
      "metadata": {
        "id": "0e7d23a8-73ff-49b9-8a3e-1f05b2b6dbae"
      },
      "source": [
        "the vanishing/exploding error happens because of interdependence between error signals. As each error signal depends on previous one from succeeding layer in an unrolled network, this creates a chain rule product over multiple timesteps.\n",
        "As a result if each product is greater than 1 gradients will explode otherwise if less than 1 gradients will vanish.\n",
        "\n",
        "\n",
        "LSTM cells fix this issue by introducing CEC and forget gates????   [^1]\n",
        "\n",
        "[^1]:https://arxiv.org/pdf/1909.09586"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feede28b-ec71-4171-81c4-b9995a3c26aa",
      "metadata": {
        "id": "feede28b-ec71-4171-81c4-b9995a3c26aa"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.preprocessing import Normalizer,MinMaxScaler,PowerTransformer,StandardScaler,RobustScaler\n",
        "data=fetch_california_housing()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb9cc783-5d77-4972-8a47-1d01efdd80fd",
      "metadata": {
        "id": "fb9cc783-5d77-4972-8a47-1d01efdd80fd"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "X = data.data\n",
        "Y = data.target\n",
        "df = pd.DataFrame(X)\n",
        "df.iloc[: ,-1] = Y\n",
        "scaler = Normalizer()\n",
        "df = scaler.fit_transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89470085-1e9d-495c-b600-fa58752fa987",
      "metadata": {
        "id": "89470085-1e9d-495c-b600-fa58752fa987"
      },
      "outputs": [],
      "source": [
        "class LSTM:\n",
        "    def __init__(self, learning_rate=5e-7, hidden_units=10 ):\n",
        "        self.learning_rate  = learning_rate\n",
        "        self.hidden_units   = hidden_units\n",
        "        self.params         = {}\n",
        "        self.losses         = []\n",
        "\n",
        "    def sigmoid(self, X):\n",
        "        return 1/ (1+ np.exp(-X))\n",
        "\n",
        "    #This tang squashes the cell input between -2 and 2\n",
        "    def hp_tang(self, X):\n",
        "        return (4 * self.sigmoid( X ) - 2 )\n",
        "\n",
        "    def loss( self , error):\n",
        "        return 1/2 * ( error ) ** 2\n",
        "    #hidden_units refer to memory cells\n",
        "    def train(self,X,Y,learning_rate=0.005, hidden_units=100 ):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.hidden_units  = hidden_units\n",
        "\n",
        "        self.timesteps , n_features = X.shape\n",
        "\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        _,*dimsout = Y.shape\n",
        "        n_out = (self.hidden_units,) if len(self.Y.shape) ==1 else ( self.hidden_units,*dimsout )\n",
        "        #weight inits\n",
        "        limit = np.sqrt( 6 / ( n_features+self.hidden_units ))\n",
        "        limitU = np.sqrt( 6 / ( self.hidden_units+self.hidden_units ))\n",
        "        limitO = np.sqrt( 6 / ( 1 if len(self.Y.shape) ==1 else dimsout[0]+self.hidden_units ))\n",
        "        \"\"\"\n",
        "\n",
        "        Glorot init Draws samples from a uniform distribution within `[-limit, limit]`, where\n",
        "        `limit = sqrt(6 / (fan_in + fan_out))` (`fan_in` is the number of input\n",
        "\n",
        "        \"\"\"\n",
        "        #input weights\n",
        "        self.params['Wf'] = np.random.uniform(0, limit, (self.hidden_units , n_features) )\n",
        "        self.params['Wi'] = np.random.uniform(-limit, -0.0001, (self.hidden_units , n_features) )\n",
        "        self.params['Wo'] = np.random.uniform(-limit, -0.0001, (self.hidden_units , n_features) )\n",
        "        self.params['Wc'] = np.random.uniform(-limit, limit, (self.hidden_units , n_features) )\n",
        "        self.params['Wk'] = np.random.uniform(-limitO, limitO, self.hidden_units  )\n",
        "        #hidden weights\n",
        "        self.params['Uf'] = np.random.uniform(0, limitU, (self.hidden_units , self.hidden_units) )\n",
        "        self.params['Ui'] = np.random.uniform(-limitU, limitU, (self.hidden_units , self.hidden_units) )\n",
        "        self.params['Uo'] = np.random.uniform(-limitU, limitU, (self.hidden_units , self.hidden_units) )\n",
        "        self.params['Uc'] = np.random.uniform(-limitU, limitU, (self.hidden_units , self.hidden_units) )\n",
        "        #bias\n",
        "        self.params['bf'] = 1#np.random.uniform(0, limit, self.hidden_units )\n",
        "        self.params['bi'] = np.random.uniform(-limitU, -0.0001, self.hidden_units )\n",
        "        self.params['bo'] = np.random.uniform(-limitU, -0.0001, self.hidden_units )\n",
        "        self.params['bc'] = np.random.uniform(-limitU, limitU, self.hidden_units )\n",
        "\n",
        "        #Ht\n",
        "        self.hidden_state          = np.zeros(self.hidden_units)\n",
        "\n",
        "        #~Ct\n",
        "        self.cell_input_activation = np.zeros(self.hidden_units)\n",
        "\n",
        "        #Ot\n",
        "        self.output_activation     = np.zeros(self.hidden_units)\n",
        "\n",
        "        #Ft\n",
        "        self.forget_activation     = np.zeros(self.hidden_units)\n",
        "\n",
        "        #It\n",
        "        self.input_activation      = np.zeros(self.hidden_units)\n",
        "\n",
        "        #Ct\n",
        "        self.cell_state            = np.zeros(self.hidden_units)\n",
        "\n",
        "        self.final_output          = np.zeros(shape=tuple(n_out))\n",
        "\n",
        "        sigmoid_derivative         = lambda x: x * (1 - x)\n",
        "\n",
        "        hp_tang_derivative         = lambda x: 4 * self.sigmoid(x)\n",
        "\n",
        "        loss_function              = lambda error: 1/2 * (error)**2\n",
        "\n",
        "        self.error_signal_final_out = np.zeros(self.hidden_units)\n",
        "\n",
        "        self.error_signal_out_gate  = np.zeros(self.hidden_units)\n",
        "\n",
        "        cell_input_partials_Wc = cell_input_partials_Uc = cell_input_partials_Wi = cell_input_partials_Ui = cell_input_partials_Wf = cell_input_partials_Uf = 0\n",
        "\n",
        "        #iterating over sequence\n",
        "        for timestep in range(self.timesteps):\n",
        "            # print(timestep)\n",
        "            self.forget_activation     = self.sigmoid( np.dot(self.params['Wf'] , self.X[timestep] ) + np.dot( self.params['Uf'] , self.hidden_state ) + self.params['bf'] )\n",
        "\n",
        "            self.input_activation      = self.sigmoid( np.dot(self.params['Wi'] , self.X[timestep] ) + np.dot( self.params['Ui'] , self.hidden_state ) + self.params['bi'] )\n",
        "\n",
        "            self.output_activation     = self.sigmoid( np.dot(self.params['Wo'] , self.X[timestep] ) + np.dot( self.params['Uo'] , self.hidden_state ) + self.params['bo'] )\n",
        "\n",
        "            self.cell_input_activation = self.hp_tang( np.dot(self.params['Wc'] , self.X[timestep] ) + np.dot( self.params['Uc'] , self.hidden_state ) + self.params['bc'] )\n",
        "\n",
        "            prev_cell_state            = self.cell_state\n",
        "\n",
        "            self.cell_state            = np.multiply( self.forget_activation , self.cell_state) + np.multiply( self.input_activation , self.cell_input_activation)\n",
        "\n",
        "            prev_hidden_state          = self.hidden_state\n",
        "\n",
        "            self.hidden_state          = np.multiply( self.output_activation , np.tanh( self.cell_state ) )\n",
        "\n",
        "            self.final_output          = self.sigmoid( np.dot( self.params['Wk'] , self.hidden_state  ) )\n",
        "\n",
        "            #BPTT for output units and output gates pass\n",
        "\n",
        "            error = self.Y[timestep] -  self.final_output\n",
        "\n",
        "            self.error_signal_out_units = sigmoid_derivative(self.final_output) * error\n",
        "\n",
        "            self.error_signal_out_gate = sigmoid_derivative(self.output_activation) * (  np.multiply( self.hp_tang( self.cell_state ) , np.dot( self.params['Wk'] , self.error_signal_out_units  )  ) )\n",
        "\n",
        "            #I need the previous hidden state\n",
        "\n",
        "            output_unit_gradient = np.outer(  self.error_signal_out_units , prev_hidden_state )\n",
        "\n",
        "            if len(self.Y.shape) ==1:\n",
        "                output_unit_gradient = output_unit_gradient[0]\n",
        "\n",
        "            self.params['Wk']  += self.learning_rate * output_unit_gradient\n",
        "\n",
        "            #BPTT for output gate\n",
        "\n",
        "            self.params['Uo']  += self.learning_rate * np.outer(  self.error_signal_out_gate , prev_hidden_state)\n",
        "\n",
        "            self.params['Wo']  += self.learning_rate * np.outer(  self.error_signal_out_gate , self.X[timestep])\n",
        "\n",
        "\n",
        "            #for input gates, cell and forget gates we use RTRl\n",
        "            #before np.outer we elementwise multiply by internal state error.\n",
        "\n",
        "            internal_state_error              = self.output_activation * 2 * self.sigmoid(self.cell_state) * np.dot( self.params['Wk'] , self.error_signal_out_units )\n",
        "\n",
        "            cell_input_activation_partials_Wc = np.outer( internal_state_error * cell_input_partials_Wc * self.forget_activation + hp_tang_derivative( self.cell_input_activation ) * self.input_activation ,  self.X[timestep] )\n",
        "\n",
        "            cell_input_activation_partials_Uc = np.outer( internal_state_error *cell_input_partials_Uc * self.forget_activation + hp_tang_derivative( self.cell_input_activation ) * self.input_activation , prev_hidden_state  )\n",
        "\n",
        "\n",
        "            cell_igate_activation_partials_Wi = np.outer( internal_state_error *cell_input_partials_Wi * self.forget_activation + sigmoid_derivative(self.input_activation)  * self.cell_input_activation , self.X[timestep] )\n",
        "\n",
        "            cell_igate_activation_partials_Ui = np.outer( internal_state_error *cell_input_partials_Ui * self.forget_activation + sigmoid_derivative(self.input_activation)  * self.cell_input_activation , prev_hidden_state )\n",
        "\n",
        "\n",
        "            cell_forget_activation_partial_Wf = np.outer( internal_state_error *cell_input_partials_Wf * self.forget_activation + prev_cell_state * sigmoid_derivative(self.forget_activation) * self.input_activation , self.X[timestep] )\n",
        "\n",
        "            cell_forget_activation_partial_Uf = np.outer( internal_state_error *cell_input_partials_Uf * self.forget_activation + prev_cell_state * sigmoid_derivative(self.forget_activation) , prev_hidden_state )\n",
        "\n",
        "            #input weights\n",
        "            self.params['Wf'] -= self.learning_rate * cell_forget_activation_partial_Wf\n",
        "            self.params['Wi'] -= self.learning_rate * cell_igate_activation_partials_Wi\n",
        "            self.params['Wc'] -= self.learning_rate * cell_input_activation_partials_Wc\n",
        "\n",
        "            #hidden weights\n",
        "            self.params['Uf'] -= self.learning_rate * cell_forget_activation_partial_Uf\n",
        "            self.params['Ui'] -= self.learning_rate * cell_igate_activation_partials_Ui\n",
        "            self.params['Uc'] -= self.learning_rate * cell_input_activation_partials_Uc\n",
        "            self.losses.append( np.mean( self.loss( error ) ))\n",
        "\n",
        "            #self.params['bf'] += self.learning_rate *  internal_state_error\n",
        "            self.params['bi'] += self.learning_rate *  internal_state_error\n",
        "            self.params['bo'] += self.learning_rate *  self.error_signal_out_gate\n",
        "            self.params['bc'] += self.learning_rate *  internal_state_error\n",
        "\n",
        "        plt.plot( range(len(self.losses)) , self.losses )\n",
        "        plt.xlabel('timesteps')\n",
        "        plt.ylabel('Loss')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45db20eb-f373-41d0-87c0-eb827c5b6c79",
      "metadata": {
        "id": "45db20eb-f373-41d0-87c0-eb827c5b6c79"
      },
      "outputs": [],
      "source": [
        "lstm = LSTM()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec8f6a7f-70c9-4c83-8c23-6d2c4fe19dbb",
      "metadata": {
        "id": "ec8f6a7f-70c9-4c83-8c23-6d2c4fe19dbb",
        "outputId": "3b888d21-bc56-4e25-b459-1c0e3a43792e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2817445183.py:9: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/ (1+ np.exp(-X))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "lstm.train(df[:,:-1] , df[:,-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05a0cfda-8817-4aff-864e-3682001b4a26",
      "metadata": {
        "id": "05a0cfda-8817-4aff-864e-3682001b4a26"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}